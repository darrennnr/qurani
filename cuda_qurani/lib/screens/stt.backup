import 'package:device_info_plus/device_info_plus.dart';
import 'package:flutter/material.dart';
import 'package:flutter/services.dart';
import 'package:path_provider/path_provider.dart';
import 'package:vosk_flutter/vosk_flutter.dart';
import 'package:supabase_flutter/supabase_flutter.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:web_socket_channel/io.dart';
import 'package:web_socket_channel/web_socket_channel.dart';
import 'package:web_socket_channel/status.dart' as status;
import 'package:http/http.dart' as http;
import 'package:flutter_sound/flutter_sound.dart';
import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'dart:math';
import 'package:archive/archive.dart';
import 'dart:math' as math;

class VoskSTTCorrectionPage extends StatefulWidget {
  final int suratId;
  final String suratName;

  const VoskSTTCorrectionPage({
    Key? key,
    required this.suratId,
    required this.suratName,
  }) : super(key: key);

  @override
  _VoskSTTCorrectionPageState createState() => _VoskSTTCorrectionPageState();
}

class AyatProgress {
  final int ayatIndex;
  final int totalWords;
  final int correctWords;
  final int errorWords;
  final int skippedWords;
  final double completionPercentage;
  final bool isCompleted;

  AyatProgress({
    required this.ayatIndex,
    required this.totalWords,
    required this.correctWords,
    required this.errorWords,
    required this.skippedWords,
    required this.completionPercentage,
    required this.isCompleted,
  });
}

class _VoskSTTCorrectionPageState extends State<VoskSTTCorrectionPage>
    with TickerProviderStateMixin {
  // ==================== API CONFIGURATION - TARTEEL ENHANCED BACKEND ====================
  // ‚úÖ UPDATED: Use correct IP from backend startup
  static const String API_BASE_URL = 'http://192.168.1.47:8000';
  static const String WEBSOCKET_URL = 'ws://192.168.1.47:8000/ws';
  
  // üïå MEMORY-BASED ENDPOINTS (Compatible with Tarteel Whisper backend)
  static const String MEMORY_API_URL = 'http://192.168.1.47:8000/live';
  static const String MEMORY_WS_URL = 'ws://192.168.1.47:8000/ws/live';
  
  // üì± For mobile device connection: Ensure your phone is on same WiFi network
  // üñ•Ô∏è Backend running at: D:/Laravel_Flutter/fastapi-service (uvicorn on 0.0.0.0:8000)
  static const Duration _apiTimeout = Duration(seconds: 20); // Diperpanjang dari 10s
  static const Duration _websocketTimeout = Duration(seconds: 15); // Diperpanjang dari 10s
  static const Duration _connectionRetryDelay = Duration(seconds: 3);
  static const int _maxRetryAttempts = 5; // Increased retry attempts

  // ==================== TAMBAH DI BAGIAN ATAS CLASS STATE ====================

  // ‚ö° LIVE TRANSCRIPT Configuration (Tarteel-like)
  static const int _sampleRate = 16000;
  static const Duration _processingInterval = Duration(milliseconds: 200); // ‚úÖ Faster processing
  static const Duration _vadCheckInterval = Duration(milliseconds: 100);   // ‚úÖ More responsive VAD
  static const Duration _liveTranscriptInterval = Duration(milliseconds: 500); // ‚úÖ Live updates every 500ms

  // Old STT variables
  String _confirmedTranscript = '';
  List<String> _transcriptHistory = [];
  Timer? _processingTimer;
  Timer? _vadTimer;
  Timer? _autoSendTimer;

  // üïå TARTEEL ENHANCED VARIABLES
  String? _tarteelSessionId;
  bool _isTarteelMode = true;  // Enable Tarteel by default
  String _tarteelMode = 'practice';  // practice, memorization, review
  bool _autoAdvanceEnabled = true;
  bool _progressiveRevealEnabled = false;
  List<Map<String, dynamic>> _revealedWords = [];
  Map<String, dynamic>? _currentMistakes;
  String _encouragementMessage = '';
  bool _isAyahCompleted = false;

  // Voice Activity Detection
  bool _isVoiceActive = false;
  double _audioLevel = 0.0;
  int _silenceFrameCount = 0;
  int _voiceFrameCount = 0;
  static const int _minVoiceFrames = 3;
  static const int _maxSilenceFrames = 15;
  double _averageAudioLevel = 0.0;
  List<double> _audioLevelHistory = [];
  static const int _audioHistoryLength = 20;
  late final Random _random;

  // Supabase client
  final SupabaseClient _supabase = Supabase.instance.client;

  // Progress tracking
  Map<int, AyatProgress> _ayatProgress = {};

  // Analytics
  int _totalTranscriptsSent = 0;
  int _successfulAPIResponses = 0;
  DateTime? _sessionStartTime;

  // UI Controllers
  final ScrollController _scrollController = ScrollController();
  late AnimationController _pulseController;
  late AnimationController _levelController;
  late AnimationController _progressController;
  late AnimationController _waveController;
  late List<GlobalKey> _ayatKeys;

  // UI State
  bool _hideUnreadAyat = false;
  bool _isQuranMode = true;
  int _currentPage = 1;
  List<AyatData> _currentPageAyats = [];
  bool _showAdvancedStats = false;
  bool _isUIVisible = true; // ‚Üê TAMBAHKAN BARIS INI
  
  // üéØ TARTEEL-STYLE: Enhanced word status tracking
  Map<int, Map<String, dynamic>> _wordStatus = {}; // position -> {status, color, similarity, timestamp}
  Map<int, String> _wordHighlights = {};              // position -> highlight_type
  List<int> _currentReadingWords = [];                // Currently being read
  List<int> _completedWords = [];                     // Successfully completed
  List<int> _errorWords = [];                         // Mistakes
  
  // üìà Real-time progress tracking
  int _wordsMatched = 0;
  int _wordsError = 0;
  int _wordsSkipped = 0;
  int _currentWordIndex = 0;          // Current word being read
  double _completionPercentage = 0.0;
  String _overallStatus = 'processing';
  
  // ‚ö° Live transcript display
  String _livePartialTranscript = '';  // Real-time partial text
  bool _showLiveTranscript = true;     // Toggle live display
  DateTime? _lastTranscriptUpdate;     // For timing
  

  // Surah info
  String _suratInfo = '';
  String _suratArti = '';
  String _suratTempatTurun = '';
  String _suratDeskripsi = '';

  // Auto features
  bool _autoSendEnabled = true;
  bool _autoMoveEnabled = true;  // Keep for backward compatibility
  Duration _autoSendDelay = Duration(seconds: 2);

  // üåà TARTEEL-STYLE Color Constants
  static const Color backgroundColor = Color.fromARGB(255, 255, 255, 255);
  static const Color primaryColor = Color(0xFF064420);
  
  // ‚ú® Word Recognition Colors (like Tarteel)
  static const Color correctColor = Color(0xFF27AE60);      // üü¢ Perfect match
  static const Color partialColor = Color(0xFFF39C12);      // üü° Partial/similar
  static const Color errorColor = Color(0xFFE74C3C);        // üî¥ Mistake
  static const Color currentColor = Color(0xFF3498DB);      // üîµ Currently reading
  static const Color completedColor = Color(0xFF2ECC71);    // ‚úÖ Completed word
  
  // üåä Progress Indicators
  static const Color listeningColor = Color(0xFF3498DB);    // üé§ Listening state
  static const Color processingColor = Color(0xFF9B59B6);   // ‚öôÔ∏è Processing
  static const Color unreadColor = Color(0xFFBDC3C7);       // üìç Not read yet
  static const Color skippedColor = Color(0xFF95A5A6);      // ‚è≠Ô∏è Skipped
  static const Color accentColor = Color(0xFF9B59B6);       // ‚ú® Accent
  static const Color warningColor = Color(0xFFF39C12);      // ‚ö†Ô∏è Warning
  
  // üåü Live Feedback Colors
  static const Color liveTranscriptColor = Color(0xFF1ABC9C); // ‚ö° Live text
  static const Color yasinHighlightColor = Color(0xFFE67E22); // üéÜ Ya-Sin special
  static const Color ayahProgressColor = Color(0xFF8E44AD);   // üìà Progress

  // ==================== ENHANCED STT VARIABLES ====================
  VoskFlutterPlugin? _vosk;
  Model? _model;
  Recognizer? _recognizer;
  SpeechService? _speechService;
  bool _isVoskInitialized = false;
  bool _isModelLoaded = false;
  bool _isListening = false;
  String _selectedModel = 'arabic_mgb2';
  
  // ==================== AUDIO RECORDING ====================
  FlutterSoundRecorder? _audioRecorder;
  bool _isRecorderInitialized = false;
  StreamSubscription<Uint8List>? _audioStreamSubscription;
  StreamController<Uint8List>? _audioStreamController;
  StreamSubscription<RecordingDisposition>? _audioLevelSubscription;

  // ==================== FIXED WEBSOCKET & SESSION MANAGEMENT ====================
  String? _activeSessionId;
  bool _isSessionActive = false;
  WebSocketChannel? _webSocketChannel;
  bool _isWebSocketConnected = false;

  // PERBAIKAN 2: Improved connection management
  Timer? _heartbeatTimer;
  Timer? _reconnectTimer;
  Timer? _connectionTimeoutTimer;
  Timer? _simulatedWordTimer;
  int _reconnectAttempts = 0;
  int _simulatedWordIndex = 0;
  static const int _maxReconnectAttempts = 3; // Kurangi dari 5 ke 3
  static const Duration _connectionTimeout = Duration(seconds: 10);
  static const Duration _heartbeatInterval = Duration(seconds: 30);

  // ==================== CONTINUOUS STT VARIABLES ====================
  String _liveTranscript = '';
  String _currentPartialTranscript = '';
  StreamController<String> _transcriptStreamController =
      StreamController<String>.broadcast();
  Timer? _transcriptSendTimer;
  Timer? _partialUpdateTimer;
  bool _isProcessingTranscript = false;
  String _lastSentTranscript = '';
  

  // ==================== ENHANCED LOGGING ====================
  List<String> _logs = [];
  List<APILog> _apiLogs = [];
  bool _showLogs = false;

  // UI and other variables remain same...
  List<AyatData> _ayatList = [];
  List<APIWordResult> _currentAyatResults = [];
  int _currentAyatIndex = 0;
  int _currentAyatNumber = 1;
  bool _isLoading = true;
  String _errorMessage = '';
  
  // ==================== TARGET AYAH SYSTEM ====================
  int? _targetAyahNumber; // Target ayah yang akan dibaca
  String _targetAyahText = ''; // Text target ayah dari database
  List<String> _targetWords = []; // Words array dari target ayah
  bool _isTargetSet = false; // Apakah target sudah di-set
  double _targetProgress = 0.0; // Progress terhadap target ayah
  
  // üéØ TARTEEL: Real-time feedback variables
  String _currentFeedbackColor = 'blue'; // Current feedback color (green/red/blue)
  double _currentProgress = 0.0; // Current progress percentage

  // ==================== FIXED API SESSION INITIALIZATION ====================

  Future<void> _initializeAPISession() async {
    _detailedLog(
      'TARTEEL_SESSION',
      'Starting Tarteel session for Surah ${widget.suratId}, Ayah $_currentAyatNumber',
    );

    try {
      // üïå MEMORY-BASED: Use memory session endpoint (with Tarteel Whisper backend)
      final userId = 'flutter_app_${DateTime.now().millisecondsSinceEpoch}';
      final memoryUrl = '$MEMORY_API_URL/start/${widget.suratId}/$_currentAyatNumber';

      // Create request body for Memory API
      final requestBody = {
        'user_id': userId,
        'mode': 'surah',
        'surah_id': widget.suratId,
        'ayah': _currentAyatNumber,
        'data': {
          'tarteel_mode': _tarteelMode,
          'auto_advance': _autoAdvanceEnabled,
          'show_transliteration': true,
        }
      };

      _detailedLog('MEMORY_SESSION', 'Memory URL: $memoryUrl');
      _detailedLog('MEMORY_SESSION', 'Request Body: ${jsonEncode(requestBody)}');

      // Memory API: Enhanced headers and timeout
      final response = await http
          .post(
            Uri.parse(memoryUrl),
            headers: {
              'Content-Type': 'application/json',
              'Accept': 'application/json',
              'User-Agent': 'Flutter-Qurani-Memory/2.0',
              'Cache-Control': 'no-cache',
            },
            body: jsonEncode(requestBody),
          )
          .timeout(_apiTimeout);

      _detailedLog('TARTEEL_SESSION', 'HTTP Status: ${response.statusCode}');
      _detailedLog('TARTEEL_SESSION', 'HTTP Body: ${response.body}');

      // üïå MEMORY: Better status code handling
      if (response.statusCode >= 200 && response.statusCode < 300) {
        final responseData = jsonDecode(response.body);
        
        // üïå MEMORY: Validate Memory API response structure (sessionId not session_id)
        if (responseData['sessionId'] != null) {
          _tarteelSessionId = responseData['sessionId'];
          _activeSessionId = _tarteelSessionId!;  // Keep compatibility
          _isSessionActive = true;

          // üïå MEMORY: Extract session data
          if (responseData['surah_id'] != null) {
            _currentAyatNumber = responseData['ayah'] ?? _currentAyatNumber;
          }

          _detailedLog('MEMORY_SESSION', 'Memory Session ID: $_tarteelSessionId');
          _logAPICall('POST', '/live/start', response.statusCode, 'Memory Session Success');

          // üïå MEMORY: Initialize WebSocket (using memory WebSocket endpoint)
          await _initializeMemoryWebSocket();
          
          setState(() {});
          _showSnackBar('üïå Memory Session Started (Tarteel Whisper)', SnackBarType.success);
        } else {
          throw Exception('Invalid Memory response: missing sessionId');
        }
      } else {
        throw Exception('HTTP ${response.statusCode}: ${response.body}');
      }
    } on TimeoutException catch (e) {
      _detailedLog('API_SESSION', 'TIMEOUT ERROR: $e');
      _logAPICall('POST', '/live/start', 0, 'Timeout: $e');
      
      // PERBAIKAN: Retry logic untuk timeout
      if (_reconnectAttempts < _maxRetryAttempts) {
        _detailedLog('API_SESSION', 'Retrying session initialization...');
        _reconnectAttempts++;
        
        await Future.delayed(_connectionRetryDelay);
        await _initializeAPISession(); // Retry
        return;
      }
      
      _isSessionActive = false;
      _showSnackBar('Connection timeout. Check your internet.', SnackBarType.error);
      throw Exception('Session initialization timeout after $_maxRetryAttempts attempts');
    } catch (e) {
      _detailedLog('API_SESSION', 'ERROR: $e');
      _logAPICall('POST', '/live/start', 0, 'Error: $e');
      _isSessionActive = false;
      _activeSessionId = null;
      setState(() {});
      _showSnackBar('Failed to start session: $e', SnackBarType.error);
      rethrow;
    }
  }
  // Handle session update
  void _handleSessionUpdate(Map<String, dynamic> data) {
    _detailedLog('WEBSOCKET', 'Session update received');
    setState(() {});
  }

  // Compatibility method
  void _showSnackBar(String message, SnackBarType type) {
    _showEnhancedSnackBar(message, type);
  }

  // Redirect method untuk backward compatibility
  Future<void> _sendTranscriptToAPI(String transcript) async {
    _sendFinalTranscript(transcript);
  }

  // ==================== TARTEEL WEBSOCKET METHODS ====================

  Future<void> _initializeMemoryWebSocket() async {
    if (_tarteelSessionId == null) {
      _detailedLog('MEMORY_WS', 'No Memory session ID available');
      return;
    }

    try {
      _detailedLog('MEMORY_WS', 'Connecting to Memory WebSocket (Tarteel Whisper backend)...');
      
      final memoryWsUrl = '$MEMORY_WS_URL/$_tarteelSessionId';
      _detailedLog('MEMORY_WS', 'Memory WS URL: $memoryWsUrl');

      _webSocketChannel = IOWebSocketChannel.connect(
        Uri.parse(memoryWsUrl),
        headers: {
          'User-Agent': 'Flutter-Qurani-Memory/2.0',
        },
      );

      _isWebSocketConnected = true;
      _reconnectAttempts = 0;

      // üïå TARTEEL: Enhanced message handling
      _webSocketChannel!.stream.listen(
        (message) => _handleTarteelWebSocketMessage(message),
        onError: (error) => _handleTarteelWebSocketError(error),
        onDone: () => _handleTarteelWebSocketDisconnect(),
      );

      _detailedLog('TARTEEL_WS', 'üïå Tarteel WebSocket connected successfully');
      _showSnackBar('üïå Tarteel WebSocket Connected', SnackBarType.success);

      // Start Tarteel heartbeat
      _startTarteelHeartbeat();

    } catch (e) {
      _detailedLog('TARTEEL_WS', 'Failed to connect: $e');
      _isWebSocketConnected = false;
      _showSnackBar('Tarteel WebSocket failed: $e', SnackBarType.error);
    }
  }

  void _handleTarteelWebSocketMessage(dynamic message) {
    try {
      final data = jsonDecode(message);
      _detailedLog('TARTEEL_WS', 'Received: ${data['type']}');

      switch (data['type']) {
        case 'transcript_result':
          _handleTarteelTranscriptResult(data['data']);
          break;
        case 'ayah_moved':
          _handleTarteelAyahMoved(data['data']);
          break;
        case 'progressive_update':
          _handleTarteelProgressiveUpdate(data['data']);
          break;
        case 'mistake_detected':
          _handleTarteelMistakeDetected(data['data']);
          break;
        case 'encouragement':
          _handleTarteelEncouragement(data['data']);
          break;
        case 'heartbeat_response':
          _detailedLog('TARTEEL_WS', 'Heartbeat acknowledged');
          break;
        case 'audio_received':
          _handleAudioReceived(data['data'] ?? data);
          break;
        default:
          _detailedLog('TARTEEL_WS', 'Unknown message type: ${data['type']}');
      }
    } catch (e) {
      _detailedLog('TARTEEL_WS', 'Message parsing error: $e');
    }
  }

  void _handleTarteelWebSocketError(dynamic error) {
    _detailedLog('TARTEEL_WS', 'WebSocket error: $error');
    _isWebSocketConnected = false;
    _showSnackBar('Tarteel connection error', SnackBarType.error);
  }

  void _handleTarteelWebSocketDisconnect() {
    _detailedLog('TARTEEL_WS', 'WebSocket disconnected');
    _isWebSocketConnected = false;
    _showSnackBar('Tarteel disconnected', SnackBarType.warning);
  }

  void _startTarteelHeartbeat() {
    Timer.periodic(Duration(seconds: 30), (timer) {
      if (!_isWebSocketConnected || _tarteelSessionId == null) {
        timer.cancel();
        return;
      }
      
      _sendTarteelMessage({
        'type': 'heartbeat',
        'session_id': _tarteelSessionId,
      });
    });
  }

  // üïå TARTEEL FEATURE HANDLERS

  void _handleTarteelTranscriptResult(Map<String, dynamic> data) {
    _detailedLog('TARTEEL', 'Transcript result received');
    
    if (data['results'] != null) {
      setState(() {
        _currentAyatResults = (data['results'] as List)
            .map((result) => APIWordResult.fromJson(result))
            .toList();
      });
    }

    if (data['encouragement'] != null) {
      setState(() {
        _encouragementMessage = data['encouragement'];
      });
    }

    if (data['progressive_update'] != null) {
      _handleTarteelProgressiveUpdate(data['progressive_update']);
    }
  }

  void _handleTarteelAyahMoved(Map<String, dynamic> data) {
    _detailedLog('TARTEEL', 'üîÑ Auto-advance to ayah ${data['new_ayah']}');
    _detailedLog('TARTEEL', 'üìä Current ayah list length: ${_ayatList.length}');
    _detailedLog('TARTEEL', 'üìä Current ayah index before: $_currentAyatIndex');
    
    if (data['new_ayah'] != null) {
      final newAyahNumber = data['new_ayah'] as int;
      final previousAyah = data['previous_ayah'] ?? _currentAyatNumber;
      final completionPercentage = data['completion_percentage'] ?? 100.0;
      final message = data['message'] ?? 'Moving to next ayah...';
      
      setState(() {
        // Update current ayah
        _currentAyatNumber = newAyahNumber;
        
        // Find the correct ayah index in the list
        _currentAyatIndex = _ayatList.indexWhere((ayat) => ayat.ayah == newAyahNumber);
        if (_currentAyatIndex == -1) {
          _currentAyatIndex = newAyahNumber - 1; // Fallback to 0-based indexing
        }
        
        _detailedLog('TARTEEL', 'üìä New ayah index: $_currentAyatIndex');
        _detailedLog('TARTEEL', 'üìä Ayah found in list: ${_currentAyatIndex != -1}');
        
        // Reset progress indicators
        _isAyahCompleted = false;
        _completedWords.clear();
        _currentReadingWords.clear();
        _wordHighlights.clear();
        _wordStatus.clear();
        _completionPercentage = 0.0;
        _wordsMatched = 0;
        _wordsError = 0;
        _wordsSkipped = 0;
        
        // Update encouragement message
        _encouragementMessage = message;
        
        // Update target ayah for comparison
        if (_ayatList.isNotEmpty && _currentAyatIndex < _ayatList.length) {
          final currentAyat = _ayatList[_currentAyatIndex];
          _targetAyahNumber = currentAyat.ayah; // Update target ayah number
          _targetAyahText = currentAyat.arabic;
          _targetWords = currentAyat.arabic.split(' ')
              .where((w) => w.trim().isNotEmpty)
              .toList();
          _detailedLog('TARTEEL_TARGET', 'Updated target ayah after move: ${currentAyat.ayah} - ${currentAyat.arabic}');
        }
        
        // Mark previous ayah as completed if not already
        if (previousAyah != newAyahNumber) {
          _ayatProgress[previousAyah - 1] = AyatProgress(
            ayatIndex: previousAyah - 1,
            completionPercentage: completionPercentage,
            isCompleted: true,
            correctWords: 0,
            errorWords: 0,
            skippedWords: 0,
            totalWords: 0,
          );
        }
      });
      
      // Load new ayah data
      _loadAyahData();
      
      // Scroll to new ayah if needed
      _scrollToCurrentAyah();
      
      // Show success message
      _showSnackBar('üéâ Ayah $previousAyah completed! Now at Ayah $newAyahNumber', SnackBarType.success);
      
      _detailedLog('AYAH_MOVEMENT', 'Successfully moved from Ayah $previousAyah to Ayah $newAyahNumber');
    }
  }

  void _handleTarteelProgressiveUpdate(Map<String, dynamic> data) {
    _detailedLog('TARTEEL', 'üìú Progressive revelation update');
    
    // Handle word-by-word progress updates
    if (data['word_results'] != null) {
      final wordResults = data['word_results'] as List;
      
      setState(() {
        // Update word highlighting based on results
        for (var wordData in wordResults) {
          final position = wordData['position'];
          final status = wordData['status'];
          final color = wordData['color'] ?? 'gray';
          final highlight = wordData['highlight'] ?? false;
          
          if (position != null) {
            _wordStatus[position] = {
              'status': status,
              'color': color,
              'similarity': wordData['similarity_score'] ?? 0.0,
              'timestamp': DateTime.now().millisecondsSinceEpoch,
              'highlight': highlight,
            };
            
            // Update word highlighting for visual feedback
            if (highlight) {
              _wordHighlights[position] = status == 'matched' ? 'completed' : 'reading';
              if (status == 'matched' && !_completedWords.contains(position)) {
                _completedWords.add(position);
              }
            }
          }
        }
        
        // Update overall progress
        if (data['completion_percentage'] != null) {
          _completionPercentage = (data['completion_percentage'] as num).toDouble();
        }
      });
      
      _detailedLog('TARTEEL_PROGRESS', 'Updated ${wordResults.length} word statuses, completion: ${_completionPercentage.toStringAsFixed(1)}%');
    }
    
    // Legacy support for reveals
    if (data['reveals'] != null) {
      setState(() {
        _revealedWords.addAll((data['reveals'] as List).cast<Map<String, dynamic>>());
      });
    }
  }

  void _handleTarteelMistakeDetected(Map<String, dynamic> data) {
    _detailedLog('TARTEEL', '‚ùå Mistake detected');
    
    setState(() {
      _currentMistakes = data;
    });
    
    if (data['correction_hint'] != null) {
      _showSnackBar('üí° ${data['correction_hint']}', SnackBarType.warning);
    }
  }

  void _handleTarteelEncouragement(Map<String, dynamic> data) {
    _detailedLog('TARTEEL', 'üåü Encouragement received');
    
    if (data['message'] != null) {
      setState(() {
        _encouragementMessage = data['message'];
      });
      _showSnackBar('üåü ${data['message']}', SnackBarType.success);
    }
  }

  void _sendTarteelMessage(Map<String, dynamic> message) {
    if (_isWebSocketConnected && _webSocketChannel != null) {
      _webSocketChannel!.sink.add(jsonEncode(message));
      _detailedLog('TARTEEL_WS', 'Sent: ${message['type']}');
    }
  }
  
  void _scrollToCurrentAyah() {
    // Scroll to current ayah for better visibility
    if (_ayatKeys.isNotEmpty && _currentAyatIndex < _ayatKeys.length) {
      final currentAyahKey = _ayatKeys[_currentAyatIndex];
      if (currentAyahKey.currentContext != null) {
        Scrollable.ensureVisible(
          currentAyahKey.currentContext!,
          duration: Duration(milliseconds: 500),
          curve: Curves.easeInOut,
        );
      }
    }
  }
  
  // ==================== TARGET AYAH SYSTEM METHODS ====================
  
  /// Set target ayah yang akan dibaca sebagai patokan comparison
  Future<void> setTargetAyah(int ayahNumber) async {
    try {
      _detailedLog('TARGET_AYAH', 'Setting target ayah: $ayahNumber');
      
      setState(() {
        _targetAyahNumber = ayahNumber;
        _isTargetSet = false; // Reset while loading
        _targetProgress = 0.0;
      });
      
      // Load target ayah data from database
      await _loadTargetAyahFromDatabase(ayahNumber);
      
      setState(() {
        _isTargetSet = true;
      });
      
      _detailedLog('TARGET_AYAH', 'Target ayah $ayahNumber set successfully');
      _showSnackBar('üéØ Target: Ayah $ayahNumber', SnackBarType.info);
      
    } catch (e) {
      _detailedLog('TARGET_AYAH', 'Error setting target ayah: $e');
      _showSnackBar('‚ùå Failed to set target ayah', SnackBarType.error);
    }
  }
  
  /// Load target ayah text dari database
  Future<void> _loadTargetAyahFromDatabase(int ayahNumber) async {
    try {
      // Use Supabase instead of local database
      final response = await _supabase
          .from('m10_quran_ayah')
          .select('*')
          .eq('surah_id', widget.suratId)
          .eq('ayah', ayahNumber)
          .limit(1);
      
      if (response.isNotEmpty) {
        final ayahData = response.first;
        setState(() {
          _targetAyahText = ayahData['arabic'] as String? ?? '';
          _targetWords = _targetAyahText.split(' ')
              .where((w) => w.trim().isNotEmpty)
              .toList();
        });
        
        _detailedLog('TARGET_AYAH', 'Loaded target text: $_targetAyahText');
        _detailedLog('TARGET_AYAH', 'Target words count: ${_targetWords.length}');
      } else {
        throw Exception('Ayah $ayahNumber not found in database');
      }
    } catch (e) {
      _detailedLog('TARGET_AYAH', 'Error loading target ayah from database: $e');
      rethrow;
    }
  }
  
  /// üïå TARTEEL-STYLE: Enhanced real-time ayah comparison with 70% threshold
  Map<String, dynamic> _compareWithTarget(String transcription) {
    if (!_isTargetSet || _targetWords.isEmpty) {
      return {
        'isTargetMatch': false,
        'similarity': 0.0,
        'matchedWords': 0,
        'totalWords': 0,
        'message': 'No target set',
        'isCorrect': false,
        'canSkip': true
      };
    }
    
    final spokenWords = transcription.split(' ')
        .where((w) => w.trim().isNotEmpty)
        .toList();
    
    // üéØ TARTEEL: Real-time feedback even with no input
    if (spokenWords.isEmpty) {
      return {
        'isTargetMatch': false,
        'similarity': 0.0,
        'matchedWords': 0,
        'totalWords': _targetWords.length,
        'message': 'üé§ Start reciting...',
        'feedbackColor': 'blue',
        'isCorrect': false,
        'waitingForInput': true
      };
    }
    
    int matchedWords = 0;
    double totalSimilarity = 0.0;
    List<Map<String, dynamic>> wordMatches = [];
    
    // üéØ ENHANCED: Smart word matching for Arabic Quranic text
    for (int i = 0; i < spokenWords.length && i < _targetWords.length; i++) {
      final spoken = _cleanArabicText(spokenWords[i]);
      final target = _cleanArabicText(_targetWords[i]);
      
      double wordSimilarity = 0.0;
      bool isExactMatch = false;
      bool isPartialMatch = false;
      
      // Exact match
      if (spoken == target) {
        matchedWords++;
        totalSimilarity += 1.0;
        wordSimilarity = 1.0;
        isExactMatch = true;
      }
      // Partial match with similarity calculation
      else if (spoken.isNotEmpty && target.isNotEmpty) {
        final similarity = _calculateWordSimilarity(spoken, target);
        if (similarity >= 0.6) { // 60% word similarity threshold
          matchedWords++;
          totalSimilarity += similarity;
          wordSimilarity = similarity;
          isPartialMatch = true;
        }
      }
      
      wordMatches.add({
        'index': i,
        'spoken': spokenWords[i],
        'target': _targetWords[i],
        'similarity': wordSimilarity,
        'isExactMatch': isExactMatch,
        'isPartialMatch': isPartialMatch,
        'isMatched': wordSimilarity >= 0.6
      });
    }
    
    final similarity = _targetWords.isNotEmpty ? totalSimilarity / _targetWords.length : 0.0;
    final progress = _targetWords.isNotEmpty ? (matchedWords / _targetWords.length) * 100 : 0.0;
    
    // üéØ TARTEEL: 70% threshold for correct/incorrect
    final isCorrect = similarity >= 0.7;
    final isTargetMatch = similarity >= 0.7;
    
    setState(() {
      _targetProgress = progress;
      // Update word highlighting for real-time feedback
      _updateTarteelWordHighlighting(wordMatches);
    });
    
    String message;
    String feedbackColor;
    
    if (isCorrect) {
      message = '‚úÖ Excellent! Ayah completed (${progress.toStringAsFixed(0)}%)';
      feedbackColor = 'green';
    } else if (progress >= 0.7) {
      message = 'üü¢ Good! Keep going (${progress.toStringAsFixed(0)}%)';
      feedbackColor = 'green';
    } else if (progress > 0) {
      message = 'üî¥ Continue reciting... (${progress.toStringAsFixed(0)}%)';
      feedbackColor = 'red';
    } else {
      message = 'üé§ Start reciting the ayah';
      feedbackColor = 'blue';
    }
    
    return {
      'isTargetMatch': isTargetMatch,
      'similarity': similarity,
      'matchedWords': matchedWords,
      'totalWords': _targetWords.length,
      'progress': progress,
      'message': message,
      'isCorrect': isCorrect,
      'canSkip': spokenWords.isEmpty,
      'wordMatches': wordMatches,
      'feedbackColor': feedbackColor
    };
  }
  
  /// üïå TARTEEL: Clean Arabic text for better comparison
  String _cleanArabicText(String text) {
    return text
        .trim()
        .replaceAll(RegExp(r'[^\u0600-\u06FF]'), '') // Keep only Arabic letters
        .replaceAll(RegExp(r'[\u064B-\u0652]'), '') // Remove diacritics
        .toLowerCase();
  }
  
  /// üéØ TARTEEL: Calculate word similarity using Levenshtein distance
  double _calculateWordSimilarity(String spoken, String target) {
    if (spoken.isEmpty || target.isEmpty) return 0.0;
    if (spoken == target) return 1.0;
    
    final distance = _levenshteinDistance(spoken, target);
    final maxLength = spoken.length > target.length ? spoken.length : target.length;
    return 1.0 - (distance / maxLength);
  }
  
  /// Calculate Levenshtein distance between two strings
  int _levenshteinDistance(String s1, String s2) {
    if (s1.isEmpty) return s2.length;
    if (s2.isEmpty) return s1.length;
    
    List<List<int>> matrix = List.generate(
      s1.length + 1,
      (i) => List.generate(s2.length + 1, (j) => 0),
    );
    
    for (int i = 0; i <= s1.length; i++) {
      matrix[i][0] = i;
    }
    for (int j = 0; j <= s2.length; j++) {
      matrix[0][j] = j;
    }
    
    for (int i = 1; i <= s1.length; i++) {
      for (int j = 1; j <= s2.length; j++) {
        int cost = s1[i - 1] == s2[j - 1] ? 0 : 1;
        matrix[i][j] = [
          matrix[i - 1][j] + 1,      // deletion
          matrix[i][j - 1] + 1,      // insertion
          matrix[i - 1][j - 1] + cost // substitution
        ].reduce((a, b) => a < b ? a : b);
      }
    }
    
    return matrix[s1.length][s2.length];
  }
  
  /// üéØ TARTEEL: Update word highlighting based on real-time comparison
  void _updateTarteelWordHighlighting(List<Map<String, dynamic>> wordMatches) {
    setState(() {
      _wordHighlights.clear();
      _wordStatus.clear();
      
      for (final match in wordMatches) {
        final index = match['index'] as int;
        final isMatched = match['isMatched'] as bool;
        final similarity = match['similarity'] as double;
        
        _wordHighlights[index] = isMatched ? 'completed' : 'unmatched';
        _wordStatus[index] = {
          'status': isMatched ? 'matched' : 'unmatched',
          'similarity': similarity,
          'color': isMatched 
              ? (similarity >= 0.9 ? 'green' : 'orange')
              : 'red',
          'highlight': isMatched
        };
      }
    });
  }
  
  /// Show dialog untuk set target ayah
  void _showTargetAyahDialog() {
    showDialog(
      context: context,
      builder: (BuildContext context) {
        int selectedAyah = _targetAyahNumber ?? _currentAyatNumber;
        
        return AlertDialog(
          title: Row(
            children: [
              Icon(Icons.track_changes, color: Colors.blue),
              SizedBox(width: 8),
              Text('Set Target Ayah'),
            ],
          ),
          content: Column(
            mainAxisSize: MainAxisSize.min,
            children: [
              Text('Pilih ayah yang akan dijadikan target untuk comparison:'),
              SizedBox(height: 16),
              Row(
                children: [
                  Text('Ayah: '),
                  Expanded(
                    child: Slider(
                      value: selectedAyah.toDouble(),
                      min: 1,
                      max: 83, // Ya-Sin has 83 ayahs
                      divisions: 82,
                      label: selectedAyah.toString(),
                      onChanged: (value) {
                        setState(() {
                          selectedAyah = value.round();
                        });
                      },
                    ),
                  ),
                  Text(selectedAyah.toString()),
                ],
              ),
              if (_isTargetSet) ...[
                SizedBox(height: 8),
                Text(
                  'Current Target: Ayah $_targetAyahNumber',
                  style: TextStyle(
                    fontSize: 12,
                    color: Colors.blue,
                    fontWeight: FontWeight.bold,
                  ),
                ),
              ],
            ],
          ),
          actions: [
            if (_isTargetSet)
              TextButton(
                onPressed: () {
                  setState(() {
                    _isTargetSet = false;
                    _targetAyahNumber = null;
                    _targetAyahText = '';
                    _targetWords.clear();
                    _targetProgress = 0.0;
                  });
                  Navigator.of(context).pop();
                  _showSnackBar('üéØ Target cleared', SnackBarType.info);
                },
                child: Text('Clear Target'),
              ),
            TextButton(
              onPressed: () => Navigator.of(context).pop(),
              child: Text('Cancel'),
            ),
            ElevatedButton(
              onPressed: () {
                Navigator.of(context).pop();
                setTargetAyah(selectedAyah);
              },
              child: Text('Set Target'),
            ),
          ],
        );
      },
    );
  }

  // üïå TARTEEL: Helper method to load ayah data after auto-advance
  Future<void> _loadAyahData() async {
    try {
      // Reload current ayah data from database
      await _loadAyatData();
      
      // Reset UI state for new ayah
      setState(() {
        _currentAyatResults.clear();
        _revealedWords.clear();
        _currentMistakes = null;
      });
      
      _detailedLog('TARTEEL', 'Ayah data reloaded for ayah $_currentAyatNumber');
    } catch (e) {
      _detailedLog('TARTEEL', 'Failed to reload ayah data: $e');
    }
  }

  // ==================== FIXED WEBSOCKET CONNECTION ====================

Future<void> _initializeWebSocketConnection() async {
    if (_activeSessionId == null) {
      _detailedLog('WEBSOCKET', 'ERROR: No active session ID');
      return;
    }

    try {
      // WebSocket connection to local FastAPI backend
      // Use the endpoint format from your FastAPI backend: /ws/live/{session_id}
      final wsUrl = '$WEBSOCKET_URL/live/$_activeSessionId';
      _detailedLog('WEBSOCKET', 'Connecting to: $wsUrl');

      await _closeWebSocketConnection();
  
      // PERBAIKAN: Enhanced WebSocket connection dengan proper headers
      final socket = await WebSocket.connect(
        wsUrl,
        headers: {
          'User-Agent': 'Flutter-WebSocket-Client/1.0',
          'Origin': 'flutter-app',
        },
      ).timeout(_websocketTimeout);

      _webSocketChannel = IOWebSocketChannel(socket);
      _detailedLog('WEBSOCKET', 'WebSocket connected successfully');

      // PERBAIKAN: Connection timeout handler
      _connectionTimeoutTimer = Timer(_websocketTimeout, () {
        if (!_isWebSocketConnected) {
          _detailedLog('WEBSOCKET', 'Connection timeout');
          _handleWebSocketError('Connection timeout');
        }
      });

      // PERBAIKAN: Enhanced stream listener
      _webSocketChannel!.stream.listen(
        (data) {
          _connectionTimeoutTimer?.cancel();
          
          if (!_isWebSocketConnected) {
            _isWebSocketConnected = true;
            _reconnectAttempts = 0;
            _detailedLog('WEBSOCKET', 'Connected successfully');
            _startHeartbeat();
            
            // Send initial handshake
            _sendWebSocketMessage({
              'type': 'connect',
              'session_id': _activeSessionId,
              'client_type': 'flutter_stt',
            });
            
            if (mounted) setState(() {});
          }

          _handleWebSocketMessage(data);
        },
        onError: (error) {
          _connectionTimeoutTimer?.cancel();
          _detailedLog('WEBSOCKET', 'Stream error: $error');
          _handleWebSocketError(error);
        },
        onDone: () {
          _connectionTimeoutTimer?.cancel();
          _detailedLog('WEBSOCKET', 'Connection closed');
          _isWebSocketConnected = false;
          if (mounted) setState(() {});
          
          // Auto-reconnect logic
          if (_isSessionActive && _reconnectAttempts < _maxRetryAttempts) {
            _attemptReconnection();
          }
        },
        cancelOnError: false,
      );

    } catch (e) {
      _connectionTimeoutTimer?.cancel();
      _detailedLog('WEBSOCKET', 'Connection failed: $e');
      _isWebSocketConnected = false;
      _handleWebSocketError(e);
      if (mounted) setState(() {});
    }
  }


void _handleWebSocketMessage(dynamic data) {
    try {
      String messageString;
      if (data is String) {
        messageString = data;
      } else {
        messageString = data.toString();
      }
      
      final messageData = jsonDecode(messageString);
      _detailedLog('WEBSOCKET_RECEIVE', 'Message: ${jsonEncode(messageData)}');

      final messageType = messageData['type'];

      switch (messageType) {
        case 'connection_ack':
        case 'connected':
          _detailedLog('WEBSOCKET', 'Connection acknowledged');
          break;

        case 'transcript_result':
          _detailedLog('WEBSOCKET_RECEIVE', 'Transcript result received');
          _handleTranscriptResult(messageData);
          _successfulAPIResponses++;
          
          // TARTEEL-STYLE: Handle real-time feedback dari backend
          if (messageData.containsKey('real_time_feedback')) {
            _handleRealTimeFeedback(messageData['real_time_feedback']);
          }
          
          // Handle alignment results untuk word-by-word feedback
          if (messageData.containsKey('alignment')) {
            _handleAlignmentResults(messageData['alignment']);
          }
          break;
          
        case 'partial_transcript':
          final transcript = messageData['transcript'] ?? '';
          _detailedLog('WEBSOCKET_RECEIVE', 'Partial transcript: "$transcript"');
          if (transcript.isNotEmpty) {
            setState(() {
              _liveTranscript = transcript;
            });
            _detailedLog('UI_UPDATE', 'Updated live transcript: "$transcript"');
          }
          break;
          
        case 'final_transcript':
          _detailedLog('WEBSOCKET_RECEIVE', 'Final transcript: ${messageData['transcript'] ?? 'empty'}');
          if (messageData['transcript'] != null) {
            setState(() {
              _liveTranscript = messageData['transcript'];
              _confirmedTranscript = messageData['transcript'];
            });
          }
          break;

        case 'word_result':
        case 'word_feedback':
          _handleWordFeedback(messageData);
          break;

        case 'session_update':
          _handleSessionUpdate(messageData);
          break;

        case 'error':
          final errorMsg = messageData['message'] ?? 'Unknown WebSocket error';
          _detailedLog('WEBSOCKET_ERROR', 'Server error: $errorMsg');
          _showSnackBar('Server Error: $errorMsg', SnackBarType.error);
          break;

        case 'heartbeat_ack':
        case 'pong':
          _detailedLog('WEBSOCKET', 'Heartbeat acknowledged');
          break;

        // TAMBAHAN: Handler untuk message types dari backend
        case 'audio_received':
          _handleAudioReceived(messageData);
          break;

        case 'audio_processing_error':
          _handleAudioProcessingError(messageData);
          break;
          
        // ‚ö° LIVE TRANSCRIPT HANDLERS - ENHANCED!
        case 'live_transcript':
          _detailedLog('LIVE_TRANSCRIPT', 'Live partial transcript received: ${messageData['transcript']}');
          _handleLiveTranscript(messageData);
          break;
          
        case 'audio_processed':
          _detailedLog('AUDIO_PROCESSED', 'Audio processed by backend: ${messageData['whisper_result']?['text']}');
          _handleWhisperAudioProcessed(messageData);
          break;
          
        case 'whisper_transcript_result':
          _detailedLog('WHISPER_RECEIVE', 'Whisper transcript result received');
          _handleWhisperTranscriptResult(messageData);
          _successfulAPIResponses++;
          break;
          
        case 'audio_processing_error':
          _detailedLog('WHISPER_ERROR', 'Audio processing error: ${messageData['error']}');
          _handleWhisperProcessingError(messageData);
          break;

        case 'disconnect_ack':
          _detailedLog('WEBSOCKET', 'Disconnect acknowledged');
          break;

        case 'session_connected':
          _detailedLog('WEBSOCKET', 'Session connected successfully');
          break;

        case 'move_ayah_confirmed':
          _detailedLog('WEBSOCKET', 'Ayah move confirmed');
          break;

        default:
          _detailedLog('WEBSOCKET_RECEIVE', 'Unknown message type: $messageType');
      }
    } catch (e) {
      _detailedLog('WEBSOCKET_RECEIVE', 'Error parsing message: $e');
    }
  }
  // ==================== IMPROVED ERROR HANDLING ====================

  void _handleWebSocketError(dynamic error) {
    _detailedLog('WEBSOCKET', 'ERROR HANDLER: $error');
    _isWebSocketConnected = false;

    // FIX: Don't immediately reconnect, wait a bit
    if (mounted) {
      setState(() {});
    }

    // Only attempt reconnection if session is still active and we haven't exceeded max attempts
    if (_isSessionActive && _reconnectAttempts < _maxReconnectAttempts) {
      _attemptReconnection();
    } else {
      _detailedLog(
        'WEBSOCKET',
        'Max reconnection attempts reached or session inactive',
      );
      _showSnackBar(
        'WebSocket connection failed. Please restart session.',
        SnackBarType.error,
      );
    }
  }

  void _attemptReconnection() {
    if (_reconnectAttempts >= _maxReconnectAttempts || !_isSessionActive) {
      _detailedLog(
        'WEBSOCKET',
        'Max reconnection attempts reached or session inactive',
      );
      _showSnackBar(
        'WebSocket connection failed permanently',
        SnackBarType.error,
      );
      return;
    }

    _reconnectAttempts++;
    _detailedLog(
      'WEBSOCKET',
      'Attempting reconnection $_reconnectAttempts/$_maxReconnectAttempts',
    );

    _reconnectTimer?.cancel();

    // Exponential backoff: 2s, 4s, 8s
    final delaySeconds = math.pow(2, _reconnectAttempts).toInt();
    final delay = Duration(seconds: math.min(delaySeconds, 10));

    _detailedLog('WEBSOCKET', 'Reconnecting in ${delay.inSeconds}s...');

    _reconnectTimer = Timer(delay, () {
      if (_isSessionActive && mounted) {
        _detailedLog(
          'WEBSOCKET',
          'Executing reconnection attempt $_reconnectAttempts',
        );
        _initializeWebSocketConnection();
      }
    });
  }
  // ==================== IMPROVED MESSAGE SENDING ====================

  int _messageSequence = 0;

  void _sendWebSocketMessage(Map<String, dynamic> message) {
    if (!_isWebSocketConnected || _webSocketChannel == null) {
      _detailedLog('WEBSOCKET', 'Cannot send message - not connected');

      // REMOVED: No HTTP fallback, WebSocket only
      if (message['type'] == 'final_transcript') {
        _detailedLog(
          'WEBSOCKET',
          'Transcript dropped - WebSocket not connected',
        );
        _showSnackBar(
          'Transcript lost - reconnecting...',
          SnackBarType.warning,
        );

        // Attempt immediate reconnection for important messages
        if (_isSessionActive && _reconnectAttempts < _maxReconnectAttempts) {
          _initializeWebSocketConnection();
        }
      }
      return;
    }

    try {
      // Add message correlation fields
      message['seq'] = ++_messageSequence;
      message['timestamp'] = DateTime.now().toIso8601String();
      message['client_id'] = 'flutter_stt_client';

      final messageJson = jsonEncode(message);
      _webSocketChannel!.sink.add(messageJson);
      _detailedLog(
        'WEBSOCKET_SEND',
        'Message sent (seq: ${message['seq']}): $messageJson',
      );

      // Track sent messages for debugging
      _totalTranscriptsSent++;
    } catch (e) {
      _detailedLog('WEBSOCKET', 'SEND ERROR: $e');
      _isWebSocketConnected = false;
      if (mounted) setState(() {});

      // Attempt reconnection on send failure
      if (_isSessionActive) {
        _attemptReconnection();
      }
    }
  }

  // ==================== IMPROVED HEARTBEAT ====================

  void _startHeartbeat() {
    _heartbeatTimer?.cancel();

    _heartbeatTimer = Timer.periodic(Duration(seconds: 30), (timer) {
      if (!_isWebSocketConnected ||
          _webSocketChannel == null ||
          !_isSessionActive) {
        _detailedLog(
          'WEBSOCKET',
          'Stopping heartbeat - connection lost or session inactive',
        );
        timer.cancel();
        return;
      }

      // Send heartbeat
      _sendWebSocketMessage({
        'type': 'heartbeat',
        'session_id': _activeSessionId,
      });

      _detailedLog('WEBSOCKET', 'Heartbeat sent');

      // Set timeout for heartbeat response (optional)
      Timer(Duration(seconds: 10), () {
        if (_isWebSocketConnected && timer.isActive) {
          // Could check if we received heartbeat_response, but not critical
          _detailedLog(
            'WEBSOCKET',
            'Heartbeat timeout - connection may be unstable',
          );
        }
      });
    });
  }

  // ==================== SERVER-BASED STT METHODS ====================
  
  Future<void> _startAudioCapture() async {
    try {
      _detailedLog('AUDIO_CAPTURE', 'Starting real audio capture for server-based STT');
      
      // Initialize audio recorder if not already done
      if (!_isRecorderInitialized) {
        await _initializeAudioRecorder();
      }
      
      // Start recording audio stream
      await _startAudioRecording();
      
      _detailedLog('AUDIO_CAPTURE', 'Audio capture initialized successfully');
      
    } catch (e) {
      _detailedLog('AUDIO_CAPTURE', 'Failed to start audio capture: $e');
      // Fallback to test mode if audio fails
      _startTestAudioStreaming();
    }
  }
  
  Future<void> _initializeAudioRecorder() async {
    try {
      _audioRecorder = FlutterSoundRecorder();
      
      // Request permissions first
      await _audioRecorder!.openRecorder();
      
      // Set up recording session for streaming - frequent chunks like Tarteel
      await _audioRecorder!.setSubscriptionDuration(Duration(milliseconds: 100));
      
      _isRecorderInitialized = true;
      _detailedLog('AUDIO_INIT', 'Audio recorder initialized successfully for streaming');
    } catch (e) {
      _detailedLog('AUDIO_INIT', 'Failed to initialize audio recorder: $e');
      throw e;
    }
  }
  
  Future<void> _startAudioRecording() async {
    if (!_isRecorderInitialized || _audioRecorder == null) {
      throw Exception('Audio recorder not initialized');
    }
    
    try {
      // Create audio stream controller for real-time processing
      _audioStreamController = StreamController<Uint8List>.broadcast();
      
      // Listen to the audio stream
      _audioStreamSubscription = _audioStreamController!.stream.listen(
        (audioChunk) {
          _processAudioChunk(audioChunk);
        },
        onError: (error) {
          _detailedLog('AUDIO_STREAM', 'Audio stream error: $error');
        },
        onDone: () {
          _detailedLog('AUDIO_STREAM', 'Audio stream ended');
        },
      );
      
      // Start recording to stream (using proper flutter_sound API)
      await _audioRecorder!.startRecorder(
        toStream: _audioStreamController!.sink,
        codec: Codec.pcm16, // Use raw PCM16 format as expected by Vosk
        sampleRate: 16000,
        numChannels: 1,
        // Remove bitRate for PCM format
      );
      
      // Also listen to audio levels for UI feedback
      _audioLevelSubscription = _audioRecorder!.onProgress!.listen(
        (data) {
          if (mounted) {
            setState(() {
              _audioLevel = data.decibels ?? 0.0;
            });
          }
          
          // Update audio level history for VAD
          _audioLevelHistory.add(data.decibels ?? 0.0);
          if (_audioLevelHistory.length > _audioHistoryLength) {
            _audioLevelHistory.removeAt(0);
          }
          
          // Calculate average for VAD
          if (_audioLevelHistory.isNotEmpty) {
            _averageAudioLevel = _audioLevelHistory.reduce((a, b) => a + b) / _audioLevelHistory.length;
          }
          
          // Voice Activity Detection
          _performVAD(data.decibels ?? 0.0);
        },
        onError: (error) {
          _detailedLog('AUDIO_LEVEL', 'Audio level error: $error');
        },
      );
      
      _detailedLog('AUDIO_RECORDING', 'Real audio recording started with streaming (16kHz, PCM16)');
    } catch (e) {
      _detailedLog('AUDIO_RECORDING', 'Failed to start audio recording: $e');
      throw e;
    }
  }
  
  void _processAudioChunk(Uint8List audioData) {
    if (!_isListening) {
      return; // Only check if listening, allow processing without WebSocket
    }
    
    try {
      // üîç DEBUG: Check if audio data contains actual sound
      bool hasAudio = false;
      int nonZeroSamples = 0;
      
      // Check for non-zero samples in the audio data
      for (int i = 0; i < audioData.length; i++) {
        if (audioData[i] != 0) {
          nonZeroSamples++;
          hasAudio = true;
        }
      }
      
      // Calculate audio "energy" to detect actual sound
      double audioEnergy = 0.0;
      if (audioData.length >= 2) {
        // Convert bytes to 16-bit PCM samples and calculate RMS energy
        for (int i = 0; i < audioData.length - 1; i += 2) {
          int sample = (audioData[i + 1] << 8) | audioData[i]; // Little-endian 16-bit
          if (sample > 32767) sample -= 65536; // Convert to signed
          audioEnergy += sample * sample;
        }
        audioEnergy = audioEnergy / (audioData.length / 2);
        audioEnergy = audioEnergy > 0 ? (10 * (audioEnergy / 32768.0).abs()).clamp(0, 100) : 0;
      }
      
      // üîç DEBUG: Log audio analysis every 20 chunks
      if (_totalTranscriptsSent % 20 == 0) {
        _detailedLog('AUDIO_DEBUG', 
          'Chunk #${_totalTranscriptsSent}: ${audioData.length} bytes, $nonZeroSamples non-zero samples (${(nonZeroSamples/audioData.length*100).toStringAsFixed(1)}%), Energy: ${audioEnergy.toStringAsFixed(2)}');
      }
      
      // FIXED: Send audio chunks via WebSocket if connected, else use HTTP fallback
      if (_isWebSocketConnected && _webSocketChannel != null) {
        // Send via WebSocket
        try {
          // Send binary audio data directly to WebSocket (backend expects bytes)
          _webSocketChannel!.sink.add(audioData);
          _totalTranscriptsSent++;
          
          _detailedLog('AUDIO_CHUNK', 'Sent ${audioData.length} bytes directly as binary data');
        } catch (e) {
          _detailedLog('AUDIO_CHUNK', 'Failed to send binary audio: $e');
          
          // Fallback: Send as JSON with base64
          final base64Audio = base64Encode(audioData);
          final audioMessage = {
            'type': 'audio_chunk',
            'session_id': _activeSessionId,
            'audio_data': base64Audio,
            'format': 'pcm16',
            'sample_rate': 16000,
            'channels': 1,
            'timestamp': DateTime.now().toIso8601String(),
            'voice_active': _isVoiceActive,
            'audio_level': _audioLevel,
            'chunk_size': audioData.length,
            'has_audio': hasAudio,
            'audio_energy': audioEnergy,
            'non_zero_samples': nonZeroSamples,
          };
          
          _sendWebSocketMessage(audioMessage);
          _detailedLog('AUDIO_CHUNK', 'Sent as JSON fallback: ${audioData.length} bytes');
        }
        
        // Enhanced debugging
        if (_totalTranscriptsSent % 50 == 0) { // Every 50 chunks
          _detailedLog('AUDIO_CHUNK', 'Sent ${_totalTranscriptsSent} audio chunks to server via WebSocket');
        }
        
        // üîç CRITICAL: Log audio quality every 10th chunk
        if (_totalTranscriptsSent % 10 == 0) {
          _detailedLog('AUDIO_CHUNK', 'Chunk #${_totalTranscriptsSent}: ${audioData.length} bytes (Level: ${_audioLevel.toStringAsFixed(1)}dB, Energy: ${audioEnergy.toStringAsFixed(2)}, HasAudio: $hasAudio)');
        }
      } else {
        // NO WEBSOCKET: Retry connection and skip this chunk
        _detailedLog('AUDIO_FALLBACK', 'WebSocket not connected, will retry connection');
        
        // Attempt to reconnect WebSocket for real-time functionality
        if (_isSessionActive && _reconnectAttempts < _maxReconnectAttempts) {
          _detailedLog('WEBSOCKET_RETRY', 'Attempting to reconnect WebSocket for real-time audio');
          _initializeWebSocketConnection();
        }
        // Send silence detection to backend
        if (_silenceFrameCount % 10 == 0) { // Every 1 second
          _sendWebSocketMessage({
            'type': 'silence_detected',
            'session_id': _activeSessionId,
            'audio_level': _audioLevel,
            'timestamp': DateTime.now().toIso8601String(),
          });
        }
      }
    } catch (e) {
      _detailedLog('AUDIO_CHUNK', 'Failed to process audio chunk: $e');
    }
  }
  
  void _performVAD(double currentLevel) {
    // Enhanced Voice Activity Detection for Arabic recitation - ULTRA SENSITIVE
    final threshold = _averageAudioLevel - 5.0; // Very sensitive threshold
    
    if (currentLevel > threshold && currentLevel > -60.0) { // Very low threshold for Arabic
      // Voice detected
      _voiceFrameCount++;
      _silenceFrameCount = 0;
      
      if (_voiceFrameCount >= _minVoiceFrames && !_isVoiceActive) {
        _isVoiceActive = true;
        _detailedLog('VAD', 'Voice activity started (${currentLevel.toStringAsFixed(1)}dB)');
        
        // Send voice activity start to backend
        if (_isWebSocketConnected) {
          _sendWebSocketMessage({
            'type': 'voice_activity_start',
            'session_id': _activeSessionId,
            'audio_level': currentLevel,
            'timestamp': DateTime.now().toIso8601String(),
          });
        }
      }
    } else {
      // Silence detected
      _silenceFrameCount++;
      _voiceFrameCount = 0;
      
      if (_silenceFrameCount >= _maxSilenceFrames && _isVoiceActive) {
        _isVoiceActive = false;
        _detailedLog('VAD', 'Voice activity ended (${currentLevel.toStringAsFixed(1)}dB)');
        
        // Send voice activity end to backend
        if (_isWebSocketConnected) {
          _sendWebSocketMessage({
            'type': 'voice_activity_end',
            'session_id': _activeSessionId,
            'audio_level': currentLevel,
            'timestamp': DateTime.now().toIso8601String(),
          });
        }
      }
    }
    
    // Update UI with voice activity state
    if (mounted) {
      setState(() {});
    }
  }
  
  Future<void> _stopAudioRecording() async {
    try {
      // Stop audio recorder
      if (_audioRecorder != null && _isRecorderInitialized) {
        await _audioRecorder!.stopRecorder();
      }
      
      // Cancel all audio subscriptions
      _audioStreamSubscription?.cancel();
      _audioStreamSubscription = null;
      
      _audioLevelSubscription?.cancel();
      _audioLevelSubscription = null;
      
      // Close audio stream controller
      _audioStreamController?.close();
      _audioStreamController = null;
      
      // Reset voice activity state
      _isVoiceActive = false;
      _audioLevel = 0.0;
      _voiceFrameCount = 0;
      _silenceFrameCount = 0;
      
      _detailedLog('AUDIO_STOP', 'Audio recording stopped and streams cleaned up');
    } catch (e) {
      _detailedLog('AUDIO_STOP', 'Error stopping audio recording: $e');
    }
  }
  
  void _startTestAudioStreaming() {
    // Send test transcript messages to verify STT processing
    _detailedLog('STT_TEST', 'Starting test audio streaming mode');
    
    Timer.periodic(Duration(seconds: 5), (timer) {
      if (!_isListening || !_isWebSocketConnected) {
        timer.cancel();
        return;
      }
      
      // Send test Arabic transcript to backend for processing
      _sendWebSocketMessage({
        'type': 'final_transcript',
        'session_id': _activeSessionId,
        'transcript': 'ÿ®ÿ≥ŸÖ ÿßŸÑŸÑŸá ÿßŸÑÿ±ÿ≠ŸÖŸÜ ÿßŸÑÿ±ÿ≠ŸäŸÖ', // Test Arabic text
        'surah_id': widget.suratId,
        'ayah': _currentAyatNumber,
        'timestamp': DateTime.now().toIso8601String(),
      });
      
      _detailedLog('STT_TEST', 'Test Arabic transcript sent: ÿ®ÿ≥ŸÖ ÿßŸÑŸÑŸá ÿßŸÑÿ±ÿ≠ŸÖŸÜ ÿßŸÑÿ±ÿ≠ŸäŸÖ');
    });
  }
  
  // Add manual test method
  void _sendTestTranscript() {
    if (!_isWebSocketConnected) {
      _detailedLog('STT_TEST', 'WebSocket not connected - cannot send test');
      _showSnackBar('WebSocket not connected', SnackBarType.warning);
      return;
    }
    
    // Send a more comprehensive test
    final testTranscripts = [
      'ÿ®ÿ≥ŸÖ ÿßŸÑŸÑŸá ÿßŸÑÿ±ÿ≠ŸÖŸÜ ÿßŸÑÿ±ÿ≠ŸäŸÖ',
      'ÿßŸÑÿ≠ŸÖÿØ ŸÑŸÑŸá ÿ±ÿ® ÿßŸÑÿπÿßŸÑŸÖŸäŸÜ', 
      'ÿßŸÑÿ±ÿ≠ŸÖŸÜ ÿßŸÑÿ±ÿ≠ŸäŸÖ',
      'ŸÖÿßŸÑŸÉ ŸäŸàŸÖ ÿßŸÑÿØŸäŸÜ'
    ];
    
    final testTranscript = testTranscripts[DateTime.now().second % testTranscripts.length];
    
    // üïå MEMORY: Send transcript using Memory API format
    if (_isSessionActive && _activeSessionId != null) {
      _sendTranscriptToAPI(testTranscript);
    } else {
      _detailedLog('STT_TEST', 'Cannot send test transcript - no active session');
      _showSnackBar('No active session', SnackBarType.warning);
    }
    
    _detailedLog('STT_TEST', 'Manual test transcript sent: $testTranscript');
    _showSnackBar('Test sent: $testTranscript', SnackBarType.info);
  }

  // üïå TARTEEL: Enhanced transcript sending
  void _sendTarteelTranscript(String transcript, bool isFinal) {
    if (!_isWebSocketConnected || _tarteelSessionId == null) {
      _detailedLog('TARTEEL', 'Cannot send transcript - not connected');
      return;
    }

    final message = {
      'type': 'transcript',
      'text': transcript,
      'is_final': isFinal,
      'confidence': 0.95,
      'audio_duration': 2.0,
      'timestamp': DateTime.now().toIso8601String(),
    };

    _sendTarteelMessage(message);
    _detailedLog('TARTEEL', 'Transcript sent: $transcript (final: $isFinal)');
  }

  // ==================== IMPROVED STT METHODS ====================

  Future<void> _startContinuousListening() async {
    if (_isListening) {
      _detailedLog('STT', 'Already listening, ignoring start request');
      return;
    }
    
    // üî• START SIMULATED WORD PROGRESSION for testing
    _startSimulatedWordProgression();

    // For server-based STT, we don't need local VOSK initialization
    // The backend handles all STT processing
    _detailedLog('STT', 'Using server-based STT - no local engine check needed');

    try {
      // Step 1: Initialize API session if not active
      if (!_isSessionActive) {
        _detailedLog('STT', 'Starting API session before STT');
        await _initializeAPISession();
        if (!_isSessionActive) {
          _showSnackBar('Failed to start API session', SnackBarType.error);
          return;
        }
      }

      // Step 2: Initialize WebSocket connection
      if (!_isWebSocketConnected) {
        _detailedLog('STT', 'Initializing WebSocket connection');
        await _initializeWebSocketConnection();
        // Don't fail if WebSocket doesn't connect - use HTTP fallback
      }

      _detailedLog('STT', 'Starting continuous listening session');

      setState(() {
        _isListening = true;
        _liveTranscript = '';
        _currentPartialTranscript = '';
        _lastSentTranscript = '';
      });

      // Step 3: For server-based STT, we use audio capture instead of local VOSK
      // Set up audio capture using flutter_sound (already in dependencies)
      _detailedLog('STT', 'Starting audio capture for server-based STT');
      
      // Initialize audio capture and streaming to WebSocket
      await _startAudioCapture();

      // Step 7: Start continuous processing timers
      _startContinuousProcessingTimers();

      _detailedLog('STT', 'Continuous listening started successfully');
      _showSnackBar(
        'Listening started - Continuous mode',
        SnackBarType.success,
      );
    } catch (e) {
      _detailedLog('STT', 'CRITICAL ERROR starting continuous listening: $e');
      setState(() {
        _isListening = false;
      });
      _showSnackBar(
        'Failed to start continuous listening: $e',
        SnackBarType.error,
      );
    }
  }

  void _startContinuousProcessingTimers() {
    // Timer 1: Continuous transcript processing
    _transcriptSendTimer = Timer.periodic(Duration(milliseconds: 1000), (
      timer,
    ) {
      if (!_isListening) {
        timer.cancel();
        return;
      }

      // Send accumulated final transcripts to API
      if (_liveTranscript.isNotEmpty &&
          _liveTranscript != _lastSentTranscript &&
          _liveTranscript.trim().length > 2) {
        _sendFinalTranscript(_liveTranscript);
      }
    });

    // Timer 2: Partial transcript updates
    _partialUpdateTimer = Timer.periodic(Duration(milliseconds: 300), (timer) {
      if (!_isListening) {
        timer.cancel();
        return;
      }

      // Send partial transcripts for real-time feedback
      if (_currentPartialTranscript.isNotEmpty) {
        _sendPartialTranscript(_currentPartialTranscript);
      }
    });

    // Timer 3: Connection health check
    Timer.periodic(Duration(seconds: 5), (timer) {
      if (!_isListening) {
        timer.cancel();
        return;
      }

      // Check WebSocket health and reconnect if needed
      if (!_isWebSocketConnected && _isSessionActive) {
        _detailedLog('STT', 'WebSocket disconnected, attempting reconnection');
        _initializeWebSocketConnection();
      }
    });
  }

  void _handlePartialTranscript(String partialJson) {
    try {
      final result = jsonDecode(partialJson);
      final partialText = result['partial']?.toString().trim() ?? '';

      if (partialText.isNotEmpty && partialText != _currentPartialTranscript) {
        _detailedLog('STT_PARTIAL', 'New partial: "$partialText"');

        setState(() {
          _currentPartialTranscript = partialText;
          // Update live display for user feedback
          if (partialText.length > _liveTranscript.length) {
            _liveTranscript = partialText;
          }
        });
      }
    } catch (e) {
      _detailedLog('STT_PARTIAL', 'Error parsing partial result: $e');
    }
  }

  void _handleFinalTranscript(String resultJson) {
    try {
      final result = jsonDecode(resultJson);
      final finalText = result['text']?.toString().trim() ?? '';

      if (finalText.isNotEmpty) {
        _detailedLog('STT_FINAL', 'Final transcript: "$finalText"');

        setState(() {
          _liveTranscript = finalText;
          _currentPartialTranscript = '';
        });

        // Immediately send final transcript to API
        _sendFinalTranscript(finalText);
      }
    } catch (e) {
      _detailedLog('STT_FINAL', 'Error parsing final result: $e');
    }
  }

  // ==================== IMPROVED TRANSCRIPT HANDLING ====================

  String _normalizeTranscript(String text) {
    return text
        .trim()
        .replaceAll(
          RegExp(
            r'[^\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\uFB50-\uFDFF\uFE70-\uFEFF\s]',
          ),
          '',
        ) // Keep only Arabic + spaces
        .replaceAll(RegExp(r'\s+'), ' ') // Normalize multiple spaces
        .toLowerCase();
  }

  // REPLACE method: _sendFinalTranscript()
void _sendFinalTranscript(String transcript) {
    if (transcript.trim().isEmpty) return;

    final normalizedTranscript = _normalizeTranscript(transcript);
    final normalizedLast = _normalizeTranscript(_lastSentTranscript);

    if (normalizedTranscript == normalizedLast || normalizedTranscript.length < 3) {
      _detailedLog('TRANSCRIPT_SEND', 'Skipping duplicate: "$transcript"');
      return;
    }

    _detailedLog('TRANSCRIPT_SEND', 'Sending: "$transcript"');
    _detailedLog('TRANSCRIPT_SEND', 'WebSocket status: connected=$_isWebSocketConnected, channel=${_webSocketChannel != null}');

    // WebSocket-first approach with HTTP fallback
    if (_isWebSocketConnected && _webSocketChannel != null) {
      // Primary: Send via WebSocket
      _sendWebSocketMessage({
        'type': 'final_transcript',
        'session_id': _activeSessionId,
        'transcript': transcript,
        'surah_id': widget.suratId,
        'ayah': _currentAyatNumber,
        'timestamp': DateTime.now().toIso8601String(),
      });
      
      _lastSentTranscript = transcript;
      _totalTranscriptsSent++;
      _detailedLog('TRANSCRIPT_SEND', 'Sent via WebSocket: "$transcript"');
      
    } else {
      // HTTP fallback
      _detailedLog('TRANSCRIPT_SEND', 'WebSocket not connected, using HTTP fallback');
      _sendTranscriptViaHTTP(transcript);
    }
  }

  // TAMBAH method baru untuk HTTP fallback:
  Future<void> _sendTranscriptViaHTTP(String transcript) async {
    try {
      _detailedLog('HTTP_FALLBACK', 'Sending transcript via HTTP: "$transcript"');
      
      final requestBody = {
        'transcript': transcript,
        'surah_id': widget.suratId,
        'ayah': _currentAyatNumber,
        'session_id': _activeSessionId,
        'user_id': 'flutter_app_${DateTime.now().millisecondsSinceEpoch}',
      };

      final response = await http
          .post(
            Uri.parse('$MEMORY_API_URL/transcript'),
            headers: {
              'Content-Type': 'application/json',
              'Accept': 'application/json',
              'ngrok-skip-browser-warning': 'true',
            },
            body: jsonEncode(requestBody),
          )
          .timeout(_apiTimeout);

      if (response.statusCode >= 200 && response.statusCode < 300) {
        final responseData = jsonDecode(response.body);
        _handleTranscriptResult(responseData);
        _successfulAPIResponses++;
        _lastSentTranscript = transcript;
        _totalTranscriptsSent++;
        
        _detailedLog('HTTP_FALLBACK', 'Success: ${response.body}');
        _logAPICall('POST', '/transcript', response.statusCode, 'Success');
      } else {
        throw Exception('HTTP ${response.statusCode}: ${response.body}');
      }
    } catch (e) {
      _detailedLog('HTTP_FALLBACK', 'Failed: $e');
      _logAPICall('POST', '/transcript', 0, 'Error: $e');
      _showSnackBar('Failed to send transcript', SnackBarType.error);
    }
  }

  Timer? _partialDebounceTimer;

  // REPLACE method: _sendPartialTranscript()
  void _sendPartialTranscript(String transcript) {
    if (transcript.trim().isEmpty || !_isWebSocketConnected) {
      return;
    }

    // Cancel previous debounce timer
    _partialDebounceTimer?.cancel();

    // DEBOUNCE: Only send if transcript changed significantly
    _partialDebounceTimer = Timer(Duration(milliseconds: 500), () {
      if (_isWebSocketConnected && transcript.trim().isNotEmpty) {
        _sendWebSocketMessage({
          'type': 'partial_transcript',
          'session_id': _activeSessionId,
          'transcript': transcript,
          'surah_id': widget.suratId,
          'ayah': _currentAyatNumber,
        });

        _detailedLog(
          'WEBSOCKET_SEND',
          'Partial transcript sent: "$transcript"',
        );
      }
    });
  }

  // ==================== HTTP FALLBACK METHOD ====================

  // ==================== IMPROVED CONNECTION CLEANUP ====================

  Future<void> _closeWebSocketConnection() async {
    _heartbeatTimer?.cancel();
    _reconnectTimer?.cancel();
    _connectionTimeoutTimer?.cancel();

    if (_webSocketChannel != null) {
      try {
        // Send close message before closing
        if (_isWebSocketConnected) {
          _sendWebSocketMessage({
            'type': 'disconnect',
            'session_id': _activeSessionId,
            'reason': 'client_disconnect',
          });

          // Wait a bit for message to be sent
          await Future.delayed(Duration(milliseconds: 200));
        }

        await _webSocketChannel!.sink.close(status.normalClosure);
        _detailedLog('WEBSOCKET', 'Connection closed gracefully');
      } catch (e) {
        _detailedLog('WEBSOCKET', 'Error closing connection: $e');
      }
      _webSocketChannel = null;
    }

    _isWebSocketConnected = false;
    _reconnectAttempts = 0;
  }

  void _startContinuousProcessing() {
    // Continuous processing timer for UI updates
    _partialUpdateTimer = Timer.periodic(Duration(milliseconds: 100), (timer) {
      if (!_isListening) {
        timer.cancel();
        return;
      }
      // Update UI if needed
      if (mounted) {
        setState(() {});
      }
    });

    // Transcript send timer (for final transcripts)
    _transcriptSendTimer = Timer.periodic(Duration(milliseconds: 500), (timer) {
      if (!_isListening) {
        timer.cancel();
        return;
      }

      // Process any pending final transcripts
      if (_liveTranscript.isNotEmpty &&
          _liveTranscript != _lastSentTranscript) {
        _sendFinalTranscript(_liveTranscript);
      }
    });
  }

  Future<void> _stopContinuousListening() async {
    if (!_isListening) {
      _detailedLog('STT', 'Not listening, ignoring stop request');
      return;
    }

    _detailedLog('STT', 'Stopping continuous listening');

    try {
      setState(() {
        _isListening = false;
      });

      // Stop timers
      _transcriptSendTimer?.cancel();
      _partialUpdateTimer?.cancel();
      
      // Stop simulated progression
      _stopSimulatedWordProgression();

      // Stop audio recording
      await _stopAudioRecording();

      // Stop speech service
      if (_speechService != null) {
        await _speechService!.stop();
        _speechService = null;
      }

      // Send stop message via WebSocket
      if (_isWebSocketConnected) {
        _sendWebSocketMessage({
          'type': 'stop_listening',
          'session_id': _activeSessionId,
          'timestamp': DateTime.now().toIso8601String(),
        });
      }

      _detailedLog('STT', 'Continuous listening stopped successfully');
      _showSnackBar('Listening stopped', SnackBarType.info);
    } catch (e) {
      _detailedLog('STT', 'Error stopping listening: $e');
    }
  }

  // ==================== ENHANCED API RESPONSE HANDLERS ====================

  void _handleTranscriptResult(Map<String, dynamic> data) {
    _detailedLog(
      'API_RESPONSE',
      'Processing transcript result: ${jsonEncode(data)}',
    );

    try {
      // Check if response follows API docs structure
      if (data.containsKey('success') && data['success'] == true) {
        // Process results array according to API docs
        if (data.containsKey('results') && data['results'] is List) {
          final results = data['results'] as List;
          final wordResults = results
              .map((r) => APIWordResult.fromJson(r))
              .toList();

          setState(() {
            _currentAyatResults = wordResults;
          });

          _detailedLog(
            'API_RESPONSE',
            'Processed ${wordResults.length} word results',
          );

          // Process summary data
          if (data.containsKey('summary') && data['summary'] != null) {
            final summary = data['summary'] as Map<String, dynamic>;
            _updateAyatProgress(summary, wordResults);
            _detailedLog('API_RESPONSE', 'Summary: ${jsonEncode(summary)}');
          }

          // Update UI with results
          _updateUIWithResults(wordResults, data['summary']);

          // Handle completion status from backend if present
          if (data.containsKey('completion_status')) {
            final completionStatus = data['completion_status'];
            _detailedLog('API_RESPONSE', 'Completion status: ${jsonEncode(completionStatus)}');
          }

          // Handle visual indicators from backend if present
          if (data.containsKey('visual_indicators')) {
            final visualIndicators = data['visual_indicators'];
            _detailedLog('API_RESPONSE', 'Visual indicators: ${jsonEncode(visualIndicators)}');
          }

          // Auto-move to next ayat if completion criteria met
          if (_autoMoveEnabled &&
              _isAyatCompleted(wordResults, data['summary'])) {
            _showSimpleCompletionCelebration();
            _autoMoveToNextAyat();
          }
        } else {
          _detailedLog('API_RESPONSE', 'No results array in response');
        }

        // Show success message if available
        if (data.containsKey('message')) {
          _detailedLog('API_RESPONSE', 'API Message: ${data['message']}');
        }
      } else {
        _detailedLog(
          'API_RESPONSE',
          'API returned success=false or missing success field',
        );
        if (data.containsKey('message')) {
          _showSnackBar('API Error: ${data['message']}', SnackBarType.error);
        }
      }
    } catch (e) {
      _detailedLog('API_RESPONSE', 'Error processing transcript result: $e');
      _showSnackBar('Error processing API response', SnackBarType.error);
    }
  }

  void _updateAyatProgress(
    Map<String, dynamic> summary,
    List<APIWordResult> results,
  ) {
    final matched = summary['matched'] ?? 0;
    final mismatched = summary['mismatched'] ?? 0;
    final skipped = summary['skipped'] ?? 0;
    final total = summary['total'] ?? results.length;

    final completionPercentage = total > 0 ? (matched / total) * 100.0 : 0.0;
    final isCompleted =
        completionPercentage >= 80.0; // 80% threshold for completion

    final progress = AyatProgress(
      ayatIndex: _currentAyatIndex,
      totalWords: total,
      correctWords: matched,
      errorWords: mismatched,
      skippedWords: skipped,
      completionPercentage: completionPercentage,
      isCompleted: isCompleted,
    );

    setState(() {
      _ayatProgress[_currentAyatIndex] = progress;
    });

    _detailedLog(
      'PROGRESS',
      'Ayat ${_currentAyatNumber}: ${completionPercentage.toStringAsFixed(1)}% '
          '($matched/$total words) - ${isCompleted ? 'COMPLETED' : 'IN_PROGRESS'}',
    );
  }

  // ==================== 9. AUTO-MOVE FUNCTIONALITY ====================

  // ADD: Auto-move configuration

  double _autoMoveThreshold = 0.8; // 80% completion threshold

  /// üïå TARTEEL-STYLE: Enhanced ayah completion check with 70% threshold
  bool _isAyatCompleted(
    List<APIWordResult> results,
    Map<String, dynamic>? summary,
  ) {
    if (summary == null) return false;

    final matched = summary['matched'] ?? 0;
    final total = summary['total'] ?? results.length;

    if (total == 0) return false;

    final completionRate = matched / total;
    
    // üéØ TARTEEL: Use 70% threshold for auto-advance
    return completionRate >= 0.7;
  }
  
  
  /// üéØ TARTEEL: Advance to next ayah when correctly recited
  void _advanceToNextAyat() {
    if (_currentAyatIndex < _ayatList.length - 1) {
      _detailedLog('TARTEEL_ADVANCE', '‚úÖ Advancing to next ayah - correctly recited $_currentAyatNumber');
      
      setState(() {
        _currentAyatIndex++;
        _currentAyatNumber = _ayatList[_currentAyatIndex].ayah;
        _currentAyatResults.clear();
        _liveTranscript = '';
        _confirmedTranscript = '';
        _lastSentTranscript = '';
        _wordHighlights.clear();
        _wordStatus.clear();
        _revealedWords.clear();
        _currentMistakes = null;
        _encouragementMessage = '';
        _isAyahCompleted = false;
      });
      
      _showSnackBar('‚è≠Ô∏è Skipped to Ayah $_currentAyatNumber', SnackBarType.info);
      
      // üïå TARTEEL: Send skip command to backend if in Tarteel mode
      if (_isTarteelMode && _tarteelSessionId != null) {
        _sendTarteelMessage({
          'type': 'skip_ayah',
          'session_id': _tarteelSessionId,
          'current_ayah': _currentAyatNumber,
          'reason': 'no_input'
        });
      }
    }
  }

  void _autoMoveToNextAyat() {
    // üéØ TARTEEL: Only advance when correctly recited (70%+ match)
    if (!_autoMoveEnabled && !_autoAdvanceEnabled) {
      _detailedLog('AUTO_MOVE', 'Auto-move disabled, staying on current ayat');
      return;
    }

    // Check if current ayah was correctly recited (70%+ completion)
    if (_completionPercentage >= 0.7) {
      _detailedLog('AUTO_MOVE', '‚úÖ Ayah correctly recited (${(_completionPercentage * 100).toStringAsFixed(1)}%) - advancing to next');
      
      if (_currentAyatIndex < _ayatList.length - 1) {
        Timer(Duration(seconds: 2), () {
          // üïå TARTEEL: Send move command to appropriate backend
          if (_isTarteelMode && _tarteelSessionId != null) {
            _moveTarteelToNextAyat();
          } else {
            _moveToNextAyatViaAPI();
          }

          setState(() {
            _currentAyatIndex++;
            _currentAyatNumber = _ayatList[_currentAyatIndex].ayah;
            _currentAyatResults.clear();
            // üïå TARTEEL: Reset Tarteel-specific state
            _revealedWords.clear();
            _currentMistakes = null;
            _encouragementMessage = '';
            _isAyahCompleted = false;
            // Reset transcript for new ayat
            _liveTranscript = '';
            _lastSentTranscript = '';
            
            // Update target ayah for comparison
            if (_ayatList.isNotEmpty && _currentAyatIndex < _ayatList.length) {
              final currentAyat = _ayatList[_currentAyatIndex];
              _targetAyahNumber = currentAyat.ayah; // Update target ayah number
              _targetAyahText = currentAyat.arabic;
              _targetWords = currentAyat.arabic.split(' ')
                  .where((w) => w.trim().isNotEmpty)
                  .toList();
              _detailedLog('TARTEEL_TARGET', 'Updated target ayah in auto-move: ${currentAyat.ayah} - ${currentAyat.arabic}');
            }
          });

          _detailedLog('AUTO_MOVE', 'üîÑ Moved to next ayat: $_currentAyatNumber (${_currentAyatIndex + 1}/${_ayatList.length})');
          
          // üïå TARTEEL: Enhanced navigation with visual feedback
          _performIntelligentNavigation();
          
          // Update encouragement message for new ayah
          setState(() {
            _encouragementMessage = 'üìñ Now reading Ayah $_currentAyatNumber';
          });
          
          _showSnackBar(
            'üîÑ Auto-moved to Ayah $_currentAyatNumber',
            SnackBarType.success,
          );
          
          // Continue listening for the new ayat
        });
      } else {
        _detailedLog('AUTO_MOVE', 'üìñ Last ayah reached - session complete');
        _showSnackBar('üìñ Last ayah reached - session complete', SnackBarType.info);
      }
    } else {
      _detailedLog('AUTO_MOVE', '‚è≥ Ayah not correctly recited (${(_completionPercentage * 100).toStringAsFixed(1)}%) - showing real-time feedback');
      // Don't show warning message, let real-time feedback handle it
    }
  }

  // üïå TARTEEL: Move to next ayat via Tarteel WebSocket
  void _moveTarteelToNextAyat() {
    if (_tarteelSessionId == null || !_isWebSocketConnected) {
      _detailedLog('TARTEEL_MOVE', 'Cannot move - no Tarteel session or WebSocket');
      return;
    }

    final nextAyah = _currentAyatNumber + 1;
    _sendTarteelMessage({
      'type': 'move_ayah',
      'ayah': nextAyah,
      'position': 0,
      'reset_progress': true,
    });

    _detailedLog('TARTEEL_MOVE', 'Sent move command to Tarteel backend: ayah $nextAyah');
  }

  // ADD: Server synchronization for ayat movement
  Future<void> _moveToNextAyatViaAPI() async {
    if (!_isSessionActive || _activeSessionId == null) return;

    try {
      final response = await http
          .patch(
            Uri.parse('$API_BASE_URL/live/move/$_activeSessionId'),
            headers: {
              'Content-Type': 'application/json',
              'ngrok-skip-browser-warning': 'true',
            },
            body: jsonEncode({'ayah': _currentAyatNumber, 'position': 0}),
          )
          .timeout(Duration(seconds: 5));

      if (response.statusCode == 200) {
        _detailedLog('API_MOVE', 'Server synchronized with ayat movement');
      } else {
        _detailedLog(
          'API_MOVE',
          'Failed to sync ayat movement: ${response.body}',
        );
      }
    } catch (e) {
      _detailedLog('API_MOVE', 'Error syncing ayat movement: $e');
    }
  }

  void _handleRealTimeFeedback(Map<String, dynamic> feedbackData) {
    _detailedLog('REAL_TIME_FEEDBACK', 'Processing real-time feedback: ${jsonEncode(feedbackData)}');
    
    try {
      setState(() {
        _wordsMatched = feedbackData['words_matched'] ?? 0;
        _wordsError = feedbackData['words_error'] ?? 0;
        _wordsSkipped = feedbackData['words_skipped'] ?? 0;
        _completionPercentage = (feedbackData['completion_percentage'] ?? 0.0).toDouble();
        _overallStatus = feedbackData['overall_status'] ?? 'processing';
      });
      
      // Show real-time progress like Tarteel
      final statusMessage = _getStatusMessage();
      if (statusMessage.isNotEmpty) {
        _showSnackBar(statusMessage, _getStatusSnackBarType());
      }
      
      _detailedLog('REAL_TIME_FEEDBACK', 
        'Updated: Matched=$_wordsMatched, Error=$_wordsError, Skipped=$_wordsSkipped, Progress=${_completionPercentage.toStringAsFixed(1)}%');
        
    } catch (e) {
      _detailedLog('REAL_TIME_FEEDBACK', 'Error processing real-time feedback: $e');
    }
  }
  
  String _getStatusMessage() {
    // Qurani-style: 60%+ = hijau/baik, <60% = merah/perlu perbaikan
    if (_completionPercentage >= 85) {
      return '‚úÖ Sangat Baik! ${_completionPercentage.toStringAsFixed(0)}%';
    } else if (_completionPercentage >= 60) {
      return 'üí™ Baik! ${_completionPercentage.toStringAsFixed(0)}%';
    } else if (_completionPercentage > 0) {
      return 'üìù Perlu Perbaikan ${_completionPercentage.toStringAsFixed(0)}%';
    } else {
      return '';
    }
  }
  
  SnackBarType _getStatusSnackBarType() {
    switch (_overallStatus) {
      case 'excellent':
        return SnackBarType.success;
      case 'good':
        return SnackBarType.info;
      case 'needs_improvement':
        return SnackBarType.warning;
      default:
        return SnackBarType.info;
    }
  }
  
  void _handleWordFeedback(Map<String, dynamic> data) {
    _detailedLog('API_RESPONSE', 'Word feedback received: ${jsonEncode(data)}');

    // Handle real-time word-by-word feedback
    try {
      final position = data['position'];
      final status = data['status'];
      final similarity = data['similarity_score'];

      // Update specific word in current results
      if (position != null && position < _currentAyatResults.length) {
        setState(() {
          _currentAyatResults[position] = APIWordResult(
            position: position,
            expected: _currentAyatResults[position].expected,
            spoken: data['spoken'] ?? '',
            status: status ?? 'unknown',
            similarity_score: (similarity ?? 0.0).toDouble(),
          );
        });
      }
    } catch (e) {
      _detailedLog('API_RESPONSE', 'Error processing word feedback: $e');
    }
  }

  // ‚ö° TARTEEL-STYLE LIVE TRANSCRIPT HANDLER - ENHANCED!
  void _handleLiveTranscript(Map<String, dynamic> data) {
    try {
      final transcript = data['transcript'] ?? '';
      final isPartial = data['is_partial'] ?? true;
      final confidence = data['confidence'] ?? 0.0;
      final engine = data['engine'] ?? 'whisper_live';
      
      _detailedLog('LIVE_TRANSCRIPT', 'Received: "$transcript" (partial: $isPartial, conf: ${confidence.toStringAsFixed(2)})');
      
      if (transcript.isNotEmpty && mounted) {
        setState(() {
          if (isPartial) {
            // ‚ö° TARTEEL: Update live partial transcript
            _livePartialTranscript = transcript;
            _liveTranscript = transcript;
            _lastTranscriptUpdate = DateTime.now();
            
            // üéØ Update word highlighting for partial text
            _updateWordHighlighting(transcript, true);
            
            _detailedLog('LIVE_UPDATE', 'Live transcript updated: "$transcript"');
          } else {
            // Final transcript - confirm and highlight
            _confirmedTranscript = transcript;
            _liveTranscript = transcript;
            _livePartialTranscript = '';
            
            // üéØ Final word highlighting and progress
            _updateWordHighlighting(transcript, false);
            _updateReadingProgress(transcript);
            
            _detailedLog('LIVE_FINAL', 'Final transcript confirmed: "$transcript"');
          }
        });
        
        // üéÜ Enhanced feedback for special recognitions
        _showLiveFeedback(transcript, confidence, isPartial);
      }
    } catch (e) {
      _detailedLog('LIVE_TRANSCRIPT', 'Error processing live transcript: $e');
    }
  }
  
  // üéØ TARTEEL-STYLE: Update word highlighting
  void _updateWordHighlighting(String transcript, bool isPartial) {
    if (_ayatList.isEmpty || _currentAyatIndex >= _ayatList.length) return;
    
    try {
      final currentAyat = _ayatList[_currentAyatIndex];
      final wordsArray = currentAyat.wordsArrayNt.isNotEmpty ? currentAyat.wordsArrayNt : currentAyat.arabic.split(' ');
      final transcriptWords = transcript.toLowerCase().split(' ');
      
      // ‚ö° ENHANCED: Smarter word matching for Arabic Quranic text
      for (int i = 0; i < wordsArray.length && i < 20; i++) {
        final expectedWord = wordsArray[i]
            .toLowerCase()
            .replaceAll(RegExp(r'[^\u0600-\u06FF]'), '') // Keep only Arabic letters
            .replaceAll(RegExp(r'[\u064B-\u0652]'), ''); // Remove diacritics
        
        // Check if this word is being spoken with multiple matching strategies
        bool wordFound = false;
        String matchedWord = '';
        
        for (final spokenWord in transcriptWords) {
          final cleanSpoken = spokenWord
              .replaceAll(RegExp(r'[^\u0600-\u06FF]'), '')
              .replaceAll(RegExp(r'[\u064B-\u0652]'), '');
              
          if (cleanSpoken.isEmpty) continue;
          
          // üéØ Multiple matching strategies
          if (_isWordMatch(expectedWord, cleanSpoken)) {
            wordFound = true;
            matchedWord = spokenWord;
            break;
          }
        }
        
        if (wordFound) {
          _detailedLog('WORD_MATCH', 'Word $i: "${wordsArray[i]}" matched with "$matchedWord"');
          
          setState(() {
            if (isPartial) {
              // üîµ Currently reading (blue highlight)
              _wordHighlights[i] = 'reading';
              if (!_currentReadingWords.contains(i)) {
                _currentReadingWords.add(i);
              }
              // Remove from completed if was there
              _completedWords.remove(i);
            } else {
              // ‚úÖ Completed word (green highlight)
              _wordHighlights[i] = 'completed';
              if (!_completedWords.contains(i)) {
                _completedWords.add(i);
              }
              _currentReadingWords.remove(i);
            }
            
            _wordStatus[i] = {
              'status': isPartial ? 'reading' : 'completed',
              'color': isPartial ? 'blue' : 'green',
              'similarity': 1.0,
              'timestamp': DateTime.now().millisecondsSinceEpoch,
              'matched_word': matchedWord,
            };
          });
        }
      }
    } catch (e) {
      _detailedLog('WORD_HIGHLIGHT', 'Error updating highlights: $e');
    }
  }
  
  // üìà TARTEEL-STYLE: Update reading progress
  void _updateReadingProgress(String transcript) {
    try {
      final wordsRead = _completedWords.length;
      final totalWords = _ayatList.isNotEmpty ? 
        (_ayatList[_currentAyatIndex].wordsArrayNt.isNotEmpty ? _ayatList[_currentAyatIndex].wordsArrayNt.length : 10) : 10;
      
      setState(() {
        _wordsMatched = wordsRead;
        _completionPercentage = (wordsRead / totalWords * 100);
        _currentWordIndex = wordsRead;
        
        if (_completionPercentage >= 80) {
          _overallStatus = 'excellent';
        } else if (_completionPercentage >= 60) {
          _overallStatus = 'good';
        } else {
          _overallStatus = 'needs_improvement';
        }
      });
      
      _detailedLog('PROGRESS', 'Reading progress: $wordsRead/$totalWords (${_completionPercentage.toStringAsFixed(1)}%)');
    } catch (e) {
      _detailedLog('PROGRESS', 'Error updating progress: $e');
    }
  }
  
  // üéÜ Enhanced live feedback
  void _showLiveFeedback(String transcript, double confidence, bool isPartial) {
    // üéØ Special recognition feedback
    if (transcript.contains('ŸäŸ∞ÿ≥€§') || transcript.toLowerCase().contains('yasin')) {
      _showSnackBar('üéÜ Ya-Sin recognized! ŸäŸ∞ÿ≥€§', SnackBarType.success);
    } else if (transcript.contains('ÿ∑Ÿ∞ŸáŸ∞') || transcript.toLowerCase().contains('taha')) {
      _showSnackBar('‚ú® Ta-Ha recognized! ÿ∑Ÿ∞ŸáŸ∞', SnackBarType.success);
    } else if (transcript.contains('ÿßŸÑŸìŸÖ€§') || transcript.toLowerCase().contains('alif lam meem')) {
      _showSnackBar('‚ú® Alif Lam Meem recognized! ÿßŸÑŸìŸÖ€§', SnackBarType.success);
    } else if (transcript.contains('ÿ®Ÿêÿ≥ŸíŸÖŸê ÿßŸÑŸÑŸéŸëŸáŸê') || transcript.toLowerCase().contains('bismillah')) {
      _showSnackBar('üåô Bismillah recognized! ÿ®Ÿêÿ≥ŸíŸÖŸê ÿßŸÑŸÑŸéŸëŸáŸê', SnackBarType.success);
    }
    
    // üìà Confidence feedback for partial transcripts
    if (isPartial && confidence > 0.8) {
      // High confidence partial - show subtle positive feedback
    } else if (!isPartial) {
      // Final transcript - show completion feedback
      if (confidence > 0.8) {
        _showSnackBar('‚úÖ High accuracy! (${(confidence * 100).toStringAsFixed(0)}%)', SnackBarType.success);
      }
    }
  }

  // WHISPER STT HANDLERS - MISSING METHODS ADDED!
  void _handleWhisperAudioProcessed(Map<String, dynamic> data) {
    try {
      final connectionId = data['connection_id'] ?? 'unknown';
      final size = data['size'] ?? 0;
      final whisperResult = data['whisper_result'] ?? {};
      
      _detailedLog('WHISPER_AUDIO', 'Audio processed: ${size} bytes by connection $connectionId');
      
        // Handle Whisper STT result
        if (whisperResult['text'] != null && whisperResult['text'].toString().isNotEmpty) {
          final text = whisperResult['text'].toString();
          final confidence = whisperResult['confidence'] ?? 0.0;
          final isFinal = whisperResult['is_final'] ?? false;
          
          _detailedLog('WHISPER_STT', 'Recognized: "$text" (confidence: ${confidence.toStringAsFixed(2)})');
          
          // üéØ TARTEEL-STYLE: Real-time ayah comparison with visual feedback
          if (text.isNotEmpty) {
            // Set current ayah as target for comparison (always update)
            if (_ayatList.isNotEmpty && _currentAyatIndex < _ayatList.length) {
              final currentAyat = _ayatList[_currentAyatIndex];
              setState(() {
                _targetAyahText = currentAyat.arabic;
                _targetWords = currentAyat.arabic.split(' ')
                    .where((w) => w.trim().isNotEmpty)
                    .toList();
                _isTargetSet = true;
              });
              _detailedLog('TARTEEL_TARGET', 'Updated target ayah: ${currentAyat.ayah} - ${currentAyat.arabic}');
            }
            
            // Perform real-time comparison
            if (_isTargetSet) {
              final targetComparison = _compareWithTarget(text);
              _detailedLog('TARTEEL_COMPARISON', 
                'Ayah $_currentAyatNumber - '
                'Correct: ${targetComparison['isCorrect']}, '
                'Similarity: ${(targetComparison['similarity'] * 100).toStringAsFixed(1)}%, '
                'Progress: ${targetComparison['progress'].toStringAsFixed(1)}%'
              );
              
              // üéØ TARTEEL: Real-time visual feedback with colors
              final feedbackColor = targetComparison['feedbackColor'] as String;
              final progress = targetComparison['progress'] as double;
              
              // Update UI with real-time feedback color
              setState(() {
                _currentFeedbackColor = feedbackColor;
                _currentProgress = progress;
                _completionPercentage = progress; // Update completion percentage for auto-advance
              });
              
              // Show appropriate feedback based on color
              if (feedbackColor == 'green') {
                _showSnackBar(targetComparison['message'], SnackBarType.success);
                // Auto-advance when correctly recited (70%+)
                if (progress >= 0.7) {
                  _detailedLog('AUTO_ADVANCE', 'üéØ Progress ${(progress * 100).toStringAsFixed(1)}% >= 70% - triggering auto-advance');
                  Timer(Duration(seconds: 2), () {
                    if (_autoMoveEnabled || _autoAdvanceEnabled) {
                      _detailedLog('AUTO_ADVANCE', 'üöÄ Auto-advance enabled - moving to next ayah');
                      _autoMoveToNextAyat();
                    } else {
                      _detailedLog('AUTO_ADVANCE', '‚ùå Auto-advance disabled - staying on current ayah');
                    }
                  });
                } else {
                  _detailedLog('AUTO_ADVANCE', '‚è≥ Progress ${(progress * 100).toStringAsFixed(1)}% < 70% - not advancing');
                }
              } else if (feedbackColor == 'red') {
                _showSnackBar(targetComparison['message'], SnackBarType.error);
              } else if (feedbackColor == 'blue') {
                _showSnackBar(targetComparison['message'], SnackBarType.info);
              }
            }
          }
          
          if (mounted) {
            setState(() {
              if (isFinal) {
                _confirmedTranscript = text;
                _liveTranscript = text;
              } else {
                _liveTranscript = text;
            }
          });
        }
      }
    } catch (e) {
      _detailedLog('WHISPER_AUDIO', 'Error processing Whisper audio: $e');
    }
  }

  void _handleWhisperTranscriptResult(Map<String, dynamic> data) {
    try {
      final transcriptData = data['data'] ?? {};
      final originalTranscript = transcriptData['original_transcript'] ?? '';
      final whisperConfidence = transcriptData['whisper_confidence'] ?? 0.0;
      final alignmentResults = transcriptData['alignment_results'] ?? {};
      final realtimeFeedback = data['real_time_feedback'] ?? {};
      
      _detailedLog('WHISPER_RESULT', 'Transcript: "$originalTranscript" (confidence: ${whisperConfidence.toStringAsFixed(2)})');
      
      // Update UI with Whisper results
      if (mounted) {
        setState(() {
          _confirmedTranscript = originalTranscript;
          _liveTranscript = originalTranscript;
          
          // Update progress from alignment
          if (alignmentResults['completion_percentage'] != null) {
            // You can add progress tracking here if needed
            final completion = alignmentResults['completion_percentage'];
            _detailedLog('WHISPER_PROGRESS', 'Completion: ${completion.toStringAsFixed(1)}%');
          }
        });
      }
      
      // Handle real-time feedback
      if (realtimeFeedback.isNotEmpty) {
        _handleRealTimeFeedback(realtimeFeedback);
      }
      
      // Show user feedback
      if (realtimeFeedback['message'] != null) {
        final status = realtimeFeedback['status'] ?? 'processing';
        final snackBarType = status == 'excellent' 
            ? SnackBarType.success 
            : status == 'good' 
                ? SnackBarType.info 
                : SnackBarType.warning;
        
        _showSnackBar(realtimeFeedback['message'], snackBarType);
      }
      
    } catch (e) {
      _detailedLog('WHISPER_RESULT', 'Error processing Whisper result: $e');
    }
  }

  void _handleWhisperProcessingError(Map<String, dynamic> data) {
    try {
      final error = data['error'] ?? 'Unknown Whisper processing error';
      final originalTranscript = data['original_transcript'] ?? '';
      
      _detailedLog('WHISPER_ERROR', 'Processing error: $error');
      
      if (originalTranscript.isNotEmpty) {
        _detailedLog('WHISPER_ERROR', 'Failed transcript: "$originalTranscript"');
      }
      
      // Show error to user
      _showSnackBar('Whisper STT Error: $error', SnackBarType.error);
      
      // Fallback: if we have the original transcript, still use it
      if (originalTranscript.isNotEmpty && mounted) {
        setState(() {
          _liveTranscript = originalTranscript;
        });
      }
      
    } catch (e) {
      _detailedLog('WHISPER_ERROR', 'Error handling Whisper error: $e');
    }
  }

  // TAMBAHAN: Handler methods untuk message types baru
  void _handleAudioReceived(Map<String, dynamic> data) {
    // Audio chunk acknowledgment dari backend
    final size = data['size'] ?? 0;
    final audioLevel = data['audio_level'] ?? 0.0;
    final voiceActive = data['voice_active'] ?? false;
    
    _detailedLog('AUDIO_ACK', 'Audio received: ${size} bytes, level: ${audioLevel.toStringAsFixed(1)}dB, voice: $voiceActive');
    
    // Update UI dengan audio level dan voice activity
    if (mounted) {
      setState(() {
        _audioLevel = audioLevel;
        _isVoiceActive = voiceActive;
      });
    }
  }

  void _handleAudioProcessingError(Map<String, dynamic> data) {
    final error = data['error'] ?? 'Unknown audio processing error';
    final action = data['action'] ?? 'continue';
    
    _detailedLog('AUDIO_ERROR', 'Audio processing error: $error, action: $action');
    
    // Show error to user but don't stop listening unless critical
    if (action == 'stop') {
      _stopContinuousListening();
      _showSnackBar('Audio processing stopped: $error', SnackBarType.error);
    } else {
      _showSnackBar('Audio issue: $error', SnackBarType.warning);
    }
  }

  void _handleAlignmentResults(Map<String, dynamic> alignmentData) {
    try {
      // Process word-by-word alignment results dari backend
      if (alignmentData.containsKey('word_results') && alignmentData['word_results'] is List) {
        final wordResults = alignmentData['word_results'] as List;
        
        for (var wordData in wordResults) {
          final position = wordData['position'];
          final status = wordData['status'];
          final color = wordData['color'] ?? 'gray';
          final similarity = wordData['similarity_score'] ?? 0.0;
          
          // Update word status untuk real-time indicators
          if (position != null) {
            setState(() {
              _wordStatus[position] = {
                'status': status,
                'color': color,
                'similarity': similarity,
                'timestamp': DateTime.now().millisecondsSinceEpoch,
              };
            });
          }
        }
        
        _detailedLog('ALIGNMENT', 'Updated ${wordResults.length} word statuses');
      }
    } catch (e) {
      _detailedLog('ALIGNMENT', 'Error processing alignment results: $e');
    }
  }

  void _updateUIWithResults(
    List<APIWordResult> results,
    Map<String, dynamic>? summary,
  ) {
    // Update progress and UI based on results
    if (summary != null) {
      final matched = summary['matched'] ?? 0;
      final total = summary['total'] ?? 1;
      final completionRate = total > 0 ? matched / total : 0.0;

      _detailedLog(
        'API_PROGRESS',
        'Ayat progress: $matched/$total (${(completionRate * 100).toStringAsFixed(1)}%)',
      );

      // Update ayat progress
      // Implementation for progress tracking...
    }

    // Trigger UI rebuild
    if (mounted) {
      setState(() {});
    }
  }

  // ==================== MISSING METHODS ====================
  
  void _startSimulatedWordProgression() {
    if (_simulatedWordTimer != null) return;
    
    _simulatedWordIndex = 0;
    _simulatedWordTimer = Timer.periodic(const Duration(milliseconds: 800), (timer) {
      if (_ayatList.isEmpty || _currentAyatIndex >= _ayatList.length) {
        _stopSimulatedWordProgression();
        return;
      }
      
      final currentAyat = _ayatList[_currentAyatIndex];
      final ayahWords = currentAyat.arabic.split(' ').where((w) => w.trim().isNotEmpty).toList();
      
      if (_simulatedWordIndex < ayahWords.length) {
        final transcriptText = ayahWords.take(_simulatedWordIndex + 1).join(' ');
        
        setState(() {
          _liveTranscript = transcriptText;
        });
        
        _simulatedWordIndex++;
      } else {
        _stopSimulatedWordProgression();
      }
    });
  }
  
  void _stopSimulatedWordProgression() {
    _simulatedWordTimer?.cancel();
    _simulatedWordTimer = null;
    _simulatedWordIndex = 0;
  }
  
  int _getTotalWordsInCurrentAyah() {
    if (_ayatList.isEmpty || _currentAyatIndex >= _ayatList.length) return 0;
    final currentAyat = _ayatList[_currentAyatIndex];
    return currentAyat.arabic.split(' ').where((w) => w.trim().isNotEmpty).length;
  }

  // ==================== ENHANCED LOGGING SYSTEM ====================

  void _detailedLog(String category, String message) {
    final timestamp = DateTime.now().toString().substring(11, 23);
    final logMessage = '[$timestamp] $category: $message';
    print(logMessage);

    if (mounted) {
      setState(() {
        _logs.add(logMessage);
        if (_logs.length > 500) {
          // Increased log capacity
          _logs.removeAt(0);
        }
      });
    }
  }

  void _logAPICall(
    String method,
    String endpoint,
    int statusCode,
    String message,
  ) {
    final apiLog = APILog(
      timestamp: DateTime.now(),
      method: method,
      endpoint: endpoint,
      statusCode: statusCode,
      message: message,
    );

    _apiLogs.add(apiLog);
    if (_apiLogs.length > 100) {
      _apiLogs.removeAt(0);
    }

    _detailedLog('API_CALL', '$method $endpoint - $statusCode - $message');
  }

  // ==================== CLEANUP AND DISPOSAL ====================

  @override
  void dispose() {
    _detailedLog('DISPOSAL', 'Starting enhanced cleanup process');

    _stopContinuousListening();
    _closeWebSocketConnection();
    _endAPISession();

    // Cancel ALL timers
    _transcriptSendTimer?.cancel();
    _partialUpdateTimer?.cancel();
    _partialDebounceTimer?.cancel(); // ADD this
    _heartbeatTimer?.cancel();
    _reconnectTimer?.cancel();
    _connectionTimeoutTimer?.cancel();
    _processingTimer?.cancel();
    _vadTimer?.cancel();
    _autoSendTimer?.cancel();

    // Close streams and dispose controllers
    _transcriptStreamController.close();
    _scrollController.dispose();
    _disposeAnimations();
    _cleanupAudioResources();
    _cleanupVoskResources();

    super.dispose();
  }

  Future<void> _cleanupAudioResources() async {
    try {
      // Stop audio recording first
      await _stopAudioRecording();
      
      // Close audio recorder properly
      if (_audioRecorder != null && _isRecorderInitialized) {
        try {
          await _audioRecorder!.closeRecorder();
        } catch (e) {
          _detailedLog('CLEANUP', 'Error closing recorder: $e');
        }
        _audioRecorder = null;
        _isRecorderInitialized = false;
      }
      
      // Clean up any remaining streams
      _audioStreamController?.close();
      _audioStreamController = null;
      
      _audioStreamSubscription?.cancel();
      _audioStreamSubscription = null;
      
      _audioLevelSubscription?.cancel();
      _audioLevelSubscription = null;
      
      // Reset audio state
      _isVoiceActive = false;
      _audioLevel = 0.0;
      _audioLevelHistory.clear();
      
      _detailedLog('CLEANUP', 'All audio resources cleaned up successfully');
    } catch (e) {
      _detailedLog('CLEANUP', 'Error during audio cleanup: $e');
    }
  }

  Future<void> _cleanupVoskResources() async {
    try {
      if (_speechService != null) {
        await _speechService!.stop();
        _speechService = null;
      }
      if (_recognizer != null) {
        await _recognizer!.dispose();
        _recognizer = null;
      }
      if (_model != null) {
        _model!.dispose();
        _model = null;
      }
    } catch (e) {
      _detailedLog('CLEANUP', 'Error during Vosk cleanup: $e');
    }
  }

Future<void> _endAPISession() async {
    if (!_isSessionActive || _activeSessionId == null) {
      _detailedLog('API_SESSION', 'No active session to end');
      return;
    }

    try {
      _detailedLog('API_SESSION', 'Ending session: $_activeSessionId');

      // Send end session request sesuai API docs
      final response = await http
          .post(
            Uri.parse('$API_BASE_URL/live/end/$_activeSessionId'),
            headers: {
              'Content-Type': 'application/json',
              'Accept': 'application/json',
              'ngrok-skip-browser-warning': 'true',
            },
          )
          .timeout(_apiTimeout);

      if (response.statusCode >= 200 && response.statusCode < 300) {
        _detailedLog('API_SESSION', 'Session ended successfully');
        _logAPICall('POST', '/live/end', response.statusCode, 'Success');
      } else {
        _detailedLog('API_SESSION', 'End session error: ${response.statusCode} - ${response.body}');
        _logAPICall('POST', '/live/end', response.statusCode, 'Error: ${response.body}');
      }
    } catch (e) {
      _detailedLog('API_SESSION', 'Error ending session: $e');
      _logAPICall('POST', '/live/end', 0, 'Error: $e');
    } finally {
      _activeSessionId = null;
      _isSessionActive = false;
      if (mounted) setState(() {});
    }
  }

  // ==================== SPEECH RECOGNITION METHODS ====================

  Future<void> _startEnhancedListening() async {
    if (_isListening) {
      _log('STT: Already listening');
      return;
    }

    if (!_isVoskInitialized || !_isModelLoaded || _recognizer == null) {
      _log('STT: Engine not ready');
      _showEnhancedSnackBar(
        'STT engine not ready. Please wait.',
        SnackBarType.warning,
      );
      return;
    }

    // Initialize API session if not active
    if (!_isSessionActive) {
      await _initializeAPISession();
      if (!_isSessionActive) {
        _showEnhancedSnackBar(
          'Failed to start API session',
          SnackBarType.error,
        );
        return;
      }
    }

    try {
      _log('STT: Starting listening session');

      setState(() {
        _isListening = true;
        _liveTranscript = '';
        _confirmedTranscript = '';
        _isProcessingTranscript = false;
      });

      // Start continuous processing timers
      _startProcessingTimers();

      // Use SpeechService for automatic audio handling
      _speechService = await _vosk!.initSpeechService(_recognizer!);

      // Set up listeners for partial and final results
      _speechService!.onPartial().listen((partialJson) {
        final partialText = _extractTextFromVoskResult(partialJson);
        if (partialText.isNotEmpty) {
          setState(() {
            _liveTranscript = partialText;
          });
          _transcriptStreamController.add(partialText);
        }
      });

      _speechService!.onResult().listen((resultJson) {
        final resultText = _extractTextFromVoskResult(resultJson);
        if (resultText.isNotEmpty) {
          setState(() {
            _confirmedTranscript = resultText;
            _liveTranscript = '';
          });
          _transcriptHistory.add(resultText);

          // üïå MEMORY: Send transcript using Memory API method
          if (_isSessionActive && _activeSessionId != null) {
            _sendTranscriptToAPI(resultText);
          } else {
            _detailedLog('STT', 'Cannot send transcript - no active session');
          }
        }
      });

      await _speechService!.start();

      // Start animations
      _pulseController.repeat(reverse: true);
      _waveController.repeat();

      _log('STT: Listening started successfully');
      _showEnhancedSnackBar('Listening started', SnackBarType.success);
    } catch (e) {
      _log('STT: Failed to start listening - $e');
      setState(() {
        _isListening = false;
      });
      _showEnhancedSnackBar(
        'Failed to start listening: $e',
        SnackBarType.error,
      );
    }
  }

  Future<void> _stopEnhancedListening() async {
    if (!_isListening) {
      _log('STT: Not listening');
      return;
    }

    _log('STT: Stopping listening session');

    try {
      setState(() {
        _isListening = false;
        _isProcessingTranscript = false;
      });

      // Stop timers
      _processingTimer?.cancel();
      _vadTimer?.cancel();
      _autoSendTimer?.cancel();

      // Stop speech service
      await _speechService?.stop();
      _speechService = null;

      // Stop animations
      _pulseController.stop();
      _waveController.stop();
      _levelController.reset();

      // Reset audio states
      _isVoiceActive = false;
      _audioLevel = 0.0;
      _silenceFrameCount = 0;
      _voiceFrameCount = 0;

      _log('STT: Listening stopped successfully');
      _showEnhancedSnackBar('Listening stopped', SnackBarType.info);
    } catch (e) {
      _log('STT: Error stopping listening - $e');
    }
  }

  void _startProcessingTimers() {
    // Main processing timer for real-time analysis
    _processingTimer = Timer.periodic(_processingInterval, (timer) {
      if (!_isListening) {
        timer.cancel();
        return;
      }
      _updateVoiceActivityDetection();
    });

    // Voice activity detection timer
    _vadTimer = Timer.periodic(_vadCheckInterval, (timer) {
      if (!_isListening) {
        timer.cancel();
        return;
      }
      _simulateAudioLevel();
    });

    // Auto-send timer for confirmed transcripts
    if (_autoSendEnabled) {
      _autoSendTimer = Timer.periodic(_autoSendDelay, (timer) {
        if (!_isListening) {
          timer.cancel();
          return;
        }
        if (_confirmedTranscript.isNotEmpty && !_isProcessingTranscript) {
          _sendTranscriptToAPI(_confirmedTranscript);
        }
      });
    }
  }

  void _updateVoiceActivityDetection() {
    double currentLevel = _audioLevel;
    _audioLevelHistory.add(currentLevel);

    if (_audioLevelHistory.length > _audioHistoryLength) {
      _audioLevelHistory.removeAt(0);
    }

    _averageAudioLevel =
        _audioLevelHistory.reduce((a, b) => a + b) / _audioLevelHistory.length;

    bool voiceDetected = currentLevel > (_averageAudioLevel * 1.5 + 0.1);

    if (voiceDetected) {
      _voiceFrameCount++;
      _silenceFrameCount = 0;

      if (_voiceFrameCount >= _minVoiceFrames && !_isVoiceActive) {
        setState(() {
          _isVoiceActive = true;
        });
      }
    } else {
      _silenceFrameCount++;
      _voiceFrameCount = 0;

      if (_silenceFrameCount >= _maxSilenceFrames && _isVoiceActive) {
        setState(() {
          _isVoiceActive = false;
        });
      }
    }

    // Update level animation
    _levelController.animateTo(_audioLevel);
  }

  void _simulateAudioLevel() {
    // Simulate realistic audio level since Vosk doesn't expose raw buffer
    _audioLevel = _isVoiceActive
        ? 0.6 + _random.nextDouble() * 0.4
        : _random.nextDouble() * 0.3;
  }

  String _extractTextFromVoskResult(String voskResult) {
    try {
      final Map<String, dynamic> result = jsonDecode(voskResult);
      if (result.containsKey('partial')) {
        return result['partial']?.toString().trim() ?? '';
      } else if (result.containsKey('text')) {
        return result['text']?.toString().trim() ?? '';
      }
      return '';
    } catch (e) {
      _log('STT: Error parsing Vosk result - $e');
      return '';
    }
  }

  // ==================== SURAH COMPLETION ====================

  void _handleSurahCompletion() {
    _log('SURAH: Completion detected');
    _stopEnhancedListening();
    _endAPISession();
    _showCompletionDialog();
  }

  // üïå TARTEEL: Enhanced completion celebration
  void _showSimpleCompletionCelebration() {
    if (!mounted) return;
    
    // Show completion message
    _showSnackBar(
      '‚úÖ Ayat $_currentAyatNumber completed!',
      SnackBarType.success,
    );
    
    // üïå TARTEEL: Enhanced visual feedback
    setState(() {
      _isAyahCompleted = true;
      _encouragementMessage = 'üéâ Excellent! Ayah completed successfully!';
    });
    
    // Pulse animation for current ayat
    if (_progressController.status != AnimationStatus.forward) {
      _progressController.forward().then((_) {
        _progressController.reverse();
      });
    }

    // üïå TARTEEL: Show auto-advance countdown if enabled
    if (_autoAdvanceEnabled || _autoMoveEnabled) {
      _showAutoAdvanceCountdown();
    }
  }

  // üïå TARTEEL: Auto-advance countdown notification
  void _showAutoAdvanceCountdown() {
    int countdown = 2;
    Timer.periodic(Duration(seconds: 1), (timer) {
      if (countdown > 0) {
        setState(() {
          _encouragementMessage = 'üîÑ Moving to next ayah in ${countdown}s...';
        });
        countdown--;
      } else {
        timer.cancel();
      }
    });
  }

  void _showCompletionDialog() {
    if (!mounted) return;

    showDialog(
      context: context,
      barrierDismissible: false,
      builder: (BuildContext context) {
        return AlertDialog(
          title: Row(
            children: [
              Icon(Icons.celebration, color: correctColor, size: 24),
              const SizedBox(width: 8),
              const Text('Surah Completed!', style: TextStyle(fontSize: 18)),
            ],
          ),
          content: Column(
            mainAxisSize: MainAxisSize.min,
            children: [
              Container(
                padding: const EdgeInsets.all(16),
                decoration: BoxDecoration(
                  color: correctColor.withOpacity(0.1),
                  borderRadius: BorderRadius.circular(12),
                ),
                child: Column(
                  children: [
                    Text(
                      'üéâ Congratulations! üéâ',
                      style: TextStyle(
                        fontSize: 20,
                        fontWeight: FontWeight.bold,
                        color: primaryColor,
                      ),
                      textAlign: TextAlign.center,
                    ),
                    const SizedBox(height: 8),
                    Text(
                      'You have completed reading ${widget.suratName}',
                      style: const TextStyle(fontSize: 14),
                      textAlign: TextAlign.center,
                    ),
                    const SizedBox(height: 12),
                    _buildCompletionStats(),
                  ],
                ),
              ),
            ],
          ),
          actions: [
            TextButton(
              onPressed: () {
                Navigator.of(context).pop();
                _showDetailedResults();
              },
              child: const Text('View Details'),
            ),
            ElevatedButton(
              onPressed: () {
                Navigator.of(context).pop();
                Navigator.of(context).pop(); // Return to previous screen
              },
              style: ElevatedButton.styleFrom(backgroundColor: primaryColor),
              child: const Text(
                'Finish',
                style: TextStyle(color: Colors.white),
              ),
            ),
          ],
        );
      },
    );
  }

  Widget _buildCompletionStats() {
    final sessionDuration = _sessionStartTime != null
        ? DateTime.now().difference(_sessionStartTime!).inMinutes
        : 0;

    return Column(
      children: [
        Row(
          mainAxisAlignment: MainAxisAlignment.spaceAround,
          children: [
            _buildStatItem('API Calls', '$_totalTranscriptsSent'),
            _buildStatItem('Success', '$_successfulAPIResponses'),
            _buildStatItem('Time', '${sessionDuration}min'),
          ],
        ),
        const SizedBox(height: 8),
        Row(
          mainAxisAlignment: MainAxisAlignment.spaceAround,
          children: [
            _buildStatItem('Ayat', '${_ayatList.length}'),
            _buildStatItem('Transcripts', '${_transcriptHistory.length}'),
            _buildStatItem(
              'Completed',
              '${_ayatProgress.values.where((p) => p.isCompleted).length}',
            ),
          ],
        ),
      ],
    );
  }

  Widget _buildStatItem(String label, String value) {
    return Column(
      children: [
        Text(
          value,
          style: TextStyle(
            fontSize: 16,
            fontWeight: FontWeight.bold,
            color: primaryColor,
          ),
        ),
        Text(
          label,
          style: TextStyle(fontSize: 10, color: Colors.grey.shade600),
        ),
      ],
    );
  }

  void _showDetailedResults() {
    showDialog(
      context: context,
      builder: (BuildContext context) {
        return AlertDialog(
          title: const Text('Detailed Results'),
          content: SizedBox(
            width: double.maxFinite,
            height: 400,
            child: SingleChildScrollView(
              child: Column(
                crossAxisAlignment: CrossAxisAlignment.start,
                children: [
                  _buildResultsSection('Overall Performance', [
                    'Total API Calls: $_totalTranscriptsSent',
                    'Successful Responses: $_successfulAPIResponses',
                    'Success Rate: ${_totalTranscriptsSent > 0 ? ((_successfulAPIResponses / _totalTranscriptsSent) * 100).toStringAsFixed(1) : 0}%',
                    'Transcript Segments: ${_transcriptHistory.length}',
                    'Completed Ayat: ${_ayatProgress.values.where((p) => p.isCompleted).length}/${_ayatList.length}',
                  ]),
                  const SizedBox(height: 16),
                  _buildResultsSection(
                    'Per-Ayat Breakdown',
                    _ayatProgress.values
                        .map(
                          (progress) =>
                              'Ayat ${progress.ayatIndex + 1}: ${progress.completionPercentage.toStringAsFixed(1)}% (${progress.correctWords}/${progress.totalWords} words)',
                        )
                        .toList(),
                  ),
                ],
              ),
            ),
          ),
          actions: [
            TextButton(
              onPressed: () => Navigator.of(context).pop(),
              child: const Text('Close'),
            ),
          ],
        );
      },
    );
  }

  Widget _buildResultsSection(String title, List<String> items) {
    return Column(
      crossAxisAlignment: CrossAxisAlignment.start,
      children: [
        Text(
          title,
          style: TextStyle(
            fontSize: 14,
            fontWeight: FontWeight.bold,
            color: primaryColor,
          ),
        ),
        const SizedBox(height: 8),
        Container(
          padding: const EdgeInsets.all(8),
          decoration: BoxDecoration(
            color: Colors.grey.shade50,
            borderRadius: BorderRadius.circular(8),
            border: Border.all(color: Colors.grey.shade300),
          ),
          child: Column(
            crossAxisAlignment: CrossAxisAlignment.start,
            children: items
                .map(
                  (item) => Padding(
                    padding: const EdgeInsets.only(bottom: 4),
                    child: Text(item, style: const TextStyle(fontSize: 12)),
                  ),
                )
                .toList(),
          ),
        ),
      ],
    );
  }

  // ==================== INITIALIZATION METHODS ====================

  @override
  void initState() {
    super.initState();
    _random = Random();
    _ayatKeys = [];
    _log('=== API-INTEGRATED STT INITIALIZATION STARTED ===');
    _initializeAnimations();
    _initializeStreams();
    _initializeApp();
    _sessionStartTime = DateTime.now();
  }

  void _initializeAnimations() {
    _pulseController = AnimationController(
      duration: const Duration(milliseconds: 800),
      vsync: this,
    );

    _levelController = AnimationController(
      duration: const Duration(milliseconds: 80),
      vsync: this,
    );

    _progressController = AnimationController(
      duration: const Duration(milliseconds: 600),
      vsync: this,
    );

    _waveController = AnimationController(
      duration: const Duration(milliseconds: 1500),
      vsync: this,
    );
  }

  void _disposeAnimations() {
    _pulseController.dispose();
    _levelController.dispose();
    _progressController.dispose();
    _waveController.dispose();
  }

  void _initializeStreams() {
    _transcriptStreamController.stream.listen((transcript) {
      // Real-time transcript processing can be handled here if needed
    });
  }

  Future<void> _cleanup() async {
    _processingTimer?.cancel();
    _vadTimer?.cancel();
    _autoSendTimer?.cancel();

    try {
      if (_speechService != null) {
        await _speechService!.stop();
        _speechService = null;
      }
      if (_recognizer != null) {
        await _recognizer!.dispose();
        _recognizer = null;
      }
      if (_model != null) {
        _model!.dispose();
        _model = null;
      }
      if (_webSocketChannel != null) {
        await _webSocketChannel!.sink.close(status.goingAway);
        _webSocketChannel = null;
      }
    } catch (e) {
      _log('CLEANUP: Error during cleanup - $e');
    }

    _log('=== API-INTEGRATED STT DISPOSAL COMPLETED ===');
  }

  void _log(String message) {
    final timestamp = DateTime.now().toString().substring(11, 23);
    final logMessage = '[$timestamp] API_STT: $message';
    print(logMessage);

    if (mounted) {
      setState(() {
        _logs.add(logMessage);
        if (_logs.length > 200) {
          _logs.removeAt(0);
        }
      });
    }
  }

  // ==================== ENHANCED INITIALIZATION ====================

  Future<void> _initializeApp() async {
    try {
      _log('APP: Starting enhanced app initialization');
      setState(() {
        _isLoading = true;
        _errorMessage = '';
      });

      await _requestEnhancedPermissions();
      await _initializeVosk();
      await _setupEnhancedVoskModel();
      await _setupEnhancedRecognizer();
      await _loadAyatData();
      
      // Set initial target ayah
      if (_ayatList.isNotEmpty && _currentAyatIndex < _ayatList.length) {
        final currentAyat = _ayatList[_currentAyatIndex];
        setState(() {
          _targetAyahNumber = currentAyat.ayah; // Set target ayah number
          _targetAyahText = currentAyat.arabic;
          _targetWords = currentAyat.arabic.split(' ')
              .where((w) => w.trim().isNotEmpty)
              .toList();
          _isTargetSet = true;
        });
        _detailedLog('TARTEEL_TARGET', 'Set initial target ayah: ${currentAyat.ayah} - ${currentAyat.arabic}');
      }

      setState(() {
        _isLoading = false;
      });

      _log('APP: Enhanced app initialization completed successfully');
    } catch (e) {
      _log('APP: Enhanced app initialization failed - $e');
      setState(() {
        _errorMessage = 'Failed to initialize enhanced STT: $e';
        _isLoading = false;
      });
    }
  }

  Future<void> _requestEnhancedPermissions() async {
    _log('PERMISSIONS: Requesting enhanced permissions');

    List<Permission> permissions = [Permission.microphone, Permission.audio];

    if (Platform.isAndroid) {
      final androidInfo = await DeviceInfoPlugin().androidInfo;
      final sdkInt = androidInfo.version.sdkInt;
      _log('PERMISSIONS: Android SDK - $sdkInt');

      if (sdkInt >= 33) {
        permissions.addAll([Permission.audio, Permission.notification]);
      } else {
        permissions.add(Permission.storage);
      }
    }

    for (Permission permission in permissions) {
      PermissionStatus status = await permission.request();
      _log('PERMISSIONS: ${permission.toString()} - $status');

      if (status.isDenied || status.isPermanentlyDenied) {
        if (permission == Permission.microphone) {
          throw Exception(
            'Microphone permission required for STT functionality',
          );
        }
      }
    }

    _log('PERMISSIONS: All permissions granted');
  }

  Future<void> _initializeVosk() async {
    _log('VOSK: Initializing Vosk engine');

    try {
      _vosk = VoskFlutterPlugin.instance();
      _isVoskInitialized = true;
      _log('VOSK: Vosk initialized successfully');
    } catch (e) {
      _log('VOSK: Failed to initialize Vosk - $e');
      throw Exception('Vosk initialization failed: $e');
    }
  }

  Future<void> _setupEnhancedVoskModel() async {
    _log('VOSK_MODEL: Using server-based STT - skipping local model setup');
    
    // For server-based architecture, we don't need local VOSK model
    // The FastAPI backend handles all speech recognition
    try {
      // Just mark as loaded since we're using backend STT
      _isModelLoaded = true;
      _log('VOSK_MODEL: Server-based STT configured successfully');
    } catch (e) {
      _log('VOSK_MODEL: Failed to setup server-based STT - $e');
      throw Exception('Server-based STT setup failed: $e');
    }
  }

  Future<void> _setupEnhancedRecognizer() async {
    _log('VOSK_RECOGNIZER: Using server-based STT - skipping local recognizer setup');

    try {
      // For server-based architecture, we don't need local recognizer
      // The FastAPI backend handles all recognition
      // Just mark as initialized
      _log('VOSK_RECOGNIZER: Server-based STT recognizer configured successfully');
    } catch (e) {
      _log('VOSK_RECOGNIZER: Failed to setup server-based recognizer - $e');
      throw Exception('Server-based recognizer setup failed: $e');
    }
  }

  Future<void> _loadAyatData() async {
    _log('DATA: Loading ayat data for surah_id ${widget.suratId}');

    try {
      // Load ayat data with page information
      final response = await _supabase
          .from('m10_quran_ayah')
          .select(
            'surah_id, ayah, arabic, no_tashkeel, transliteration, words_array_nt, page, juz, quarter_hizb',
          )
          .eq('surah_id', widget.suratId)
          .order('ayah', ascending: true);

      if (response.isEmpty) {
        throw Exception('No ayat found for surah ${widget.suratId}');
      }

      // Load surah info
      final surahResponse = await _supabase
          .from('surat')
          .select('nama, namalatin, jumlahayat, tempatturun, arti, deskripsi')
          .eq('id', widget.suratId)
          .single();

      final surahNama = surahResponse['nama'] ?? widget.suratName;
      final surahNamalatin = surahResponse['namalatin'] ?? '';
      final jumlahAyat = surahResponse['jumlahayat'] ?? response.length;

      _suratArti = surahResponse['arti'] ?? '';
      _suratTempatTurun = surahResponse['tempatturun'] ?? '';
      _suratDeskripsi = surahResponse['deskripsi'] ?? '';

      _suratInfo =
          '$surahNama${surahNamalatin.isNotEmpty ? ' ($surahNamalatin)' : ''} (1-$jumlahAyat)';

      _ayatList = response.map((data) => AyatData.fromJson(data)).toList();

      // Set initial page and ayat
      if (_ayatList.isNotEmpty) {
        _currentPage = _ayatList.first.page;
        _currentAyatNumber = _ayatList.first.ayah;
        _loadCurrentPageAyats();
      }

      _ayatKeys = List.generate(_ayatList.length, (index) => GlobalKey());

      _log('DATA: Loaded ${_ayatList.length} ayat with enhanced surah info');
    } catch (e) {
      _log('DATA: Failed to load ayat data - $e');
      throw Exception('Data loading failed: $e');
    }
  }

  Future<void> _loadCurrentPageAyats() async {
    if (!_isQuranMode) {
      _currentPageAyats = _ayatList;
      return;
    }

    try {
      final response = await _supabase
          .from('m10_quran_ayah')
          .select(
            'surah_id, ayah, arabic, no_tashkeel, transliteration, words_array_nt, page, juz, quarter_hizb',
          )
          .eq('page', _currentPage)
          .order('surah_id', ascending: true)
          .order('ayah', ascending: true);

      _currentPageAyats = response
          .map((data) => AyatData.fromJson(data))
          .toList();
      _log(
        'DATA: Loaded ${_currentPageAyats.length} ayats for page $_currentPage',
      );
    } catch (e) {
      _log('DATA: Error loading page ayats - $e');
      _currentPageAyats = [];
    }
  }

  void _performIntelligentNavigation() {
    if (!_scrollController.hasClients ||
        _currentAyatIndex >= _ayatKeys.length ||
        _ayatKeys[_currentAyatIndex].currentContext == null)
      return;

    try {
      final context = _ayatKeys[_currentAyatIndex].currentContext!;
      final renderBox = context.findRenderObject()! as RenderBox;
      final scrollViewContext =
          _scrollController.position.context.storageContext;
      final scrollViewBox = scrollViewContext.findRenderObject()! as RenderBox;
      final position = renderBox.localToGlobal(
        Offset.zero,
        ancestor: scrollViewBox,
      );

      double targetOffset = position.dy - 150;
      targetOffset = targetOffset.clamp(
        0.0,
        _scrollController.position.maxScrollExtent,
      );

      _scrollController.animateTo(
        targetOffset,
        duration: const Duration(milliseconds: 500),
        curve: Curves.easeInOutCubic,
      );
    } catch (e) {
      _log('NAVIGATION: Scroll error - $e');
      // Fallback to estimated position
      double estimatedAyatHeight = 120.0;
      double targetOffset = _currentAyatIndex * estimatedAyatHeight;
      _scrollController.animateTo(
        targetOffset.clamp(0.0, _scrollController.position.maxScrollExtent),
        duration: const Duration(milliseconds: 500),
        curve: Curves.easeOutQuint,
      );
    }
  }

  // ==================== UI BUILD METHODS ====================

@override
Widget build(BuildContext context) {
  return Scaffold(
    backgroundColor: backgroundColor,
    // MODIFIKASI: AppBar hanya tampil jika _isUIVisible = true
    appBar: _isUIVisible ? _buildEnhancedAppBar() : null,
    body: _isLoading
        ? _buildEnhancedLoadingWidget()
        : _errorMessage.isNotEmpty && !_isListening
        ? _buildEnhancedErrorWidget()
        : GestureDetector(
            // TAMBAHAN: GestureDetector untuk mendeteksi tap
            onTap: () {
              setState(() {
                _isUIVisible = !_isUIVisible; // Toggle UI visibility
              });
            },
            child: Column(
              children: [
                Expanded(child: _buildEnhancedMainContent()),
                if (_showLogs && _isUIVisible) _buildEnhancedLogsPanel(),
              ],
            ),
          ),
  );
}

PreferredSizeWidget _buildEnhancedAppBar() {
  // TAMBAHAN: Animated opacity untuk smooth transition
  return PreferredSize(
    preferredSize: const Size.fromHeight(kToolbarHeight),
    child: AnimatedOpacity(
      duration: const Duration(milliseconds: 200),
      opacity: _isUIVisible ? 1.0 : 0.0,
      child: AppBar(
        backgroundColor: primaryColor,
        foregroundColor: Colors.white,
        elevation: 0,
        title: Padding(
          padding: const EdgeInsets.only(left: 15),
          child: Row(
            crossAxisAlignment: CrossAxisAlignment.center,
            children: [
              const Icon(Icons.menu, size: 24, color: Colors.white),
              const SizedBox(width: 12),
              Expanded(
                child: Column(
                  crossAxisAlignment: CrossAxisAlignment.start,
                  mainAxisAlignment: MainAxisAlignment.center,
                  children: [
                    const Text(
                      'Qurani Hafidz',
                      style: TextStyle(fontSize: 16, height: 1.2),
                    ),
                    Text(
                      'Surat Yasin 36 - 83 Ayat',
                      style: TextStyle(
                        fontSize: 10,
                        fontWeight: FontWeight.w400,
                        height: 1.2,
                        color: Colors.white,
                      ),
                    ),
                  ],
                ),
              ),
            ],
          ),
        ),
        titleSpacing: 0,
        actions: [
          // API Status indicator
          Container(
            margin: const EdgeInsets.only(right: 8),
            child: Icon(
              _isWebSocketConnected ? Icons.wifi : Icons.wifi_off,
              color: _isWebSocketConnected
                  ? Colors.greenAccent
                  : Colors.redAccent,
              size: 20,
            ),
          ),

          // Toggle mode button
          IconButton(
            icon: Icon(
              _isQuranMode ? Icons.menu_book : Icons.view_list,
              size: 20,
            ),
            onPressed: () async {
              setState(() {
                _isQuranMode = !_isQuranMode;
              });
              await _loadCurrentPageAyats();
            },
            tooltip: _isQuranMode
                ? 'Switch to List Mode'
                : 'Switch to Mushaf Mode',
          ),

          // Hide/show button
          IconButton(
            icon: Icon(
              _hideUnreadAyat ? Icons.visibility : Icons.visibility_off,
              size: 20,
            ),
            onPressed: () {
              setState(() {
                _hideUnreadAyat = !_hideUnreadAyat;
              });
            },
            tooltip: _hideUnreadAyat ? 'Show All Text' : 'Hide Unread',
          ),

          PopupMenuButton<String>(
            onSelected: _handleMenuAction,
            iconSize: 20,
            itemBuilder: (BuildContext context) => [
              const PopupMenuItem(value: 'logs', child: Text('Debug Logs')),
              const PopupMenuItem(value: 'api_status', child: Text('API Status')),
              const PopupMenuItem(value: 'settings', child: Text('STT Settings')),
              const PopupMenuItem(value: 'reset', child: Text('Reset Session')),
              const PopupMenuItem(value: 'export', child: Text('Export Session')),
            ],
          ),
        ],
      ),
    ),
  );
}

  void _handleMenuAction(String action) {
    switch (action) {
      case 'logs':
        _toggleLogs();
        break;
      case 'api_status':
        _showAPIStatus();
        break;
      case 'settings':
        _showSTTSettings();
        break;
      case 'reset':
        _showResetDialog();
        break;
      case 'export':
        _exportSession();
        break;
    }
  }

Widget _buildEnhancedMainContent() {
  return Stack(
    children: [
      Column(
        children: [
          // Quran text tetap di tempatnya
Expanded(
  flex: 4,
  child: Padding(
    // MODIFIKASI: Padding bottom hanya diterapkan jika UI visible
    padding: EdgeInsets.only(bottom: _isUIVisible ? 80 : 0),
    child: Center(
      child: _buildEnhancedQuranText(),
    ),
  ),
),
   ],
      ),
      // MODIFIKASI: Bottom bar hanya tampil jika UI visible
      if (_isUIVisible)
        Positioned(
          bottom: 0, 
          left: 0, 
          right: 0, 
          child: _buildBottomBar()
        ),
    ],
  );
}

  Widget _buildBottomBar() {
    return Container(
      height: 90,
      child: Stack(
        children: [
          // Test button (left side)
          Positioned(
            bottom: 25,
            left: 40,
            child: Container(
              width: 45,
              height: 45,
              decoration: BoxDecoration(
                color: warningColor,
                shape: BoxShape.circle,
                boxShadow: [
                  BoxShadow(
                    color: warningColor.withOpacity(0.3),
                    blurRadius: 4,
                    offset: const Offset(0, 2),
                  ),
                ],
              ),
              child: Material(
                color: Colors.transparent,
                child: InkWell(
                  borderRadius: BorderRadius.circular(22.5),
                  onTap: _sendTestTranscript,
                  child: const Icon(
                    Icons.send,
                    color: Colors.white,
                    size: 20,
                  ),
                ),
              ),
            ),
          ),
          // Mic button positioned at the top of the curve
          Positioned(
            bottom: 25,
            left: 0,
            right: 0,
            child: Center(
              child: Container(
                width: 65,
                height: 65,
                decoration: BoxDecoration(
                  color: _isListening ? errorColor : primaryColor,
                  shape: BoxShape.circle,
                  boxShadow: [
                    BoxShadow(
                      color: (_isListening ? errorColor : primaryColor)
                          .withOpacity(0.3),
                      blurRadius: 8,
                      offset: const Offset(0, 4),
                    ),
                  ],
                ),
                child: Material(
                  color: Colors.transparent,
                  child: InkWell(
                    borderRadius: BorderRadius.circular(30),
                    onTap: _isListening
                        ? _stopContinuousListening
                        : _startContinuousListening,
                    child: Center(
                      child: AnimatedSwitcher(
                        duration: const Duration(milliseconds: 200),
                        child: Icon(
                          _isListening ? Icons.stop : Icons.mic,
                          key: ValueKey(_isListening),
                          color: Colors.white,
                          size: 26,
                        ),
                      ),
                    ),
                  ),
                ),
              ),
            ),
          ),
        ],
      ),
    );
  }

  // UI PANELS REMOVED
  Widget _buildTarteelProgressPanel() {
    if (_ayatList.isEmpty || _currentAyatIndex >= _ayatList.length) {
      return const SizedBox.shrink();
    }

    final currentAyat = _ayatList[_currentAyatIndex];
    final totalWords = _getTotalWordsInCurrentAyah();
    final completedWords = _completedWords.length;
    final currentWords = _currentReadingWords.length;
    final progressPercent = totalWords > 0 ? (completedWords / totalWords * 100) : 0.0;
    
    // Color based on progress
    Color progressColor = completedColor;
    if (progressPercent < 40) {
      progressColor = errorColor;
    } else if (progressPercent < 80) {
      progressColor = warningColor;
    }

    return Container(
      margin: const EdgeInsets.symmetric(horizontal: 12, vertical: 4),
      padding: const EdgeInsets.symmetric(horizontal: 16, vertical: 12),
      decoration: BoxDecoration(
        gradient: LinearGradient(
          colors: [
            primaryColor.withOpacity(0.05),
            progressColor.withOpacity(0.1),
          ],
          begin: Alignment.centerLeft,
          end: Alignment.centerRight,
        ),
        borderRadius: BorderRadius.circular(12),
        border: Border.all(
          color: progressColor.withOpacity(0.3),
          width: 1,
        ),
        boxShadow: [
          BoxShadow(
            color: progressColor.withOpacity(0.1),
            blurRadius: 8,
            offset: const Offset(0, 2),
          ),
        ],
      ),
      child: Column(
        children: [
          // Title and word count
          Row(
            children: [
              Icon(
                Icons.auto_stories,
                size: 16,
                color: progressColor,
              ),
              const SizedBox(width: 8),
              Text(
                'Ayah ${currentAyat.ayah}',
                style: TextStyle(
                  fontSize: 12,
                  fontWeight: FontWeight.w600,
                  color: progressColor,
                ),
              ),
              const Spacer(),
              Container(
                padding: const EdgeInsets.symmetric(horizontal: 8, vertical: 2),
                decoration: BoxDecoration(
                  color: progressColor.withOpacity(0.15),
                  borderRadius: BorderRadius.circular(12),
                ),
                child: Text(
                  '$completedWords/$totalWords',
                  style: TextStyle(
                    fontSize: 11,
                    fontWeight: FontWeight.bold,
                    color: progressColor,
                  ),
                ),
              ),
              const SizedBox(width: 8),
              Text(
                '${progressPercent.toStringAsFixed(0)}%',
                style: TextStyle(
                  fontSize: 12,
                  fontWeight: FontWeight.w700,
                  color: progressColor,
                ),
              ),
            ],
          ),
          const SizedBox(height: 8),
          // Progress bar
          Container(
            height: 6,
            decoration: BoxDecoration(
              color: Colors.grey.withOpacity(0.2),
              borderRadius: BorderRadius.circular(3),
            ),
            child: ClipRRect(
              borderRadius: BorderRadius.circular(3),
              child: LinearProgressIndicator(
                value: progressPercent / 100,
                backgroundColor: Colors.transparent,
                valueColor: AlwaysStoppedAnimation<Color>(progressColor),
              ),
            ),
          ),
          const SizedBox(height: 6),
          // Status indicators
          Row(
            mainAxisAlignment: MainAxisAlignment.center,
            children: [
              if (currentWords > 0) ...[
                Container(
                  width: 8,
                  height: 8,
                  decoration: BoxDecoration(
                    color: currentColor,
                    shape: BoxShape.circle,
                  ),
                ),
                const SizedBox(width: 4),
                Text(
                  'Reading',
                  style: TextStyle(
                    fontSize: 9,
                    color: currentColor,
                    fontWeight: FontWeight.w500,
                  ),
                ),
                const SizedBox(width: 12),
              ],
              Container(
                width: 8,
                height: 8,
                decoration: BoxDecoration(
                  color: completedColor,
                  shape: BoxShape.circle,
                ),
              ),
              const SizedBox(width: 4),
              Text(
                'Completed',
                style: TextStyle(
                  fontSize: 9,
                  color: completedColor,
                  fontWeight: FontWeight.w500,
                ),
              ),
            ],
          ),
        ],
      ),
    );
  }

  Widget _buildAPIStatsPanel() {
    return Container(
      margin: const EdgeInsets.symmetric(horizontal: 8),
      padding: const EdgeInsets.all(8),
      decoration: BoxDecoration(
        color: accentColor.withOpacity(0.1),
        borderRadius: BorderRadius.circular(6),
        border: Border.all(color: accentColor.withOpacity(0.3)),
      ),
      child: Column(
        crossAxisAlignment: CrossAxisAlignment.start,
        children: [
          Text(
            'API Analytics',
            style: TextStyle(
              fontWeight: FontWeight.bold,
              color: accentColor,
              fontSize: 12,
            ),
          ),
          const SizedBox(height: 6),
          Row(
            children: [
              Expanded(
                child: _buildAnalyticsCard(
                  'API Calls',
                  '$_totalTranscriptsSent',
                  Icons.send,
                ),
              ),
              const SizedBox(width: 4),
              Expanded(
                child: _buildAnalyticsCard(
                  'Success Rate',
                  '${_totalTranscriptsSent > 0 ? ((_successfulAPIResponses / _totalTranscriptsSent) * 100).toStringAsFixed(0) : 0}%',
                  Icons.check_circle,
                ),
              ),
              const SizedBox(width: 4),
              Expanded(
                child: _buildAnalyticsCard(
                  'WebSocket',
                  _isWebSocketConnected ? 'Connected' : 'Disconnected',
                  _isWebSocketConnected ? Icons.wifi : Icons.wifi_off,
                ),
              ),
            ],
          ),
        ],
      ),
    );
  }

  Widget _buildAnalyticsCard(String title, String value, IconData icon) {
    return Container(
      padding: const EdgeInsets.all(4),
      decoration: BoxDecoration(
        color: Colors.white.withOpacity(0.7),
        borderRadius: BorderRadius.circular(4),
      ),
      child: Column(
        children: [
          Icon(icon, color: accentColor, size: 12),
          const SizedBox(height: 2),
          Text(
            title,
            style: const TextStyle(fontSize: 8, fontWeight: FontWeight.w500),
          ),
          Text(
            value,
            style: TextStyle(
              fontSize: 10,
              fontWeight: FontWeight.bold,
              color: accentColor,
            ),
          ),
        ],
      ),
    );
  }

  Widget _buildEnhancedQuranText() {
    return Container(
      margin: const EdgeInsets.all(8),
      padding: const EdgeInsets.all(8),
      decoration: BoxDecoration(
        color: Colors.white,
        borderRadius: BorderRadius.circular(8),
      ),
      child: SingleChildScrollView(
        child: Column(
          crossAxisAlignment: CrossAxisAlignment.stretch,
          children: [
            if (!_isQuranMode) ...[
              Divider(color: Colors.grey.shade300, thickness: 1),
              _buildSuratInfoHeader(),
              Divider(color: Colors.grey.shade300, thickness: 1),
              const SizedBox(height: 8),
            ],
            _isQuranMode
                ? _buildQuranModeDisplay()
                : _buildEnhancedAllAyatDisplay(),
          ],
        ),
      ),
    );
  }

  Widget _buildSuratInfoHeader() {
    if (_suratInfo.isEmpty) return const SizedBox.shrink();

    final parts = _suratInfo.split('(');
    final nama = parts[0].trim();
    String namalatin = '';
    String ayatInfo = '';

    if (parts.length > 1) {
      final remaining = parts[1];
      final closeParen = remaining.indexOf(')');
      if (closeParen > 0) {
        namalatin = remaining.substring(0, closeParen);
        final lastPart = remaining.substring(closeParen + 1).trim();
        if (lastPart.startsWith('(') && lastPart.endsWith(')')) {
          ayatInfo = lastPart.substring(1, lastPart.length - 1);
        }
      }
    }

    return Column(
      children: [
        const SizedBox(height: 2),
        if (namalatin.isNotEmpty || _suratArti.isNotEmpty)
          Row(
            mainAxisAlignment: MainAxisAlignment.center,
            crossAxisAlignment: CrossAxisAlignment.center,
            children: [
              _buildOrnament(),
              const SizedBox(width: 12),
              Expanded(
                child: Row(
                  mainAxisAlignment: MainAxisAlignment.center,
                  children: [
                    if (namalatin.isNotEmpty) ...[
                      Text(
                        namalatin,
                        style: TextStyle(
                          fontSize: 14,
                          fontWeight: FontWeight.w600,
                          color: primaryColor,
                        ),
                      ),
                      if (_suratArti.isNotEmpty) ...[
                        Text(
                          ' ‚Ä¢ ',
                          style: TextStyle(
                            fontSize: 12,
                            color: Colors.grey.shade500,
                          ),
                        ),
                        Text(
                          _suratArti,
                          style: TextStyle(
                            fontSize: 12,
                            fontStyle: FontStyle.italic,
                            color: Colors.grey.shade600,
                          ),
                        ),
                      ],
                    ] else if (_suratArti.isNotEmpty) ...[
                      Text(
                        _suratArti,
                        style: TextStyle(
                          fontSize: 12,
                          fontStyle: FontStyle.italic,
                          color: Colors.grey.shade600,
                        ),
                      ),
                    ],
                  ],
                ),
              ),
              const SizedBox(width: 12),
              _buildOrnament(),
            ],
          ),
        Container(
          height: 2,
          decoration: BoxDecoration(
            color: Colors.grey.shade200,
            borderRadius: BorderRadius.circular(1),
          ),
          child: LayoutBuilder(
            builder: (context, constraints) {
              final completedAyat = _ayatProgress.values
                  .where((p) => p.isCompleted)
                  .length;
              final totalAyat = _ayatList.length;
              final progress = totalAyat > 0 ? completedAyat / totalAyat : 0.0;
              return Stack(
                children: [
                  Container(
                    width: constraints.maxWidth * progress,
                    decoration: BoxDecoration(
                      gradient: LinearGradient(
                        colors: [primaryColor, correctColor],
                      ),
                      borderRadius: BorderRadius.circular(1),
                    ),
                  ),
                ],
              );
            },
          ),
        ),
        const SizedBox(height: 2),
      ],
    );
  }

  Widget _buildOrnament() {
    return Container(
      width: 20,
      height: 20,
      decoration: BoxDecoration(
        color: primaryColor.withOpacity(0.1),
        shape: BoxShape.circle,
        border: Border.all(color: primaryColor.withOpacity(0.2), width: 1),
      ),
      child: Center(
        child: Container(
          width: 8,
          height: 8,
          decoration: BoxDecoration(
            color: primaryColor.withOpacity(0.3),
            shape: BoxShape.circle,
          ),
        ),
      ),
    );
  }

  Widget _buildQuranModeDisplay() {
    return GestureDetector(
      onHorizontalDragEnd: (DragEndDetails details) {
        if (details.velocity.pixelsPerSecond.dx > 300) {
          // Swipe kanan - ke halaman sebelumnya
          if (_currentPage > 1) {
            _navigateToPage(_currentPage + 1);
          }
        } else if (details.velocity.pixelsPerSecond.dx < -300) {
          // Swipe kiri - ke halaman berikutnya
          if (_currentPage < 604) {
            _navigateToPage(_currentPage - 1);
          }
        }
      },
      child: _currentPageAyats.isEmpty
          ? const Center(
              child: Text(
                'No ayats found for this page',
                style: TextStyle(fontSize: 14, color: Colors.grey),
              ),
            )
          : SingleChildScrollView(
              padding: const EdgeInsets.all(0),
              child: Container(
                decoration: BoxDecoration(
                  color: Color.fromARGB(255, 255, 255, 255),
                ),
                padding: const EdgeInsets.all(16),
                child: Stack(
                  children: [
                    Positioned(
                      top: 0,
                      left: 0,
                      child: Text(
                        'Juz ${_currentPageAyats.isNotEmpty ? _currentPageAyats.first.juz : '1'}',
                        style: TextStyle(
                          fontSize: 12,
                          color: Colors.grey.shade600,
                          fontWeight: FontWeight.w500,
                        ),
                      ),
                    ),
                    Positioned(
                      top: 0,
                      right: 0,
                      child: Text(
                        'Page $_currentPage',
                        style: TextStyle(
                          fontSize: 12,
                          color: Colors.grey.shade600,
                          fontWeight: FontWeight.w500,
                        ),
                      ),
                    ),
                    Padding(
                      padding: const EdgeInsets.only(top: 18),
                      child: _buildContinuousQuranText(),
                    ),
                  ],
                ),
              ),
            ),
    );
  }

  Widget _buildContinuousQuranText() {
    List<Widget> pageElements = [];

    Map<int, List<AyatData>> ayatsBySurah = {};
    for (final ayat in _currentPageAyats) {
      if (!ayatsBySurah.containsKey(ayat.surah_id)) {
        ayatsBySurah[ayat.surah_id] = [];
      }
      ayatsBySurah[ayat.surah_id]!.add(ayat);
    }

    ayatsBySurah.forEach((surahId, ayats) {
      bool isNewSurah = ayats.any((ayat) => ayat.ayah == 1);

      if (isNewSurah && surahId != 1 && surahId != 9) {
        pageElements.add(_buildSurahHeaderInPage(surahId));
        pageElements.add(_buildBismillahInPage());
      }

      List<InlineSpan> textSpans = [];

      for (int i = 0; i < ayats.length; i++) {
        final ayat = ayats[i];

        int ayatIndex = _ayatList.indexWhere(
          (a) => a.surah_id == ayat.surah_id && a.ayah == ayat.ayah,
        );
        bool isCurrentAyat = ayatIndex >= 0 && ayatIndex == _currentAyatIndex;

        textSpans.addAll(
          _buildContinuousAyatSpansWithAPI(ayat, ayatIndex, isCurrentAyat),
        );

        textSpans.add(
          TextSpan(
            text: ' ${_getArabicNumber(ayat.ayah)} ',
            style: TextStyle(
              fontSize: 25,
              fontFamily: 'Uthmanic',
              color: const Color.fromARGB(150, 0, 0, 0),
              fontWeight: FontWeight.bold,
            ),
          ),
        );

        if (i < ayats.length - 1 || ayatsBySurah.keys.last != surahId) {
          textSpans.add(TextSpan(text: ' '));
        }
      }

      pageElements.add(
        RichText(
          textAlign: TextAlign.justify,
          textDirection: TextDirection.rtl,
          text: TextSpan(
            style: const TextStyle(
              fontSize: 25,
              fontFamily: 'KFGQPCUthmanicScriptHAFSRegular',
              wordSpacing: -5.9,
              letterSpacing: -0.5,
            ),
            children: textSpans,
          ),
        ),
      );
    });

    return Column(
      crossAxisAlignment: CrossAxisAlignment.stretch,
      children: pageElements,
    );
  }

  List<InlineSpan> _buildContinuousAyatSpansWithAPI(
    AyatData ayat,
    int ayatIndex,
    bool isCurrentAyat,
  ) {
    final arabicWords = ayat.arabic
        .split(' ')
        .where((w) => w.trim().isNotEmpty)
        .toList();
    List<InlineSpan> spans = [];

    for (int wordIndex = 0; wordIndex < arabicWords.length; wordIndex++) {
      final word = arabicWords[wordIndex];

      // Get status from API results
      APIWordResult? wordResult;
      if (isCurrentAyat && wordIndex < _currentAyatResults.length) {
        wordResult = _currentAyatResults[wordIndex];
      }

      final status = wordResult?.getReadingStatus() ?? ReadingStatus.notRead;
      final isCurrentWord =
          isCurrentAyat; // For now, highlight entire current ayat

      double wordOpacity = 1.0;
      if (_hideUnreadAyat &&
          status == ReadingStatus.notRead &&
          !isCurrentWord) {
        wordOpacity = 0.0;
      }

      spans.add(
        TextSpan(
          text: '$word ',
          style: TextStyle(
            fontSize: 24,
            fontFamily: 'KFGQPCUthmanicScriptHAFSRegular',
            color: _getAPIWordTextColor(
              status,
              isCurrentWord,
            ).withOpacity(wordOpacity),
            backgroundColor: wordResult != null 
                ? wordResult.getBackgroundColor().withOpacity(wordOpacity)
                : (isCurrentWord ? listeningColor.withOpacity(0.2 * wordOpacity) : null),
            fontWeight: _getWordFontWeight(0.0, isCurrentWord),
          ),
        ),
      );
    }

    return spans;
  }

  Color _getAPIWordTextColor(ReadingStatus status, bool isCurrentWord) {
    if (isCurrentWord) return listeningColor;
    return Colors.black87;
  }

  Color _getAPIStatusColor(ReadingStatus status, bool isCurrentWord) {
    if (isCurrentWord) return listeningColor;

    switch (status) {
      case ReadingStatus.notRead:
        return unreadColor;
      case ReadingStatus.correct:
        return correctColor;
      case ReadingStatus.error:
        return errorColor;
      case ReadingStatus.skipped:
        return skippedColor;
    }
  }

  FontWeight _getWordFontWeight(double confidence, bool isCurrentWord) {
    if (isCurrentWord) return FontWeight.w600;
    return FontWeight.w500;
  }
  
  // üéØ TARTEEL-STYLE: Font weight for live recognition
  FontWeight _getTarteelWordWeight(bool isCurrentWord, bool isCompletedWord) {
    if (isCompletedWord) return FontWeight.w700; // ‚úÖ Bold for completed
    if (isCurrentWord) return FontWeight.w600;   // üîµ Semi-bold for current
    return FontWeight.w400;                      // üìç Normal for unread
  }
  
  // üéØ ENHANCED: Smart Arabic word matching for Quranic text
  bool _isWordMatch(String expectedWord, String spokenWord) {
    if (expectedWord.isEmpty || spokenWord.isEmpty) return false;
    
    // Strategy 1: Exact match
    if (expectedWord == spokenWord) {
      return true;
    }
    
    // Strategy 2: Contains match (either direction)
    if (expectedWord.contains(spokenWord) || spokenWord.contains(expectedWord)) {
      return true;
    }
    
    // Strategy 3: Similarity match for Arabic words
    if (_calculateSimilarity(expectedWord, spokenWord) > 0.7) {
      return true;
    }
    
    // Strategy 4: Special cases for common Arabic patterns
    if (_isArabicPatternMatch(expectedWord, spokenWord)) {
      return true;
    }
    
    return false;
  }
  
  // üìà Calculate similarity between two Arabic words
  double _calculateSimilarity(String word1, String word2) {
    if (word1.isEmpty || word2.isEmpty) return 0.0;
    
    int longer = word1.length > word2.length ? word1.length : word2.length;
    if (longer == 0) return 1.0;
    
    int distance = _levenshteinDistance(word1, word2);
    return (longer - distance) / longer;
  }
  
  
  // üï∞Ô∏è Special Arabic pattern matching
  bool _isArabicPatternMatch(String expectedWord, String spokenWord) {
    // Handle common Arabic root patterns
    
    // Remove common prefixes/suffixes
    final expectedClean = expectedWord
        .replaceAll(RegExp(r'^(ÿßŸÑ|ŸàÿßŸÑ|ÿ®ÿßŸÑ|ŸÑŸÑ)'), '') // Remove ÿßŸÑÿå ŸàÿßŸÑÿå ÿ®ÿßŸÑÿå ŸÑŸÑ
        .replaceAll(RegExp(r'(ÿ©|Ÿá)$'), ''); // Remove ÿ©ÿå Ÿá endings
        
    final spokenClean = spokenWord
        .replaceAll(RegExp(r'^(ÿßŸÑ|ŸàÿßŸÑ|ÿ®ÿßŸÑ|ŸÑŸÑ)'), '')
        .replaceAll(RegExp(r'(ÿ©|Ÿá)$'), '');
    
    return expectedClean.contains(spokenClean) || spokenClean.contains(expectedClean);
  }

  bool _shouldShowWordBackground(ReadingStatus status, bool isCurrentWord) {
    if (!_hideUnreadAyat)
      return status != ReadingStatus.notRead || isCurrentWord;
    return isCurrentWord || status != ReadingStatus.notRead;
  }

  Widget _buildSurahHeaderInPage(int surahId) {
    return Container(
      margin: const EdgeInsets.symmetric(vertical: 0),
      child: Stack(
        alignment: Alignment.center,
        children: [
          Image.asset(
            "assets/images/headerquran/headerquran.png",
            fit: BoxFit.contain,
            width: double.infinity,
          ),
          Text(
            'ÿ≥ŸèŸàÿ±Ÿéÿ© ${widget.suratName}',
            style: const TextStyle(
              fontSize: 22,
              fontFamily: 'KFGQPCUthmanicScriptHAFSRegular',
              fontWeight: FontWeight.w500,
              color: Colors.black,
            ),
            textAlign: TextAlign.center,
          ),
        ],
      ),
    );
  }

  Widget _buildBismillahInPage() {
    return Padding(
      padding: const EdgeInsets.symmetric(vertical: 2),
      child: Text(
        'k',
        style: TextStyle(
          fontSize: 27,
          fontFamily: '110BesmellahNormal',
          color: Colors.black87,
        ),
        textAlign: TextAlign.center,
      ),
    );
  }

  String _getArabicNumber(int number) {
    const arabicNumbers = ['Ÿ†', 'Ÿ°', 'Ÿ¢', 'Ÿ£', 'Ÿ§', 'Ÿ•', 'Ÿ¶', 'Ÿß', 'Ÿ®', 'Ÿ©'];
    return number
        .toString()
        .split('')
        .map((digit) => arabicNumbers[int.parse(digit)])
        .join();
  }

  Future<void> _navigateToPage(int newPage) async {
    setState(() {
      _currentPage = newPage;
    });
    await _loadCurrentPageAyats();
  }

  Widget _buildEnhancedAllAyatDisplay() {
    List<Widget> ayatWidgets = [];

    ayatWidgets.add(
      Padding(
        padding: const EdgeInsets.fromLTRB(0, 3, 0, 0),
        child: Container(
          padding: const EdgeInsets.symmetric(horizontal: 0, vertical: 0),
          child: const Text(
            'k',
            style: TextStyle(
              fontSize: 43,
              fontFamily: '110BesmellahNormal',
              fontWeight: FontWeight.normal,
              height: 0.8,
              color: Colors.black,
            ),
            textAlign: TextAlign.center,
          ),
        ),
      ),
    );

    for (int ayatIndex = 0; ayatIndex < _ayatList.length; ayatIndex++) {
      final ayat = _ayatList[ayatIndex];
      final isCurrentAyat = ayatIndex == _currentAyatIndex;

      ayatWidgets.add(_buildEnhancedAyatHeader(ayatIndex, isCurrentAyat));
      ayatWidgets.add(
        _buildEnhancedColoredAyatText(ayat, ayatIndex, isCurrentAyat),
      );
    }

    return Column(
      crossAxisAlignment: CrossAxisAlignment.stretch,
      children: ayatWidgets,
    );
  }

  Widget _buildEnhancedAyatHeader(int ayatIndex, bool isCurrentAyat) {
    final progress = _ayatProgress[ayatIndex];
    final completionPercentage = progress?.completionPercentage ?? 0.0;

    return Container(
      key: _ayatKeys[ayatIndex],
      margin: const EdgeInsets.symmetric(vertical: 4),
      child: Row(
        mainAxisAlignment: MainAxisAlignment.spaceBetween,
        children: [
          Expanded(
            child: Container(
              height: 1,
              decoration: BoxDecoration(
                color: Colors.grey.shade300,
                borderRadius: BorderRadius.circular(2),
              ),
              child: ClipRRect(
                borderRadius: BorderRadius.circular(2),
                child: LinearProgressIndicator(
                  value: completionPercentage / 100,
                  backgroundColor: Colors.transparent,
                  valueColor: AlwaysStoppedAnimation<Color>(
                    completionPercentage >= 80.0 ? correctColor : // Green when completed (80%+)
                    (isCurrentAyat ? listeningColor : Colors.grey.shade400), // Blue when current, gray otherwise
                  ),
                ),
              ),
            ),
          ),
          const SizedBox(width: 8),
          Container(
            padding: const EdgeInsets.symmetric(horizontal: 6, vertical: 2),
            decoration: BoxDecoration(
              color: isCurrentAyat ? primaryColor : Colors.grey.shade400,
              borderRadius: BorderRadius.circular(4),
            ),
            child: Text(
              '${_ayatList[ayatIndex].ayah}',
              style: const TextStyle(
                color: Colors.white,
                fontWeight: FontWeight.bold,
                fontSize: 12,
              ),
            ),
          ),
        ],
      ),
    );
  }

  Widget _buildEnhancedColoredAyatText(
    AyatData ayat,
    int ayatIndex,
    bool isCurrentAyat,
  ) {
    final arabicWords = ayat.arabic
        .split(' ')
        .where((w) => w.trim().isNotEmpty)
        .toList();

    return Wrap(
      alignment: WrapAlignment.start,
      textDirection: TextDirection.rtl,
      spacing: 0,
      runSpacing: 8,
      children: arabicWords.asMap().entries.map((entry) {
        final wordIndex = entry.key;
        final word = entry.value;

        // Get status from API results
        APIWordResult? wordResult;
        if (isCurrentAyat && wordIndex < _currentAyatResults.length) {
          wordResult = _currentAyatResults[wordIndex];
        }

        return _buildEnhancedWordWidget(
          word,
          wordResult,
          isCurrentAyat,
          wordIndex,
        );
      }).toList(),
    );
  }

  Widget _buildEnhancedWordWidget(
    String word,
    APIWordResult? wordResult,
    bool isCurrentAyat,
    int wordIndex,
  ) {
    // üéØ TARTEEL-STYLE: Get status from live word highlighting
    final status = wordResult?.getReadingStatus() ?? ReadingStatus.notRead;
    
    // ‚ö° REAL-TIME: Get live word status from backend updates
    final liveWordStatus = _wordStatus[wordIndex];
    final wordHighlight = _wordHighlights[wordIndex];
    final isCurrentWord = isCurrentAyat && _currentReadingWords.contains(wordIndex);
    final isCompletedWord = isCurrentAyat && _completedWords.contains(wordIndex);
    
    // üåà Dynamic status based on real-time backend updates
    ReadingStatus liveStatus = status;
    Color backgroundColor = Colors.transparent;
    Color textColor = Colors.black87;
    
    if (liveWordStatus != null && isCurrentAyat) {
      // Use real-time status from backend
      final backendStatus = liveWordStatus['status'] as String?;
      final backendColor = liveWordStatus['color'] as String?;
      final highlight = liveWordStatus['highlight'] as bool? ?? false;
      
      switch (backendStatus) {
        case 'matched':
          liveStatus = ReadingStatus.correct;
          backgroundColor = completedColor.withOpacity(0.4);
          textColor = completedColor;
          break;
        case 'mismatched':
          liveStatus = ReadingStatus.error;
          backgroundColor = errorColor.withOpacity(0.4);
          textColor = errorColor;
          break;
        case 'provis_matched':
          liveStatus = ReadingStatus.correct;
          backgroundColor = currentColor.withOpacity(0.3);
          textColor = currentColor;
          break;
        case 'skipped':
          backgroundColor = Colors.orange.withOpacity(0.3);
          textColor = Colors.orange.shade700;
          break;
        default:
          // Use legacy highlighting
          if (isCompletedWord) {
            backgroundColor = completedColor.withOpacity(0.3);
            textColor = completedColor;
          } else if (isCurrentWord) {
            backgroundColor = currentColor.withOpacity(0.3);
            textColor = currentColor;
          }
      }
    } else {
      // Fallback to legacy highlighting
      if (isCompletedWord) {
        liveStatus = ReadingStatus.correct;
        backgroundColor = completedColor.withOpacity(0.3);
        textColor = completedColor;
      } else if (isCurrentWord) {
        liveStatus = ReadingStatus.notRead; // Will be styled as "reading"
        backgroundColor = currentColor.withOpacity(0.3);
        textColor = currentColor;
      }
    }

    bool showColors = liveStatus != ReadingStatus.notRead || isCurrentWord || liveWordStatus != null;

    return GestureDetector(
      onTap: () {
        if (wordResult != null) {
          _showAPIWordDetails(wordResult, wordIndex);
        }
      },
      child: AnimatedContainer(
        duration: const Duration(milliseconds: 300),
        curve: Curves.easeOutCubic,
        padding: const EdgeInsets.symmetric(horizontal: 6, vertical: 3),
        decoration: BoxDecoration(
          color: backgroundColor,
          borderRadius: BorderRadius.circular(6),
          // ‚ú® Add subtle border for current word
          border: isCurrentWord ? Border.all(color: currentColor, width: 1) : null,
        ),
        child: AnimatedOpacity(
          duration: const Duration(milliseconds: 200),
          opacity: _shouldShowWord(liveStatus, isCurrentWord || isCompletedWord) ? 1.0 : 0.0,
          child: Text(
            word,
            style: TextStyle(
              fontSize: 26,
              fontFamily: 'KFGQPCUthmanicScriptHAFSRegular',
              color: textColor, // ‚ö° Use live text color
              fontWeight: _getTarteelWordWeight(isCurrentWord, isCompletedWord),
              height: 1.5,
            ),
            textDirection: TextDirection.rtl,
          ),
        ),
      ),
    );
  }

  bool _shouldShowWord(ReadingStatus status, bool isCurrentWord) {
    if (!_hideUnreadAyat) return true;
    if (isCurrentWord) return true;
    if (status != ReadingStatus.notRead) return true;
    return false;
  }

  void _showAPIWordDetails(APIWordResult wordResult, int wordIndex) {
    showDialog(
      context: context,
      builder: (BuildContext context) {
        return AlertDialog(
          title: Row(
            children: [
              Icon(Icons.api, color: primaryColor, size: 18),
              const SizedBox(width: 4),
              const Text('API Word Analysis', style: TextStyle(fontSize: 14)),
            ],
          ),
          content: SingleChildScrollView(
            child: Column(
              mainAxisSize: MainAxisSize.min,
              crossAxisAlignment: CrossAxisAlignment.start,
              children: [
                Container(
                  width: double.infinity,
                  padding: const EdgeInsets.all(8),
                  decoration: BoxDecoration(
                    color: Colors.grey.shade50,
                    borderRadius: BorderRadius.circular(6),
                  ),
                  child: Text(
                    wordResult.expected,
                    style: const TextStyle(
                      fontSize: 24,
                      fontFamily: 'KFGQPCUthmanicScriptHAFSRegular',
                      fontWeight: FontWeight.bold,
                    ),
                    textAlign: TextAlign.center,
                    textDirection: TextDirection.rtl,
                  ),
                ),
                const SizedBox(height: 8),
                _buildAPIDetailCard('Position', '${wordResult.position + 1}'),
                _buildAPIDetailCard('Expected', wordResult.expected),
                _buildAPIDetailCard('Spoken', wordResult.spoken),
                _buildAPIDetailCard('Status', wordResult.status),
                _buildAPIDetailCard(
                  'Similarity Score',
                  '${(wordResult.similarity_score * 100).toStringAsFixed(1)}%',
                ),
              ],
            ),
          ),
          actions: [
            TextButton(
              onPressed: () => Navigator.of(context).pop(),
              child: const Text('Close', style: TextStyle(fontSize: 12)),
            ),
          ],
        );
      },
    );
  }

  Widget _buildAPIDetailCard(String label, String value) {
    return Container(
      margin: const EdgeInsets.only(bottom: 4),
      padding: const EdgeInsets.all(6),
      decoration: BoxDecoration(
        color: Colors.white,
        borderRadius: BorderRadius.circular(4),
        border: Border.all(color: Colors.grey.shade300),
      ),
      child: Row(
        crossAxisAlignment: CrossAxisAlignment.start,
        children: [
          SizedBox(
            width: 80,
            child: Text(
              '$label:',
              style: const TextStyle(fontWeight: FontWeight.w600, fontSize: 10),
            ),
          ),
          Expanded(child: Text(value, style: const TextStyle(fontSize: 10))),
        ],
      ),
    );
  }

  // ==================== UTILITY METHODS ====================

  void _showEnhancedSnackBar(String message, SnackBarType type) {
    if (!mounted) return;

    Color backgroundColor;
    IconData icon;

    switch (type) {
      case SnackBarType.success:
        backgroundColor = correctColor;
        icon = Icons.check_circle;
        break;
      case SnackBarType.error:
        backgroundColor = errorColor;
        icon = Icons.error;
        break;
      case SnackBarType.warning:
        backgroundColor = warningColor;
        icon = Icons.warning;
        break;
      case SnackBarType.info:
        backgroundColor = listeningColor;
        icon = Icons.info;
        break;
    }

    ScaffoldMessenger.of(context).showSnackBar(
      SnackBar(
        content: Row(
          children: [
            Icon(icon, color: Colors.white, size: 16),
            const SizedBox(width: 4),
            Expanded(
              child: Text(message, style: const TextStyle(fontSize: 12)),
            ),
          ],
        ),
        backgroundColor: backgroundColor,
        duration: const Duration(seconds: 2),
        behavior: SnackBarBehavior.floating,
        shape: RoundedRectangleBorder(borderRadius: BorderRadius.circular(6)),
      ),
    );
  }

  void _toggleLogs() {
    setState(() {
      _showLogs = !_showLogs;
    });
  }

  void _showAPIStatus() {
    showDialog(
      context: context,
      builder: (BuildContext context) {
        return AlertDialog(
          title: const Text('API Status', style: TextStyle(fontSize: 16)),
          content: SingleChildScrollView(
            child: Column(
              mainAxisSize: MainAxisSize.min,
              crossAxisAlignment: CrossAxisAlignment.start,
              children: [
                _buildStatusRow('Session Active', _isSessionActive ? '‚úì' : '‚úó'),
                _buildStatusRow('Session ID', _activeSessionId ?? 'N/A'),
                _buildStatusRow(
                  'WebSocket',
                  _isWebSocketConnected ? 'Connected' : 'Disconnected',
                ),
                _buildStatusRow('Current Ayat', '$_currentAyatNumber'),
                _buildStatusRow('API Calls', '$_totalTranscriptsSent'),
                _buildStatusRow(
                  'Success Rate',
                  '${_totalTranscriptsSent > 0 ? ((_successfulAPIResponses / _totalTranscriptsSent) * 100).toStringAsFixed(1) : 0}%',
                ),
                const SizedBox(height: 8),
                Text(
                  'Recent API Logs:',
                  style: TextStyle(fontWeight: FontWeight.bold, fontSize: 12),
                ),
                Container(
                  height: 100,
                  child: ListView.builder(
                    itemCount: _apiLogs.length,
                    itemBuilder: (context, index) {
                      final log = _apiLogs[_apiLogs.length - 1 - index];
                      return Text(
                        '${log.method} ${log.endpoint} - ${log.statusCode} - ${log.message}',
                        style: TextStyle(
                          fontSize: 10,
                          color: Colors.grey.shade600,
                        ),
                      );
                    },
                  ),
                ),
              ],
            ),
          ),
          actions: [
            TextButton(
              onPressed: () => Navigator.pop(context),
              child: const Text('Close'),
            ),
          ],
        );
      },
    );
  }

  Widget _buildStatusRow(String label, String value) {
    return Padding(
      padding: const EdgeInsets.only(bottom: 4),
      child: Row(
        mainAxisAlignment: MainAxisAlignment.spaceBetween,
        children: [
          Text(label, style: const TextStyle(fontSize: 12)),
          Text(
            value,
            style: const TextStyle(fontSize: 12, fontWeight: FontWeight.bold),
          ),
        ],
      ),
    );
  }

  void _showSTTSettings() {
    showDialog(
      context: context,
      builder: (BuildContext context) {
        return StatefulBuilder(
          builder: (context, setDialogState) {
            return AlertDialog(
              title: const Text(
                'API STT Settings',
                style: TextStyle(fontSize: 16),
              ),
              content: SingleChildScrollView(
                child: Column(
                  mainAxisSize: MainAxisSize.min,
                  children: [
                    SwitchListTile(
                      title: const Text(
                        'Auto Send Transcripts',
                        style: TextStyle(fontSize: 12),
                      ),
                      subtitle: const Text(
                        'Automatically send to API',
                        style: TextStyle(fontSize: 10),
                      ),
                      value: _autoSendEnabled,
                      onChanged: (value) {
                        setDialogState(() {
                          _autoSendEnabled = value;
                        });
                      },
                    ),
                    SwitchListTile(
                      title: const Text(
                        'Auto Move Ayat (Tarteel)',
                        style: TextStyle(fontSize: 12),
                      ),
                      subtitle: const Text(
                        'Auto advance when ayah completed',
                        style: TextStyle(fontSize: 10),
                      ),
                      value: _autoMoveEnabled,
                      onChanged: (value) {
                        setDialogState(() {
                          _autoMoveEnabled = value;
                          _autoAdvanceEnabled = value;  // Sync both settings
                        });
                      },
                    ),
                    ListTile(
                      title: const Text(
                        'Auto Send Delay',
                        style: TextStyle(fontSize: 12),
                      ),
                      subtitle: Text(
                        '${_autoSendDelay.inSeconds}s',
                        style: const TextStyle(fontSize: 10),
                      ),
                      trailing: SizedBox(
                        width: 100,
                        child: Slider(
                          value: _autoSendDelay.inSeconds.toDouble(),
                          min: 1.0,
                          max: 5.0,
                          divisions: 4,
                          onChanged: (value) {
                            setDialogState(() {
                              _autoSendDelay = Duration(seconds: value.toInt());
                            });
                          },
                        ),
                      ),
                    ),
                  ],
                ),
              ),
              actions: [
                TextButton(
                  onPressed: () {
                    setState(() {});
                    Navigator.pop(context);
                    _showEnhancedSnackBar(
                      'Settings updated',
                      SnackBarType.success,
                    );
                  },
                  child: const Text('Apply', style: TextStyle(fontSize: 12)),
                ),
              ],
            );
          },
        );
      },
    );
  }

  void _showResetDialog() {
    showDialog(
      context: context,
      builder: (BuildContext context) {
        return AlertDialog(
          title: Row(
            children: [
              Icon(Icons.warning, color: warningColor, size: 18),
              const SizedBox(width: 4),
              const Text('Reset Session', style: TextStyle(fontSize: 14)),
            ],
          ),
          content: const Text(
            'Reset current session? This will end the API session and restart.',
            style: TextStyle(fontSize: 12),
          ),
          actions: [
            TextButton(
              onPressed: () => Navigator.of(context).pop(),
              child: const Text('Cancel', style: TextStyle(fontSize: 12)),
            ),
            ElevatedButton(
              onPressed: () {
                Navigator.of(context).pop();
                _performReset();
              },
              style: ElevatedButton.styleFrom(backgroundColor: errorColor),
              child: const Text('Reset', style: TextStyle(fontSize: 12)),
            ),
          ],
        );
      },
    );
  }

  void _performReset() {
    _log('RESET: Performing session reset');

    // End current API session
    _endAPISession();

    setState(() {
      _currentAyatIndex = 0;
      _currentAyatNumber = _ayatList.isNotEmpty ? _ayatList[0].ayah : 1;
      _currentAyatResults.clear();
      _ayatProgress.clear();
      _liveTranscript = '';
      _confirmedTranscript = '';
      _transcriptHistory.clear();
      _apiLogs.clear();
      _totalTranscriptsSent = 0;
      _successfulAPIResponses = 0;
      _sessionStartTime = DateTime.now();
      
      // ‚ö° TARTEEL-STYLE: Clear live highlighting status
      _wordHighlights.clear();
      _currentReadingWords.clear();
      _completedWords.clear();
      _errorWords.clear();
      _wordStatus.clear();
      _currentWordIndex = 0;
      _livePartialTranscript = '';
      _wordsMatched = 0;
      _completionPercentage = 0.0;
      _overallStatus = 'pending';
    });

    _showEnhancedSnackBar('Session reset', SnackBarType.info);
  }

  void _exportSession() {
    final sessionData = {
      'surah': widget.suratName,
      'session_id': _activeSessionId,
      'api_calls': _totalTranscriptsSent,
      'successful_responses': _successfulAPIResponses,
      'success_rate': _totalTranscriptsSent > 0
          ? (_successfulAPIResponses / _totalTranscriptsSent * 100)
          : 0,
      'session_duration': _sessionStartTime != null
          ? DateTime.now().difference(_sessionStartTime!).inMinutes
          : 0,
      'transcript_history': _transcriptHistory,
      'api_logs': _apiLogs.map((log) => log.toJson()).toList(),
      'completed_ayat': _ayatProgress.values.where((p) => p.isCompleted).length,
      'total_ayat': _ayatList.length,
    };

    _log('EXPORT: Session exported - ${jsonEncode(sessionData)}');
    _showEnhancedSnackBar('Session exported to logs', SnackBarType.success);
  }

  Widget _buildEnhancedLoadingWidget() {
    return Center(
      child: Column(
        mainAxisAlignment: MainAxisAlignment.center,
        children: [
          Container(
            width: 60,
            height: 60,
            decoration: BoxDecoration(
              color: primaryColor,
              shape: BoxShape.circle,
            ),
            child: const Center(
              child: CircularProgressIndicator(
                valueColor: AlwaysStoppedAnimation<Color>(Colors.white),
                strokeWidth: 2,
              ),
            ),
          ),
          const SizedBox(height: 12),
          Text(
            'Initializing API STT...',
            style: TextStyle(
              fontSize: 16,
              fontWeight: FontWeight.bold,
              color: primaryColor,
            ),
          ),
          const SizedBox(height: 4),
          Text(
            _errorMessage.isNotEmpty
                ? _errorMessage
                : 'Setting up API integration...',
            style: TextStyle(fontSize: 12, color: Colors.grey.shade600),
            textAlign: TextAlign.center,
          ),
        ],
      ),
    );
  }

  Widget _buildEnhancedErrorWidget() {
    return Center(
      child: Padding(
        padding: const EdgeInsets.all(16.0),
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          children: [
            Container(
              width: 80,
              height: 80,
              decoration: BoxDecoration(
                color: errorColor.withOpacity(0.1),
                shape: BoxShape.circle,
                border: Border.all(color: errorColor.withOpacity(0.3)),
              ),
              child: Icon(Icons.error_outline, size: 40, color: errorColor),
            ),
            const SizedBox(height: 12),
            Text(
              'API STT Initialization Error',
              style: TextStyle(
                fontSize: 18,
                fontWeight: FontWeight.bold,
                color: primaryColor,
              ),
              textAlign: TextAlign.center,
            ),
            const SizedBox(height: 8),
            Container(
              padding: const EdgeInsets.all(8),
              decoration: BoxDecoration(
                color: Colors.grey.shade50,
                borderRadius: BorderRadius.circular(6),
                border: Border.all(color: Colors.grey.shade300),
              ),
              child: Text(
                _errorMessage,
                textAlign: TextAlign.center,
                style: const TextStyle(fontSize: 12),
              ),
            ),
            const SizedBox(height: 12),
            Row(
              mainAxisAlignment: MainAxisAlignment.center,
              children: [
                ElevatedButton.icon(
                  onPressed: _initializeApp,
                  icon: const Icon(Icons.refresh, size: 16),
                  label: const Text('Retry', style: TextStyle(fontSize: 12)),
                  style: ElevatedButton.styleFrom(
                    backgroundColor: primaryColor,
                    foregroundColor: Colors.white,
                    padding: const EdgeInsets.symmetric(
                      horizontal: 8,
                      vertical: 4,
                    ),
                  ),
                ),
                const SizedBox(width: 8),
                TextButton.icon(
                  onPressed: _toggleLogs,
                  icon: const Icon(Icons.bug_report, size: 16),
                  label: const Text(
                    'View Logs',
                    style: TextStyle(fontSize: 12),
                  ),
                ),
              ],
            ),
          ],
        ),
      ),
    );
  }

  Widget _buildEnhancedLogsPanel() {
    return Container(
      height: 150,
      decoration: BoxDecoration(
        color: Colors.black87,
        borderRadius: const BorderRadius.vertical(top: Radius.circular(12)),
      ),
      child: Column(
        children: [
          Container(
            padding: const EdgeInsets.symmetric(horizontal: 8, vertical: 6),
            decoration: const BoxDecoration(
              color: Colors.black,
              borderRadius: BorderRadius.vertical(top: Radius.circular(12)),
            ),
            child: Row(
              children: [
                Icon(Icons.terminal, color: correctColor, size: 16),
                const SizedBox(width: 4),
                const Text(
                  'API Debug Console',
                  style: TextStyle(
                    color: Colors.white,
                    fontWeight: FontWeight.bold,
                    fontSize: 12,
                  ),
                ),
                const Spacer(),
                IconButton(
                  icon: const Icon(Icons.clear, color: Colors.white, size: 16),
                  onPressed: () {
                    setState(() {
                      _logs.clear();
                      _apiLogs.clear();
                    });
                  },
                ),
                IconButton(
                  icon: const Icon(
                    Icons.save_alt,
                    color: Colors.white,
                    size: 16,
                  ),
                  onPressed: _exportSession,
                ),
                IconButton(
                  icon: const Icon(Icons.close, color: Colors.white, size: 16),
                  onPressed: _toggleLogs,
                ),
              ],
            ),
          ),
          Expanded(
            child: ListView.builder(
              reverse: true,
              padding: const EdgeInsets.all(4),
              itemCount: _logs.length,
              itemBuilder: (context, index) {
                final logIndex = _logs.length - 1 - index;
                final log = _logs[logIndex];

                Color logColor = Colors.greenAccent;
                if (log.contains('ERROR') || log.contains('Failed')) {
                  logColor = Colors.redAccent;
                } else if (log.contains('WARNING') || log.contains('Warning')) {
                  logColor = Colors.orangeAccent;
                } else if (log.contains('API_') || log.contains('WEBSOCKET')) {
                  logColor = Colors.cyanAccent;
                }

                return Padding(
                  padding: const EdgeInsets.symmetric(vertical: 1),
                  child: Text(
                    log,
                    style: TextStyle(
                      color: logColor,
                      fontSize: 8,
                      fontFamily: 'monospace',
                    ),
                  ),
                );
              },
            ),
          ),
        ],
      ),
    );
  }
}

// ==================== DATA CLASSES ====================

class AyatData {
  final int surah_id;
  final int ayah;
  final String arabic;
  final String noTashkeel;
  final String transliteration;
  final List<String> wordsArrayNt;
  final int page;
  final int juz;
  final double quarterHizb;

  AyatData({
    required this.surah_id,
    required this.ayah,
    required this.arabic,
    required this.noTashkeel,
    required this.transliteration,
    required this.wordsArrayNt,
    required this.page,
    required this.juz,
    required this.quarterHizb,
  });

  factory AyatData.fromJson(Map<String, dynamic> json) {
    return AyatData(
      surah_id: json['surah_id'] ?? 0,
      ayah: json['ayah'] ?? 0,
      arabic: json['arabic'] ?? '',
      noTashkeel: json['no_tashkeel'] ?? '',
      transliteration: json['transliteration'] ?? '',
      wordsArrayNt: (json['words_array_nt'] as List?)?.cast<String>() ?? [],
      page: json['page'] ?? 1,
      juz: json['juz'] ?? 1,
      quarterHizb: (json['quarter_hizb'] ?? 0.0).toDouble(),
    );
  }
}

class APIWordResult {
  final int position;
  final String expected;
  final String spoken;
  final String status;
  final double similarity_score;

  APIWordResult({
    required this.position,
    required this.expected,
    required this.spoken,
    required this.status,
    required this.similarity_score,
  });

  factory APIWordResult.fromJson(Map<String, dynamic> json) {
    return APIWordResult(
      position: json['position'] ?? 0,
      expected: json['expected'] ?? '',
      spoken: json['spoken'] ?? '',
      status: json['status'] ?? 'unknown',
      similarity_score: (json['similarity_score'] ?? 0.0).toDouble(),
    );
  }

  ReadingStatus getReadingStatus() {
    switch (status.toLowerCase()) {
      case 'matched':
        return ReadingStatus.correct;
      case 'mismatched':
        return ReadingStatus.error;
      case 'skipped':
        return ReadingStatus.skipped;
      default:
        return ReadingStatus.notRead;
    }
  }

  // Get background color based on word status
  Color getBackgroundColor() {
    switch (status.toLowerCase()) {
      case 'matched':
        return const Color(0xFF27AE60).withOpacity(0.3); // Green for correct
      case 'mismatched':
        return const Color(0xFFE74C3C).withOpacity(0.4); // Brighter red for incorrect
      case 'skipped':
      case 'unknown':
      default:
        return Colors.transparent; // No background for unspoken
    }
  }
}

class APILog {
  final DateTime timestamp;
  final String method;
  final String endpoint;
  final int statusCode;
  final String message;

  APILog({
    required this.timestamp,
    required this.method,
    required this.endpoint,
    required this.statusCode,
    required this.message,
  });

  Map<String, dynamic> toJson() {
    return {
      'timestamp': timestamp.toIso8601String(),
      'method': method,
      'endpoint': endpoint,
      'status_code': statusCode,
      'message': message,
    };
  }
}

enum ReadingStatus { notRead, correct, error, skipped }

enum SnackBarType { success, error, warning, info }

// ==================== VOSK MODEL MANAGER ====================

class EnhancedVoskModelManager {
  static const String _logPrefix = 'ENHANCED_VOSK_MODEL_MANAGER';

  static const Map<String, EnhancedModelInfo> availableModels = {
    'arabic_linto': EnhancedModelInfo(
      key: 'arabic_linto',
      name: 'Arabic Linto Pro',
      language: 'ar',
      assetPath: 'assets/models/vosk-model-ar-0.22-linto-1.1.0.zip',
      description:
          'High-accuracy Arabic model optimized for Quranic recitation',
      estimatedSize: '1,3 GB',
      accuracy: 0.92,
      speed: 0.88,
    ),
    'arabic_mgb2': EnhancedModelInfo(
      key: 'arabic_mgb2',
      name: 'Arabic MGB2 Enhanced',
      language: 'ar',
      assetPath: 'assets/models/vosk-model-ar-mgb2-0.4.zip',
      description: 'Balanced Arabic model with good speed and accuracy',
      estimatedSize: '300 MB',
      accuracy: 0.89,
      speed: 0.94,
    ),
  };

  static Future<String> getModelPath(String modelKey) async {
    final modelInfo = availableModels[modelKey];
    if (modelInfo == null) {
      throw Exception('Enhanced model not found: $modelKey');
    }

    final appDir = await getApplicationDocumentsDirectory();
    final modelDir = Directory('${appDir.path}/enhanced_vosk_models/$modelKey');
    return modelDir.path;
  }

  static Future<bool> isModelExists(String modelKey) async {
    try {
      final modelPath = await getModelPath(modelKey);
      final modelDir = Directory(modelPath);

      if (!await modelDir.exists()) {
        return false;
      }

      final requiredFiles = [
        'am/final.mdl',
        'graph/HCLG.fst',
        'graph/phones.txt',
        'graph/words.txt',
        'ivector/final.ie',
        'ivector/global_cmvn.stats',
        'conf/model.conf',
        'conf/mfcc.conf',
      ];

      for (final file in requiredFiles) {
        final filePath = File('$modelPath/$file');
        if (!await filePath.exists()) {
          _log('Verification failed: Missing $file');
          return false;
        }

        final stat = await filePath.stat();
        if (stat.size == 0) {
          _log('Verification failed: Empty file $file');
          return false;
        }
      }

      _log('Model verification passed for $modelKey');
      return true;
    } catch (e) {
      _log('Error in model verification: $e');
      return false;
    }
  }

  static Future<void> copyModelFromAssets({
    required String modelKey,
    Function(int copied, int total)? onProgress,
  }) async {
    final modelInfo = availableModels[modelKey];
    if (modelInfo == null) {
      throw Exception('Enhanced model not found: $modelKey');
    }

    _log('Extraction starting for $modelKey from ${modelInfo.assetPath}');

    final modelPath = await getModelPath(modelKey);
    final modelDir = Directory(modelPath);

    if (await modelDir.exists()) {
      await modelDir.delete(recursive: true);
    }
    await modelDir.create(recursive: true);

    try {
      _log('Loading ZIP asset: ${modelInfo.assetPath}');
      final zipBytes = await rootBundle.load(modelInfo.assetPath);
      final zipData = zipBytes.buffer.asUint8List();

      _log('ZIP loaded: ${formatFileSize(zipData.length)}');

      late Archive archive;
      try {
        archive = ZipDecoder().decodeBytes(zipData);
      } catch (e) {
        throw Exception('Failed to decode ZIP: $e');
      }

      _log('ZIP decoded: ${archive.files.length} files');

      String? modelFolderPrefix = _detectEnhancedModelPrefix(archive);
      if (modelFolderPrefix != null) {
        _log('Model prefix: $modelFolderPrefix');
      }

      int extractedFiles = 0;
      final totalFiles = archive.files.where((f) => f.isFile).length;

      for (final file in archive.files) {
        if (!file.isFile) continue;

        String relativePath = _processEnhancedFilePath(
          file.name,
          modelFolderPrefix,
        );

        if (relativePath.isEmpty) continue;

        final filePath = '${modelDir.path}/$relativePath';
        final targetFile = File(filePath);

        _log('Extracting: ${file.name} -> $relativePath');

        try {
          await targetFile.parent.create(recursive: true);

          final fileData = file.content as List<int>;
          await targetFile.writeAsBytes(fileData);

          if (_isEnhancedCriticalFile(relativePath)) {
            final stat = await targetFile.stat();
            if (stat.size == 0) {
              throw Exception('Critical file empty: $relativePath');
            }
            _log(
              '‚úì Critical file: $relativePath (${formatFileSize(stat.size)})',
            );
          }

          extractedFiles++;
          onProgress?.call(extractedFiles, totalFiles);
        } catch (e) {
          _log('Extraction error for ${file.name}: $e');
          throw Exception('Failed to extract ${file.name}: $e');
        }
      }

      _log('Extraction completed: $extractedFiles/$totalFiles files');

      if (extractedFiles == 0) {
        throw Exception('No files extracted from ZIP');
      }

      await _performEnhancedFinalVerification(modelPath);

      _log('Model $modelKey extracted and verified');
    } catch (e) {
      _log('Extraction failed: $e');
      if (await modelDir.exists()) {
        await modelDir.delete(recursive: true);
      }
      throw Exception('Model extraction failed: $e');
    }
  }

  static String? _detectEnhancedModelPrefix(Archive archive) {
    Set<String> topLevelDirs = {};

    for (final file in archive.files) {
      if (file.isFile && file.name.contains('/')) {
        final parts = file.name.split('/');
        if (parts.isNotEmpty) {
          topLevelDirs.add(parts[0]);
        }
      }
    }

    for (final dir in topLevelDirs) {
      if (dir.toLowerCase().startsWith('vosk-model')) {
        return dir;
      }
    }

    return null;
  }

  static String _processEnhancedFilePath(String originalPath, String? prefix) {
    String path = originalPath;

    if (prefix != null && path.startsWith('$prefix/')) {
      path = path.substring(prefix.length + 1);
    }

    path = path.replaceAll(RegExp(r'^[\/\\]+'), '');

    return path;
  }

  static bool _isEnhancedCriticalFile(String path) {
    final criticalPaths = [
      'am/final.mdl',
      'graph/HCLG.fst',
      'graph/phones.txt',
      'graph/words.txt',
      'ivector/final.ie',
      'ivector/global_cmvn.stats',
      'conf/model.conf',
      'conf/mfcc.conf',
    ];

    return criticalPaths.any((criticalPath) => path.endsWith(criticalPath));
  }

  static Future<void> _performEnhancedFinalVerification(
    String modelPath,
  ) async {
    _log('Final verification for $modelPath');

    final criticalFiles = [
      'am/final.mdl',
      'graph/HCLG.fst',
      'ivector/final.ie',
      'conf/model.conf',
    ];

    for (final filePath in criticalFiles) {
      final file = File('$modelPath/$filePath');

      if (!await file.exists()) {
        throw Exception('Missing critical file $filePath');
      }

      final stat = await file.stat();
      if (stat.size == 0) {
        throw Exception('Empty critical file $filePath');
      }

      if (filePath.endsWith('model.conf')) {
        final content = await file.readAsString();
        if (!content.contains('--sample-frequency')) {
          _log('Warning: model.conf may be incomplete');
        }
      }

      _log('‚úì Verification passed: $filePath (${formatFileSize(stat.size)})');
    }

    _log('Final verification completed');
  }

  static Future<bool> verifyEnhancedModelIntegrity(String modelKey) async {
    try {
      _log('Integrity verification for $modelKey');

      final modelPath = await getModelPath(modelKey);

      final criticalFiles = [
        'am/final.mdl',
        'graph/HCLG.fst',
        'graph/phones.txt',
        'graph/words.txt',
        'ivector/final.ie',
        'conf/model.conf',
      ];

      for (final filePath in criticalFiles) {
        final file = File('$modelPath/$filePath');
        if (!await file.exists() || (await file.stat()).size == 0) {
          _log('Integrity check failed for $filePath');
          return false;
        }
      }

      _log('Integrity verification passed for $modelKey');
      return true;
    } catch (e) {
      _log('Integrity verification error: $e');
      return false;
    }
  }

  static String formatFileSize(int bytes) {
    const suffixes = ['B', 'KB', 'MB', 'GB'];
    int i = 0;
    double size = bytes.toDouble();

    while (size >= 1024 && i < suffixes.length - 1) {
      size /= 1024;
      i++;
    }

    return '${size.toStringAsFixed(1)} ${suffixes[i]}';
  }

  static void _log(String message) {
    final timestamp = DateTime.now().toString().substring(11, 23);
    print('[$timestamp] $_logPrefix: $message');
  }
} // End of _VoskSTTCorrectionPageState class

class EnhancedModelInfo {
  final String key;
  final String name;
  final String language;
  final String assetPath;
  final String description;
  final String estimatedSize;
  final double accuracy;
  final double speed;

  const EnhancedModelInfo({
    required this.key,
    required this.name,
    required this.language,
    required this.assetPath,
    required this.description,
    required this.estimatedSize,
    required this.accuracy,
    required this.speed,
  });
}

