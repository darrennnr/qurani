# ğŸ“‹ Qurani Hafidz - Project Summary

## ğŸ¯ Project Overview

**Qurani Hafidz** is a real-time Quran recitation app with AI-powered feedback, built using:
- **Flutter** for mobile UI
- **FastAPI** for backend server
- **Whisper AI** for Arabic speech recognition (GPU-accelerated)
- **Supabase** for cloud database storage

The app allows users to recite Quranic verses and receive instant, word-level feedback on their pronunciation accuracy.

## ğŸ—ï¸ Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MOBILE APP (Flutter)                     â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚   Surah    â”‚  â”‚ Recitation â”‚  â”‚   Audio    â”‚                 â”‚
â”‚  â”‚    Page    â”‚â—„â”€â”¤  Provider  â”‚â—„â”€â”¤  Service   â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                         â”‚                â”‚                        â”‚
â”‚                         â”‚                â”‚ Record Audio           â”‚
â”‚                         â–¼                â–¼                        â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                  â”‚  WebSocket Service      â”‚                     â”‚
â”‚                  â”‚  (Real-time Streaming)  â”‚                     â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ WebSocket
                             â”‚ (Base64 Audio)
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND SERVER (FastAPI)                      â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚
â”‚  â”‚   Main.py   â”‚ WebSocket Endpoint                              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                                 â”‚
â”‚         â”‚                                                         â”‚
â”‚         â”œâ”€â–º â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚         â”‚   â”‚  VAD Service     â”‚ Voice Activity Detection        â”‚
â”‚         â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚         â”‚                                                         â”‚
â”‚         â”œâ”€â–º â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚         â”‚   â”‚ Whisper Service  â”‚ GPU Speech-to-Text             â”‚
â”‚         â”‚   â”‚  (CUDA/PyTorch)  â”‚                                â”‚
â”‚         â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚         â”‚                                                         â”‚
â”‚         â”œâ”€â–º â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚         â”‚   â”‚ Text Aligner     â”‚ Compare with Quran Reference   â”‚
â”‚         â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚         â”‚                                                         â”‚
â”‚         â””â”€â–º â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚             â”‚ Supabase Client  â”‚ Save Session Data              â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ HTTPS REST API
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   SUPABASE      â”‚
                    â”‚   (PostgreSQL)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Complete File Structure

```
cuda_qurani/
â”‚
â”œâ”€â”€ lib/                              # Flutter Application
â”‚   â”œâ”€â”€ main.dart                     # App entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ quran_models.dart        # Data models (Verse, Surah, WordFeedback)
â”‚   â”‚
â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â””â”€â”€ recitation_provider.dart # State management for recitation
â”‚   â”‚
â”‚   â”œâ”€â”€ screens/
â”‚   â”‚   â””â”€â”€ surah_page.dart          # Main Surah recitation UI
â”‚   â”‚
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ audio_service.dart       # Audio recording/streaming
â”‚       â”œâ”€â”€ websocket_service.dart   # WebSocket communication
â”‚       â””â”€â”€ supabase_service.dart    # Supabase REST API client
â”‚
â”œâ”€â”€ backend/                          # Python Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                  # FastAPI app + WebSocket endpoint
â”‚   â”‚   â”œâ”€â”€ whisper_service.py       # Whisper AI inference
â”‚   â”‚   â”œâ”€â”€ text_alignment.py        # Arabic text comparison
â”‚   â”‚   â”œâ”€â”€ vad_service.py           # Voice Activity Detection
â”‚   â”‚   â””â”€â”€ supabase_client.py       # Supabase REST client
â”‚   â”‚
â”‚   â”œâ”€â”€ requirements.txt              # Python dependencies
â”‚   â”œâ”€â”€ .env.example                  # Environment variables template
â”‚   â””â”€â”€ setup.ps1                     # Automated setup script
â”‚
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ surah_yasin.json         # Quran reference data
â”‚
â”œâ”€â”€ android/
â”‚   â””â”€â”€ app/src/main/
â”‚       â””â”€â”€ AndroidManifest.xml      # Android permissions
â”‚
â”œâ”€â”€ pubspec.yaml                      # Flutter dependencies
â”œâ”€â”€ README.md                         # Full documentation
â”œâ”€â”€ QUICKSTART.md                     # Quick setup guide
â””â”€â”€ PROJECT_SUMMARY.md                # This file
```

## ğŸ”„ Data Flow

### Recording Flow:
1. User presses **microphone button**
2. Flutter app requests **microphone permission**
3. `AudioService` starts recording **16kHz PCM audio**
4. Audio chunks are **base64 encoded**
5. Sent via **WebSocket** to backend

### Processing Flow:
1. Backend receives audio chunk
2. **VAD Service** checks for speech activity
3. If speech detected â†’ **Whisper Service** transcribes
4. **Text Aligner** compares with Quran reference
5. Returns word-level feedback:
   - âœ… **Matched** (green) - â‰¥60% similarity
   - âš ï¸ **Mismatched** (red) - 30-59% similarity
   - âŒ **Skipped** (gray) - <30% similarity

### Feedback Flow:
1. Backend sends **progress message** via WebSocket
2. Flutter receives and updates UI **in real-time**
3. Words are highlighted with color coding
4. On stop: **summary calculated**
5. Summary saved to **Supabase**

## ğŸ› ï¸ Technology Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Mobile UI** | Flutter 3.9+ | Cross-platform mobile app |
| **State Management** | Provider | Reactive state updates |
| **Audio Recording** | `record` package | Real-time audio streaming |
| **Communication** | WebSocket | Bidirectional real-time data |
| **Backend** | FastAPI | High-performance Python API |
| **AI Model** | OpenAI Whisper | Arabic speech recognition |
| **GPU Acceleration** | PyTorch + CUDA | Fast inference |
| **Text Processing** | Python difflib | Levenshtein distance |
| **Database** | Supabase (PostgreSQL) | Session storage |
| **API** | REST | Database operations |

## ğŸ“Š Key Features Implementation

### 1. Real-time Audio Streaming
- **Package**: `record` (Flutter)
- **Format**: PCM 16-bit, 16kHz, Mono
- **Protocol**: WebSocket with base64 encoding
- **Latency**: < 1.5 seconds

### 2. GPU-Accelerated Transcription
- **Model**: Whisper Base (Arabic)
- **Hardware**: CUDA-enabled GPU
- **Optimization**: FP16 mixed precision
- **Fallback**: CPU mode if no GPU

### 3. Word-Level Feedback
- **Normalization**: Remove Arabic diacritics
- **Comparison**: Levenshtein distance ratio
- **Thresholds**:
  - Matched: â‰¥ 0.6 (60%)
  - Mismatched: 0.3 - 0.59 (30-59%)
  - Skipped: < 0.3 (30%)

### 4. Cloud Storage
- **Platform**: Supabase
- **Protocol**: REST API (no direct PostgreSQL)
- **Data**: Sessions, transcripts, logs
- **Security**: Service role key authentication

## ğŸš€ Performance Metrics

| Metric | Target | Notes |
|--------|--------|-------|
| Audio Latency | < 100ms | Recording to network |
| Transcription | < 1.5s | 3-second audio chunk |
| Feedback Display | < 50ms | WebSocket â†’ UI update |
| Total E2E Latency | < 2s | User speech â†’ visual feedback |
| GPU Memory | ~2GB | RTX 3050 or better |
| CPU Mode | 5-10s | Fallback without GPU |

## ğŸ” Security Considerations

1. **API Keys**: Stored in `.env`, never committed
2. **Permissions**: Microphone access requested at runtime
3. **Network**: HTTPS for Supabase, WSS for WebSocket (production)
4. **Audio**: Not stored permanently on device
5. **Database**: Row-level security in Supabase (optional)

## ğŸ§ª Testing Strategy

### Unit Tests (Future)
- Text normalization
- Similarity calculation
- Audio format validation

### Integration Tests (Future)
- WebSocket communication
- Whisper inference
- Supabase API calls

### Manual Testing (Current)
1. Test on real device with microphone
2. Verify real-time feedback
3. Check accuracy calculation
4. Confirm Supabase storage

## ğŸ“ˆ Future Enhancements

- [ ] **More Surahs**: Add all 114 Surahs
- [ ] **Tajweed Feedback**: Detect pronunciation rules
- [ ] **User Authentication**: Personal accounts
- [ ] **Progress Tracking**: Historical performance
- [ ] **Offline Mode**: Local transcription cache
- [ ] **Multi-language**: Support for translations
- [ ] **Advanced Analytics**: Detailed statistics dashboard
- [ ] **Social Features**: Compare with friends
- [ ] **Gamification**: Badges and achievements

## ğŸ“ Deployment Checklist

### Backend
- [ ] Set up GPU server (RunPod/AWS/GCP)
- [ ] Configure firewall rules
- [ ] Set environment variables
- [ ] Enable HTTPS (Let's Encrypt)
- [ ] Set up monitoring (logs)
- [ ] Configure auto-restart

### Frontend
- [ ] Update server URLs
- [ ] Build release APK/IPA
- [ ] Test on multiple devices
- [ ] Submit to Play Store/App Store
- [ ] Configure app signing

### Database
- [ ] Create Supabase project
- [ ] Run SQL schema
- [ ] Configure RLS policies
- [ ] Set up backups

## ğŸ“ Learning Resources

- **Flutter**: https://flutter.dev/docs
- **FastAPI**: https://fastapi.tiangolo.com
- **Whisper**: https://github.com/openai/whisper
- **Tarteel**: https://tarteel.ai
- **Supabase**: https://supabase.com/docs

---

**Project Status**: âœ… Core Features Complete  
**Version**: 1.0.0  
**Last Updated**: 2025-10-06
